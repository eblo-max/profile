"""Добавлены поля настроек пользователя

Revision ID: 016c3506fbf6
Revises: b4b252dffe8f
Create Date: 2025-07-07 23:25:08.536236

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "016c3506fbf6"
down_revision: Union[str, None] = "b4b252dffe8f"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("api_usage")
    op.drop_table("analysis_errors")
    op.drop_table("analyses")
    op.drop_table("user_sessions")
    op.alter_column(
        "users",
        "id",
        existing_type=sa.BIGINT(),
        type_=sa.Integer(),
        existing_nullable=False,
        autoincrement=True,
    )
    op.drop_constraint("users_telegram_id_key", "users", type_="unique")
    op.create_index(op.f("ix_users_id"), "users", ["id"], unique=False)
    op.create_index(op.f("ix_users_telegram_id"), "users", ["telegram_id"], unique=True)
    op.create_unique_constraint(None, "users", ["referral_code"])
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, "users", type_="unique")
    op.drop_index(op.f("ix_users_telegram_id"), table_name="users")
    op.drop_index(op.f("ix_users_id"), table_name="users")
    op.create_unique_constraint("users_telegram_id_key", "users", ["telegram_id"])
    op.alter_column(
        "users",
        "id",
        existing_type=sa.Integer(),
        type_=sa.BIGINT(),
        existing_nullable=False,
        autoincrement=True,
    )
    op.create_table(
        "user_sessions",
        sa.Column("id", sa.BIGINT(), autoincrement=True, nullable=False),
        sa.Column("telegram_id", sa.BIGINT(), autoincrement=False, nullable=False),
        sa.Column(
            "current_state", sa.VARCHAR(length=100), autoincrement=False, nullable=True
        ),
        sa.Column(
            "session_data",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.PrimaryKeyConstraint("id", name="user_sessions_pkey"),
        sa.UniqueConstraint("telegram_id", name="user_sessions_telegram_id_key"),
    )
    op.create_table(
        "analyses",
        sa.Column(
            "id",
            sa.BIGINT(),
            server_default=sa.text("nextval('analyses_id_seq'::regclass)"),
            autoincrement=True,
            nullable=False,
        ),
        sa.Column("user_id", sa.BIGINT(), autoincrement=False, nullable=False),
        sa.Column("status", sa.VARCHAR(length=50), autoincrement=False, nullable=False),
        sa.Column("input_text", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column(
            "input_images",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "input_metadata",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "watson_result",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "azure_result",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "google_result",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "aws_result",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "crystal_result",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "receptiviti_result",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "lexalytics_result",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "monkeylearn_result",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "claude_synthesis",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "confidence_score",
            sa.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "bias_warnings",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "source_breakdown",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column("final_report", sa.TEXT(), autoincrement=False, nullable=True),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["user_id"], ["users.id"], name="analyses_user_id_fkey", ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id", name="analyses_pkey"),
        postgresql_ignore_search_path=False,
    )
    op.create_table(
        "analysis_errors",
        sa.Column("id", sa.BIGINT(), autoincrement=True, nullable=False),
        sa.Column("analysis_id", sa.BIGINT(), autoincrement=False, nullable=False),
        sa.Column(
            "service_name", sa.VARCHAR(length=100), autoincrement=False, nullable=False
        ),
        sa.Column(
            "error_type", sa.VARCHAR(length=100), autoincrement=False, nullable=False
        ),
        sa.Column("error_message", sa.TEXT(), autoincrement=False, nullable=False),
        sa.Column(
            "error_details",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["analysis_id"],
            ["analyses.id"],
            name="analysis_errors_analysis_id_fkey",
            ondelete="CASCADE",
        ),
        sa.PrimaryKeyConstraint("id", name="analysis_errors_pkey"),
    )
    op.create_table(
        "api_usage",
        sa.Column("id", sa.BIGINT(), autoincrement=True, nullable=False),
        sa.Column("user_id", sa.BIGINT(), autoincrement=False, nullable=False),
        sa.Column(
            "service_name", sa.VARCHAR(length=100), autoincrement=False, nullable=False
        ),
        sa.Column("requests_count", sa.INTEGER(), autoincrement=False, nullable=False),
        sa.Column("tokens_used", sa.INTEGER(), autoincrement=False, nullable=True),
        sa.Column(
            "cost_usd",
            sa.DOUBLE_PRECISION(precision=53),
            autoincrement=False,
            nullable=True,
        ),
        sa.Column(
            "date",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            autoincrement=False,
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["user_id"], ["users.id"], name="api_usage_user_id_fkey", ondelete="CASCADE"
        ),
        sa.PrimaryKeyConstraint("id", name="api_usage_pkey"),
    )
    # ### end Alembic commands ###
