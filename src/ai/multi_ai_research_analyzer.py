"""
–°–∏—Å—Ç–µ–º–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—É—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ AI –º–æ–¥–µ–ª–∏.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ AI —Å–∏—Å—Ç–µ–º—ã:
- Claude 3.5 Sonnet (–æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ + —Å–∏–Ω—Ç–µ–∑)
- GPT-4 (—Ç–∏–ø–æ–ª–æ–≥–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏)  
- Gemini (–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
- Cohere (–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑)
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import json
from datetime import datetime

import anthropic
import openai
# import google.generativeai as genai  # –ë—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ
# import cohere  # –ë—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–æ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ

from .scientific_research_engine import ScientificSource, PersonData
from ..config.settings import Settings

logger = logging.getLogger(__name__)

@dataclass
class AIAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç –æ–¥–Ω–æ–π AI —Å–∏—Å—Ç–µ–º—ã"""
    ai_model: str
    analysis_type: str
    confidence_score: float
    findings: Dict[str, Any]
    scientific_references: List[str]
    timestamp: datetime
    
    def to_dict(self) -> Dict:
        return {
            "ai_model": self.ai_model,
            "analysis_type": self.analysis_type,
            "confidence_score": self.confidence_score,
            "findings": self.findings,
            "scientific_references": self.scientific_references,
            "timestamp": self.timestamp.isoformat()
        }

class MultiAIResearchAnalyzer:
    """–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞"""
    
    def __init__(self, settings: Settings):
        self.settings = settings
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –∫–ª–∏–µ–Ω—Ç–æ–≤
        self.claude_client = anthropic.AsyncAnthropic(
            api_key=settings.ANTHROPIC_API_KEY
        ) if settings.ANTHROPIC_API_KEY else None
        
        self.openai_client = openai.AsyncOpenAI(
            api_key=settings.OPENAI_API_KEY
        ) if hasattr(settings, 'OPENAI_API_KEY') and settings.OPENAI_API_KEY else None
        
        # Gemini –∏ Cohere –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–ª—é—á–µ–π
        self.gemini_client = None
        self.cohere_client = None
        
        # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –º–æ–¥–µ–ª–µ–π
        self.ai_specializations = {
            "claude": "general_synthesis",
            "gpt4": "personality_typology", 
            "gemini": "cognitive_analysis",
            "cohere": "behavioral_patterns"
        }
    
    async def comprehensive_research_analysis(
        self, 
        person_data: PersonData,
        research_sources: List[ScientificSource]
    ) -> Dict[str, Any]:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ AI —Å–∏—Å—Ç–µ–º—ã
        
        Args:
            person_data: –î–∞–Ω–Ω—ã–µ –æ —á–µ–ª–æ–≤–µ–∫–µ
            research_sources: –ù–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–∞—É—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            
        Returns:
            –î–µ—Ç–∞–ª—å–Ω—ã–π –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        """
        logger.info(f"üß† –ó–∞–ø—É—Å–∫ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {person_data.name}")
        
        try:
            # –≠—Ç–∞–ø 1: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ AI
            analysis_tasks = []
            
            if self.claude_client:
                analysis_tasks.append(
                    self._claude_general_analysis(person_data, research_sources)
                )
            
            if self.openai_client:
                analysis_tasks.append(
                    self._gpt4_personality_analysis(person_data, research_sources)
                )
            
            # –ö–æ–≥–¥–∞ –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏:
            # if self.gemini_client:
            #     analysis_tasks.append(
            #         self._gemini_cognitive_analysis(person_data, research_sources)
            #     )
            # 
            # if self.cohere_client:
            #     analysis_tasks.append(
            #         self._cohere_behavioral_analysis(person_data, research_sources)
            #     )
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            ai_analyses = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            successful_analyses = [
                result for result in ai_analyses 
                if isinstance(result, AIAnalysisResult)
            ]
            
            logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ {len(successful_analyses)} AI –∞–Ω–∞–ª–∏–∑–æ–≤")
            
            # –≠—Ç–∞–ø 2: –°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            final_synthesis = await self._synthesize_ai_results(
                successful_analyses, person_data, research_sources
            )
            
            return {
                "comprehensive_profile": final_synthesis,
                "individual_analyses": [analysis.to_dict() for analysis in successful_analyses],
                "analysis_metadata": {
                    "total_ai_models": len(successful_analyses),
                    "research_sources_used": len(research_sources),
                    "analysis_timestamp": datetime.now().isoformat(),
                    "person_name": person_data.name
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")
            return {
                "comprehensive_profile": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {str(e)}",
                "individual_analyses": [],
                "analysis_metadata": {"error": str(e)}
            }
    
    async def _claude_general_analysis(
        self, 
        person_data: PersonData,
        sources: List[ScientificSource]
    ) -> AIAnalysisResult:
        """Claude: –û–±—â–∏–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ —Å–∏–Ω—Ç–µ–∑"""
        try:
            prompt = self._create_claude_prompt(person_data, sources)
            
            response = await self.claude_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=3000,
                messages=[{"role": "user", "content": prompt}]
            )
            
            analysis_text = response.content[0].text
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
            findings = self._parse_claude_analysis(analysis_text)
            
            return AIAnalysisResult(
                ai_model="Claude-3.5-Sonnet",
                analysis_type="general_synthesis",
                confidence_score=0.85,
                findings=findings,
                scientific_references=self._extract_references(analysis_text),
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Claude –∞–Ω–∞–ª–∏–∑–∞: {e}")
            raise
    
    def _create_claude_prompt(
        self, 
        person_data: PersonData,
        sources: List[ScientificSource]
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è Claude"""
        sources_text = self._format_sources_for_ai(sources[:10])
        
        return f"""
–í—ã–ø–æ–ª–Ω–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π.

–î–ê–ù–ù–´–ï –û –ß–ï–õ–û–í–ï–ö–ï:
–ò–º—è: {person_data.name}
–í–æ–∑—Ä–∞—Å—Ç: {person_data.age}
–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {person_data.occupation}
–ü–æ–≤–µ–¥–µ–Ω–∏–µ: {person_data.behavior_description}
–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã: {', '.join(person_data.emotional_markers)}
–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(person_data.social_patterns)}
–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏: {', '.join(person_data.cognitive_traits)}

–ù–ê–£–ß–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò:
{sources_text}

–ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å, –∏—Å–ø–æ–ª—å–∑—É—è –Ω–∞—É—á–Ω–æ-–æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥.

–¢–†–ï–ë–£–ï–ú–´–ô –§–û–†–ú–ê–¢ (JSON):
{{
    "personality_type": "–û—Å–Ω–æ–≤–Ω–æ–π —Ç–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º",
    "big_five_traits": {{
        "openness": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}},
        "conscientiousness": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}},
        "extraversion": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}},
        "agreeableness": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}},
        "neuroticism": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}}
    }},
    "emotional_intelligence": {{
        "self_awareness": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}},
        "self_regulation": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}},
        "motivation": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}},
        "empathy": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}},
        "social_skills": {{"score": 0-100, "description": "–æ–ø–∏—Å–∞–Ω–∏–µ"}}
    }},
    "cognitive_profile": {{
        "thinking_style": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∏–ª—è –º—ã—à–ª–µ–Ω–∏—è",
        "decision_making": "–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π",
        "problem_solving": "–ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º",
        "learning_style": "–ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —Å—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è"
    }},
    "behavioral_patterns": {{
        "communication_style": "—Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è",
        "conflict_resolution": "–ø–æ–¥—Ö–æ–¥ –∫ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞–º",
        "leadership_style": "—Å—Ç–∏–ª—å –ª–∏–¥–µ—Ä—Å—Ç–≤–∞",
        "stress_response": "—Ä–µ–∞–∫—Ü–∏—è –Ω–∞ —Å—Ç—Ä–µ—Å—Å"
    }},
    "relationship_compatibility": {{
        "attachment_style": "—Å—Ç–∏–ª—å –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏",
        "romantic_compatibility": "—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö",
        "friendship_patterns": "–ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥—Ä—É–∂–±—ã",
        "team_dynamics": "–¥–∏–Ω–∞–º–∏–∫–∞ –≤ –∫–æ–º–∞–Ω–¥–µ"
    }},
    "professional_profile": {{
        "career_strengths": ["—Å–ø–∏—Å–æ–∫ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω"],
        "ideal_work_environment": "–æ–ø–∏—Å–∞–Ω–∏–µ –∏–¥–µ–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—á–µ–π —Å—Ä–µ–¥—ã",
        "leadership_potential": "–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –ª–∏–¥–µ—Ä—Å—Ç–≤–∞",
        "collaboration_style": "—Å—Ç–∏–ª—å —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞"
    }},
    "potential_challenges": {{
        "stress_vulnerabilities": ["—É—è–∑–≤–∏–º–æ—Å—Ç–∏ –∫ —Å—Ç—Ä–µ—Å—Å—É"],
        "relationship_challenges": ["–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö"],
        "professional_risks": ["–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏"],
        "growth_areas": ["–æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è"]
    }},
    "cultural_considerations": {{
        "cultural_background_impact": "–≤–ª–∏—è–Ω–∏–µ –∫—É–ª—å—Ç—É—Ä–Ω–æ–≥–æ —Ñ–æ–Ω–∞",
        "adaptation_patterns": "–ø–∞—Ç—Ç–µ—Ä–Ω—ã –∞–¥–∞–ø—Ç–∞—Ü–∏–∏",
        "value_system": "—Å–∏—Å—Ç–µ–º–∞ —Ü–µ–Ω–Ω–æ—Å—Ç–µ–π"
    }},
    "scientific_validation": {{
        "confidence_level": "—É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –∞–Ω–∞–ª–∏–∑–µ (0-100)",
        "key_research_support": ["–∫–ª—é—á–µ–≤—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ –≤—ã–≤–æ–¥—ã"],
        "limitations": ["–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞"]
    }}
}}

–£–±–µ–¥–∏—Å—å, —á—Ç–æ –∫–∞–∂–¥—ã–π –≤—ã–≤–æ–¥ –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω –Ω–∞—É—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
"""
    
    def _format_sources_for_ai(self, sources: List[ScientificSource]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è AI"""
        formatted = []
        
        for i, source in enumerate(sources, 1):
            entry = f"""
–ò–°–¢–û–ß–ù–ò–ö {i}:
- –ó–∞–≥–æ–ª–æ–≤–æ–∫: {source.title}
- –ê–≤—Ç–æ—Ä—ã: {', '.join(source.authors)}
- –ü—É–±–ª–∏–∫–∞—Ü–∏—è: {source.publication} ({source.year})
- –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {source.abstract[:300]}...
- –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {source.citations}
- –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {source.quality_score}/100
"""
            formatted.append(entry)
        
        return "\n".join(formatted)
    
    def _parse_claude_analysis(self, analysis_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ Claude"""
        try:
            # –ò—â–µ–º JSON –±–ª–æ–∫ –≤ –æ—Ç–≤–µ—Ç–µ
            json_start = analysis_text.find('{')
            json_end = analysis_text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = analysis_text[json_start:json_end]
                return json.loads(json_text)
            else:
                # –ï—Å–ª–∏ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                return {
                    "analysis_summary": analysis_text,
                    "parsing_note": "JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–µ–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"
                }
                
        except json.JSONDecodeError:
            return {
                "analysis_summary": analysis_text,
                "parsing_note": "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON, –≤–æ–∑–≤—Ä–∞—â–µ–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑"
            }
    
    def _extract_references(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞—É—á–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        references = []
        
        # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        patterns = [
            r'–ò–°–¢–û–ß–ù–ò–ö \d+',
            r'\(\d{4}\)',  # –ì–æ–¥—ã –≤ —Å–∫–æ–±–∫–∞—Ö
            r'et al\.',
            r'DOI:.*',
            r'PMID:.*'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            references.extend(matches)
        
        return list(set(references))
    
    async def _gpt4_personality_analysis(
        self, 
        person_data: PersonData,
        sources: List[ScientificSource]
    ) -> AIAnalysisResult:
        """GPT-4: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –ª–∏—á–Ω–æ—Å—Ç–∏"""
        try:
            prompt = self._create_gpt4_prompt(person_data, sources)
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2500,
                temperature=0.3
            )
            
            analysis_text = response.choices[0].message.content
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
            findings = self._parse_gpt4_analysis(analysis_text)
            
            return AIAnalysisResult(
                ai_model="GPT-4",
                analysis_type="personality_typology",
                confidence_score=0.80,
                findings=findings,
                scientific_references=self._extract_references(analysis_text),
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ GPT-4 –∞–Ω–∞–ª–∏–∑–∞: {e}")
            raise
    
    def _create_gpt4_prompt(
        self, 
        person_data: PersonData,
        sources: List[ScientificSource]
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è GPT-4"""
        sources_text = self._format_sources_for_ai(sources[:8])
        
        return f"""
–ü—Ä–æ–≤–µ–¥–∏ —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞ –ª–∏—á–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—É—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

–õ–ò–ß–ù–´–ï –î–ê–ù–ù–´–ï:
{self._format_person_data(person_data)}

–ù–ê–£–ß–ù–ê–Ø –ë–ê–ó–ê:
{sources_text}

–§–û–ö–£–° –ê–ù–ê–õ–ò–ó–ê:
1. MBTI —Ç–∏–ø–æ–ª–æ–≥–∏—è —Å –Ω–∞—É—á–Ω—ã–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º
2. Big Five –º–æ–¥–µ–ª—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏
3. DISC –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è —Ä–∞–±–æ—á–µ–π —Å—Ä–µ–¥—ã
4. –¢–µ–æ—Ä–∏—è —Ç–∏–ø–æ–≤ –Æ–Ω–≥–∞
5. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ª–∏—á–Ω–æ—Å—Ç–∏

–¢–†–ï–ë–£–ï–ú–´–ô –§–û–†–ú–ê–¢:
```json
{{
    "mbti_analysis": {{
        "primary_type": "4-–±—É–∫–≤–µ–Ω–Ω—ã–π –∫–æ–¥ MBTI",
        "confidence": "–ø—Ä–æ—Ü–µ–Ω—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏",
        "cognitive_functions": {{
            "dominant": "–æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏",
            "auxiliary": "–æ–ø–∏—Å–∞–Ω–∏–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏",
            "tertiary": "–æ–ø–∏—Å–∞–Ω–∏–µ —Ç—Ä–µ—Ç–∏—á–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏",
            "inferior": "–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∏–∑—à–µ–π —Ñ—É–Ω–∫—Ü–∏–∏"
        }},
        "type_description": "–¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–∏–ø–∞"
    }},
    "big_five_detailed": {{
        "openness": {{"percentile": 0-100, "facets": ["—Å–ø–∏—Å–æ–∫ –≥—Ä–∞–Ω–µ–π"]}},
        "conscientiousness": {{"percentile": 0-100, "facets": ["—Å–ø–∏—Å–æ–∫ –≥—Ä–∞–Ω–µ–π"]}},
        "extraversion": {{"percentile": 0-100, "facets": ["—Å–ø–∏—Å–æ–∫ –≥—Ä–∞–Ω–µ–π"]}},
        "agreeableness": {{"percentile": 0-100, "facets": ["—Å–ø–∏—Å–æ–∫ –≥—Ä–∞–Ω–µ–π"]}},
        "neuroticism": {{"percentile": 0-100, "facets": ["—Å–ø–∏—Å–æ–∫ –≥—Ä–∞–Ω–µ–π"]}}
    }},
    "disc_profile": {{
        "primary_style": "D/I/S/C",
        "secondary_style": "–≤—Ç–æ—Ä–∏—á–Ω—ã–π —Å—Ç–∏–ª—å",
        "workplace_behavior": "–ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ —Ä–∞–±–æ—Ç–µ",
        "communication_preferences": "–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –≤ –æ–±—â–µ–Ω–∏–∏"
    }},
    "jungian_types": {{
        "attitude": "extraversion/introversion",
        "functions": ["thinking", "feeling", "sensing", "intuition"],
        "type_dynamics": "–¥–∏–Ω–∞–º–∏–∫–∞ —Ç–∏–ø–∞"
    }},
    "modern_models": {{
        "hexaco": "–∞–Ω–∞–ª–∏–∑ –ø–æ –º–æ–¥–µ–ª–∏ HEXACO",
        "dark_triad": "–∞–Ω–∞–ª–∏–∑ —Ç–µ–º–Ω–æ–π —Ç—Ä–∏–∞–¥—ã",
        "emotional_stability": "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å"
    }},
    "scientific_backing": {{
        "research_support": ["–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"],
        "reliability_scores": "–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–æ–∫",
        "cross_validation": "–∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏"
    }}
}}
```

–û–±–µ—Å–ø–µ—á—å –Ω–∞—É—á–Ω—É—é –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ –≤—ã–≤–æ–¥–∞.
"""
    
    def _format_person_data(self, person_data: PersonData) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —á–µ–ª–æ–≤–µ–∫–µ"""
        return f"""
–ò–º—è: {person_data.name}
–í–æ–∑—Ä–∞—Å—Ç: {person_data.age}
–ü–æ–ª: {person_data.gender or '–ù–µ —É–∫–∞–∑–∞–Ω'}
–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {person_data.occupation}
–ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {person_data.behavior_description}
–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π —Ç–∏–ø: {person_data.suspected_personality_type}
–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã: {', '.join(person_data.emotional_markers)}
–°–æ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {', '.join(person_data.social_patterns)}
–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ —á–µ—Ä—Ç—ã: {', '.join(person_data.cognitive_traits)}
–°—Ç—Ä–∞–Ω–∞: {person_data.country}
–ö—É–ª—å—Ç—É—Ä–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {person_data.cultural_context}
"""
    
    def _parse_gpt4_analysis(self, analysis_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ GPT-4"""
        try:
            # –ò—â–µ–º JSON –±–ª–æ–∫
            json_start = analysis_text.find('{')
            json_end = analysis_text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_text = analysis_text[json_start:json_end]
                return json.loads(json_text)
            else:
                return {
                    "gpt4_analysis": analysis_text,
                    "note": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω"
                }
                
        except json.JSONDecodeError:
            return {
                "gpt4_analysis": analysis_text,
                "note": "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON"
            }
    
    async def _synthesize_ai_results(
        self, 
        ai_analyses: List[AIAnalysisResult],
        person_data: PersonData,
        sources: List[ScientificSource]
    ) -> str:
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –≤—Å–µ—Ö AI —Å–∏—Å—Ç–µ–º"""
        if not ai_analyses:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã AI –∞–Ω–∞–ª–∏–∑–∞."
        
        if not self.claude_client:
            return self._create_basic_synthesis(ai_analyses, person_data)
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
            analyses_summary = self._prepare_synthesis_data(ai_analyses)
            
            synthesis_prompt = f"""
–°–æ–∑–¥–∞–π –∏—Ç–æ–≥–æ–≤—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å, –æ–±—ä–µ–¥–∏–Ω–∏–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç —Ä–∞–∑–Ω—ã—Ö AI —Å–∏—Å—Ç–µ–º.

–î–ê–ù–ù–´–ï –û –ß–ï–õ–û–í–ï–ö–ï:
{self._format_person_data(person_data)}

–†–ï–ó–£–õ–¨–¢–ê–¢–´ AI –ê–ù–ê–õ–ò–ó–û–í:
{analyses_summary}

–ö–û–õ–ò–ß–ï–°–¢–í–û –ù–ê–£–ß–ù–´–• –ò–°–¢–û–ß–ù–ò–ö–û–í: {len(sources)}

–ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π, –Ω–∞—É—á–Ω–æ-–æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å, –∫–æ—Ç–æ—Ä—ã–π:
1. –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
2. –†–∞–∑—Ä–µ—à–∞–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ –∞–Ω–∞–ª–∏–∑–∞–º–∏
3. –í—ã–¥–µ–ª—è–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–µ –≤—ã–≤–æ–¥—ã
4. –£–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±–ª–∞—Å—Ç–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
5. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
## üß† –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ü–†–û–§–ò–õ–¨: {person_data.name}

### üìä –ú–ï–¢–ê-–ê–ù–ê–õ–ò–ó
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ AI –º–æ–¥–µ–ª–µ–π:** {len(ai_analyses)}
- **–°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:** [—Ä–∞—Å—Å—á–∏—Ç–∞–π —Å—Ä–µ–¥–Ω–µ–µ]
- **–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:** [–æ—Ü–µ–Ω–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å]

### üéØ –ö–û–ù–°–û–õ–ò–î–ò–†–û–í–ê–ù–ù–´–ô –¢–ò–ü –õ–ò–ß–ù–û–°–¢–ò
[–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –≤—ã–≤–æ–¥—ã –æ —Ç–∏–ø–µ –ª–∏—á–Ω–æ—Å—Ç–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —É—Ä–æ–≤–Ω—è —Å–æ–≥–ª–∞—Å–∏—è –º–µ–∂–¥—É AI]

### üß© –ú–ù–û–ì–û–ú–ï–†–ù–´–ô –ê–ù–ê–õ–ò–ó –ß–ï–†–¢
[–°–∏–Ω—Ç–µ–∑ –æ—Ü–µ–Ω–æ–∫ –ø–æ —Ä–∞–∑–Ω—ã–º –º–æ–¥–µ–ª—è–º –ª–∏—á–Ω–æ—Å—Ç–∏]

### üí≠ –≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–´–ô –ò –ö–û–ì–ù–ò–¢–ò–í–ù–´–ô –ü–†–û–§–ò–õ–¨
[–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ –∏ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è—Ö]

### üë• –°–û–¶–ò–ê–õ–¨–ù–û-–ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò
[–ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è]

### üíº –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
[–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –∫–∞—Ä—å–µ—Ä–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏]

### ‚ö†Ô∏è –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –û–ë–õ–ê–°–¢–ò –í–ù–ò–ú–ê–ù–ò–Ø
[–í—ã—è–≤–ª–µ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏ –∏ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è]

### üîÑ –†–ê–ó–†–ï–®–ï–ù–ò–ï –ü–†–û–¢–ò–í–û–†–ï–ß–ò–ô
[–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –≤ –∞–Ω–∞–ª–∏–∑–∞—Ö –∏ –∏—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã]

### üìà –£–†–û–í–ï–ù–¨ –î–û–°–¢–û–í–ï–†–ù–û–°–¢–ò
[–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞]

### üîó –ù–ê–£–ß–ù–ê–Ø –ë–ê–ó–ê
[–°—Å—ã–ª–∫–∏ –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ –≤—ã–≤–æ–¥—ã]

–û–±–µ—Å–ø–µ—á—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –Ω–∞—É—á–Ω—É—é –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å.
"""
            
            response = await self.claude_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=4000,
                messages=[{"role": "user", "content": synthesis_prompt}]
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            return self._create_basic_synthesis(ai_analyses, person_data)
    
    def _prepare_synthesis_data(self, ai_analyses: List[AIAnalysisResult]) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞"""
        synthesis_data = []
        
        for analysis in ai_analyses:
            data = f"""
AI –ú–û–î–ï–õ–¨: {analysis.ai_model}
–¢–ò–ü –ê–ù–ê–õ–ò–ó–ê: {analysis.analysis_type}
–£–í–ï–†–ï–ù–ù–û–°–¢–¨: {analysis.confidence_score:.2f}
–í–†–ï–ú–Ø: {analysis.timestamp.strftime('%Y-%m-%d %H:%M')}

–ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´:
{json.dumps(analysis.findings, indent=2, ensure_ascii=False)}

–ù–ê–£–ß–ù–´–ï –°–°–´–õ–ö–ò:
{', '.join(analysis.scientific_references[:5])}
"""
            synthesis_data.append(data)
        
        return "\n" + "="*50 + "\n".join(synthesis_data)
    
    def _create_basic_synthesis(
        self, 
        ai_analyses: List[AIAnalysisResult],
        person_data: PersonData
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞ –±–µ–∑ Claude"""
        synthesis = f"""
## üß† –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ü–†–û–§–ò–õ–¨: {person_data.name}

### üìä –ú–ï–¢–ê-–ê–ù–ê–õ–ò–ó
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ AI –º–æ–¥–µ–ª–µ–π:** {len(ai_analyses)}
- **–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≤–µ–¥–µ–Ω:** {datetime.now().strftime('%d.%m.%Y %H:%M')}

### üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê

"""
        
        for i, analysis in enumerate(ai_analyses, 1):
            synthesis += f"""
#### {i}. {analysis.ai_model} - {analysis.analysis_type}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {analysis.confidence_score:.1%}

**–ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã:**
{json.dumps(analysis.findings, indent=2, ensure_ascii=False)}

---
"""
        
        synthesis += f"""
### ‚ö†Ô∏è –í–ê–ñ–ù–û–ï –ü–†–ò–ú–ï–ß–ê–ù–ò–ï
–î–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã {len(ai_analyses)} AI —Å–∏—Å—Ç–µ–º –∏ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö.
–î–ª—è –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º.

*–ê–Ω–∞–ª–∏–∑ —Å–æ–∑–¥–∞–Ω: {datetime.now().strftime('%d.%m.%Y %H:%M')}*
"""
        
        return synthesis 