"""
–û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤ –∏ —Å–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
"""
import asyncio
import structlog
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict

from src.ai.anthropic_client import anthropic_client
from src.ai.watson_client import watson_client
from src.database.connection import get_async_session
from src.database.models import Analysis, AnalysisError
from src.config.settings import settings

logger = structlog.get_logger()


@dataclass
class AnalysisInput:
    """–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    user_id: int
    telegram_id: int
    text: Optional[str] = None
    images: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    analysis_id: int
    status: str
    confidence_score: float
    main_findings: Dict[str, Any]
    detailed_analysis: Dict[str, Any]
    psychological_profile: Dict[str, Any]
    final_report: str
    methodology: List[str]
    limitations: List[str]
    bias_warnings: List[str]
    created_at: datetime


class AnalysisEngine:
    """–û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞"""
        self.claude_client = anthropic_client
        self.watson_client = watson_client
        self.supported_services = {
            "claude": True,
            "watson": watson_client.is_available,
            "azure": settings.azure_cognitive_key is not None,
            "google": settings.google_cloud_project_id is not None,
            "aws": settings.aws_access_key_id is not None,
            "crystal": settings.crystal_api_key is not None,
            "receptiviti": settings.receptiviti_api_key is not None,
            "lexalytics": settings.lexalytics_api_key is not None,
            "monkeylearn": settings.monkeylearn_api_key is not None
        }
        
        active_services = [name for name, active in self.supported_services.items() if active]
        logger.info("üöÄ AnalysisEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω", 
                   active_services=active_services,
                   total_services=len(active_services))
    
    async def analyze_comprehensive(self, analysis_input: AnalysisInput) -> AnalysisResult:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
        
        Args:
            analysis_input: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ –ë–î
        analysis_id = await self._create_analysis_record(analysis_input)
        
        try:
            logger.info("üîç –ù–∞—á–∏–Ω–∞—é –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", 
                       analysis_id=analysis_id,
                       user_id=analysis_input.user_id)
            
            # –≠—Ç–∞–ø 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤
            ai_results = await self._collect_ai_insights(analysis_input, analysis_id)
            
            # –≠—Ç–∞–ø 2: –°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Claude
            synthesis_result = await self._synthesize_results(ai_results, analysis_input)
            
            # –≠—Ç–∞–ø 3: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            validation_result = await self._validate_analysis(synthesis_result)
            
            # –≠—Ç–∞–ø 4: –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            final_report = await self._generate_final_report(
                synthesis_result, 
                validation_result, 
                ai_results
            )
            
            # –≠—Ç–∞–ø 5: –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            confidence_score = self._calculate_confidence_score(ai_results, validation_result)
            bias_warnings = self._detect_potential_bias(synthesis_result, ai_results)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = AnalysisResult(
                analysis_id=analysis_id,
                status="completed",
                confidence_score=confidence_score,
                main_findings=synthesis_result.get("main_findings", {}),
                detailed_analysis=synthesis_result.get("detailed_analysis", {}),
                psychological_profile=synthesis_result.get("psychological_profile", {}),
                final_report=final_report,
                methodology=self._get_methodology_used(ai_results),
                limitations=synthesis_result.get("limitations", []),
                bias_warnings=bias_warnings,
                created_at=datetime.utcnow()
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –ë–î
            await self._save_analysis_result(analysis_id, result, ai_results, synthesis_result)
            
            logger.info("‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                       analysis_id=analysis_id,
                       confidence_score=confidence_score,
                       ai_services_used=len(ai_results))
            
            return result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", 
                        analysis_id=analysis_id, 
                        error=str(e), 
                        exc_info=True)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ –≤ –ë–î
            await self._save_analysis_error(analysis_id, "comprehensive_analysis", str(e))
            
            # –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –æ—à–∏–±–∫–æ–π
            return AnalysisResult(
                analysis_id=analysis_id,
                status="failed",
                confidence_score=0.0,
                main_findings={"error": str(e)},
                detailed_analysis={},
                psychological_profile={},
                final_report=f"–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è: {str(e)}",
                methodology=[],
                limitations=["–ê–Ω–∞–ª–∏–∑ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏"],
                bias_warnings=[],
                created_at=datetime.utcnow()
            )
    
    async def quick_analyze(self, text: str, user_id: int, telegram_id: int) -> str:
        """
        –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Claude + Watson (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            telegram_id: Telegram ID
            
        Returns:
            –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            user_context = {"user_id": user_id, "telegram_id": telegram_id}
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
            services_to_use = ["Claude"]
            if self.supported_services["watson"]:
                services_to_use.append("Watson")
            
            logger.info("‚ö° –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑", 
                       user_id=user_id, 
                       text_length=len(text),
                       services=services_to_use)
            
            # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            tasks = []
            
            # Claude (–≤—Å–µ–≥–¥–∞)
            tasks.append(self._run_claude_analysis(text, user_context))
            
            # Watson (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω –∏ —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π)
            watson_result = None
            if self.supported_services["watson"] and len(text.split()) >= 100:
                tasks.append(self._run_watson_analysis(text, user_context))
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–æ–≤
            if len(tasks) > 1:
                claude_result, watson_result = await asyncio.gather(*tasks, return_exceptions=True)
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                if isinstance(claude_result, Exception):
                    logger.error("‚ùå –û—à–∏–±–∫–∞ Claude", error=str(claude_result))
                    claude_result = {"error": str(claude_result), "status": "failed"}
                
                if isinstance(watson_result, Exception):
                    logger.warning("‚ö†Ô∏è Watson –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", error=str(watson_result))
                    watson_result = None
                
            else:
                # –¢–æ–ª—å–∫–æ Claude
                claude_result = await tasks[0]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if watson_result and watson_result.get("status") == "success":
                # –û–±–æ–≥–∞—â–∞–µ–º Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–∞–Ω–Ω—ã–º–∏ Watson
                enhanced_result = self._enrich_with_watson_data(claude_result, watson_result)
                logger.info("‚úÖ –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω (Claude + Watson)", 
                           user_id=user_id,
                           confidence=enhanced_result.get('confidence_score', 0))
            else:
                # –¢–æ–ª—å–∫–æ Claude
                enhanced_result = claude_result
                logger.info("‚úÖ –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω (—Ç–æ–ª—å–∫–æ Claude)", 
                           user_id=user_id,
                           confidence=enhanced_result.get('confidence_score', 0))
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            formatted_result = self._format_quick_result(enhanced_result, watson_available=bool(watson_result))
            
            return formatted_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", error=str(e), exc_info=True)
            return f"‚ö†Ô∏è **–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**: {str(e)}\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
    
    def _format_quick_result(self, analysis_result: Dict[str, Any], watson_available: bool = False) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è Telegram"""
        
        if "error" in analysis_result:
            return f"‚ö†Ô∏è **–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**: {analysis_result['error']}"
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        hook_summary = analysis_result.get("hook_summary", "")
        personality_core = analysis_result.get("personality_core", {})
        main_findings = analysis_result.get("main_findings", {})
        psychological_profile = analysis_result.get("psychological_profile", {})
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç Watson Big Five –¥–∞–Ω–Ω—ã–º –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        watson_big_five = psychological_profile.get("watson_big_five", {})
        claude_big_five = psychological_profile.get("big_five_traits", {})
        big_five_detailed = watson_big_five if watson_big_five else claude_big_five
        
        practical_insights = analysis_result.get("practical_insights", {})
        actionable_recommendations = analysis_result.get("actionable_recommendations", {})
        fascinating_details = analysis_result.get("fascinating_details", {})
        confidence = analysis_result.get("confidence_score", 80)
        
        # –î–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        data_sources = analysis_result.get("data_sources", {})
        
        # –ù–∞—á–∞–ª–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        result = "üß† **–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó**\n"
        result += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        # –ó–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π —Ö—É–∫
        if hook_summary:
            result += f"‚ú® **{hook_summary}**\n\n"
        
        # –°—É—Ç—å –ª–∏—á–Ω–æ—Å—Ç–∏
        if personality_core.get("essence"):
            result += f"üéØ **–°–£–¢–¨ –õ–ò–ß–ù–û–°–¢–ò:**\n{personality_core['essence']}\n\n"
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–µ—Ä—Ç—ã
        if personality_core.get("unique_traits"):
            result += "‚≠ê **–£–ù–ò–ö–ê–õ–¨–ù–´–ï –ß–ï–†–¢–´:**\n"
            for trait in personality_core["unique_traits"][:3]:
                result += f"‚Ä¢ {trait}\n"
            result += "\n"
        
        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–æ–¥–ø–∏—Å—å
        if main_findings.get("emotional_signature"):
            result += f"‚ù§Ô∏è **–≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–ê–Ø –ü–û–î–ü–ò–°–¨:**\n{main_findings['emotional_signature']}\n\n"
        
        # –°—Ç–∏–ª—å –º—ã—à–ª–µ–Ω–∏—è
        if main_findings.get("thinking_style"):
            result += f"üß† **–°–¢–ò–õ–¨ –ú–´–®–õ–ï–ù–ò–Ø:**\n{main_findings['thinking_style']}\n\n"
        
        # Big Five —Å –¥–µ—Ç–∞–ª—è–º–∏
        if big_five_detailed:
            result += "üìä **–ü–†–û–§–ò–õ–¨ –õ–ò–ß–ù–û–°–¢–ò (Big Five):**\n"
            traits_ru = {
                "openness": "üé® –û—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å",
                "conscientiousness": "üìã –î–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω–æ—Å—Ç—å", 
                "extraversion": "üë• –≠–∫—Å—Ç—Ä–∞–≤–µ—Ä—Å–∏—è",
                "agreeableness": "ü§ù –î–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
                "neuroticism": "üåä –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"
            }
            
            for trait, trait_data in big_five_detailed.items():
                if trait in traits_ru and isinstance(trait_data, dict):
                    score = trait_data.get("score", 50)
                    description = trait_data.get("description", "")
                    level = "üî¥ –ù–∏–∑–∫–∏–π" if score < 40 else "üü° –°—Ä–µ–¥–Ω–∏–π" if score < 70 else "üü¢ –í—ã—Å–æ–∫–∏–π"
                    result += f"‚Ä¢ {traits_ru[trait]}: {score}% {level}\n"
                    if description:
                        result += f"  ‚îî {description[:80]}...\n"
            result += "\n"
        
        # –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
        if practical_insights.get("strengths_to_leverage"):
            result += "üí™ **–í–ê–®–ò –°–£–ü–ï–†–°–ò–õ–´:**\n"
            for strength in practical_insights["strengths_to_leverage"][:2]:
                result += f"‚Ä¢ {strength}\n"
            result += "\n"
        
        # –°–∫—Ä—ã—Ç—ã–µ —Ç–∞–ª–∞–Ω—Ç—ã
        if fascinating_details.get("hidden_talents"):
            result += "üéÅ **–°–ö–†–´–¢–´–ï –¢–ê–õ–ê–ù–¢–´:**\n"
            for talent in fascinating_details["hidden_talents"][:2]:
                result += f"‚Ä¢ {talent}\n"
            result += "\n"
        
        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if actionable_recommendations.get("immediate_actions"):
            result += "üöÄ **–î–ï–ô–°–¢–í–ò–Ø –ù–ê –ù–ï–î–ï–õ–Æ:**\n"
            for action in actionable_recommendations["immediate_actions"][:3]:
                result += f"‚Ä¢ {action}\n"
            result += "\n"
        
        # –ö–∞—Ä—å–µ—Ä–Ω—ã–µ —Å–æ–≤–µ—Ç—ã
        if practical_insights.get("career_alignment"):
            result += f"üíº **–ö–ê–†–¨–ï–†–ê:**\n{practical_insights['career_alignment']}\n\n"
        
        # –û—Ç–Ω–æ—à–µ–Ω–∏—è
        if practical_insights.get("relationship_style"):
            result += f"üíï **–û–¢–ù–û–®–ï–ù–ò–Ø:**\n{practical_insights['relationship_style']}\n\n"
        
        # –°–∫—Ä—ã—Ç—ã–µ –≥–ª—É–±–∏–Ω—ã
        if personality_core.get("hidden_depths"):
            result += f"üîç **–ó–ê –§–ê–°–ê–î–û–ú:**\n{personality_core['hidden_depths']}\n\n"
        
        # –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        result += f"üìà **–ò–ù–î–ï–ö–° –£–í–ï–†–ï–ù–ù–û–°–¢–ò:** {confidence}%\n"
        
        # AI –¥–≤–∏–∂–∫–∏
        if watson_available and data_sources:
            result += f"ü§ñ **AI –î–í–ò–ñ–ö–ò:** Claude 3.5 Sonnet + IBM Watson\n"
            result += f"üî¨ **–ú–ï–¢–û–î–´:** Big Five (Watson), –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (Claude)\n"
            if psychological_profile.get("scientific_validation"):
                result += f"‚úÖ **–ù–ê–£–ß–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø:** IBM Research\n"
        else:
            result += f"ü§ñ **AI –î–í–ò–ñ–û–ö:** Claude 3.5 Sonnet\n"
            result += f"üî¨ **–ú–ï–¢–û–î–´:** Big Five, –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑\n"
        
        # Watson —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if watson_available and watson_big_five:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º Watson –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            watson_needs = psychological_profile.get("psychological_needs", {})
            if watson_needs:
                top_needs = sorted(watson_needs.items(), key=lambda x: x[1].get('percentile', 0), reverse=True)[:2]
                if top_needs:
                    result += f"\nüéØ **–ö–õ–Æ–ß–ï–í–´–ï –ü–û–¢–†–ï–ë–ù–û–°–¢–ò (Watson):**\n"
                    for need_id, need_data in top_needs:
                        result += f"‚Ä¢ {need_data.get('name', need_id)}: {need_data.get('percentile', 0):.0f}%\n"
        
        result += "\nüí¨ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â–µ —Ç–µ–∫—Å—Ç –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!"
        
        return result
    
    async def _collect_ai_insights(self, analysis_input: AnalysisInput, analysis_id: int) -> Dict[str, Any]:
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        results = {}
        tasks = []
        
        if analysis_input.text:
            # Claude –∞–Ω–∞–ª–∏–∑ (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)
            tasks.append(self._run_claude_analysis(analysis_input.text, analysis_input.metadata))
            
            # Watson –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            if self.supported_services["watson"]:
                tasks.append(self._run_watson_analysis(analysis_input.text, analysis_input.metadata))
            
            logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞", 
                       services_count=len(tasks),
                       analysis_id=analysis_id)
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
            ai_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            service_names = ["claude"]
            if self.supported_services["watson"]:
                service_names.append("watson")
            
            for i, result in enumerate(ai_results):
                service_name = service_names[i]
                
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ {service_name} –∞–Ω–∞–ª–∏–∑–∞", 
                               error=str(result), 
                               analysis_id=analysis_id)
                    results[service_name] = {
                        "error": str(result),
                        "status": "failed",
                        "service": service_name
                    }
                else:
                    results[service_name] = result
                    logger.info(f"‚úÖ {service_name.title()} –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                               confidence=result.get('confidence_score', 0),
                               analysis_id=analysis_id)
        
        return results
    
    async def _run_claude_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ Claude –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            return await self.claude_client.analyze_text(
                text=text,
                analysis_type="comprehensive_psychological",
                user_context=metadata
            )
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ Claude –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed",
                "service": "claude"
            }
    
    async def _run_watson_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ Watson –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            return await self.watson_client.analyze_personality(
                text=text,
                user_context=metadata
            )
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ Watson –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed", 
                "service": "watson"
            }
    
    async def _synthesize_results(self, ai_results: Dict[str, Any], analysis_input: AnalysisInput) -> Dict[str, Any]:
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Claude —Å —É—á–µ—Ç–æ–º –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            logger.info("üîÑ –°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç AI —Å–µ—Ä–≤–∏—Å–æ–≤", 
                       services_available=list(ai_results.keys()))
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ–∑
            if len(ai_results) > 1 and "watson" in ai_results and "claude" in ai_results:
                # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ —á–µ—Ä–µ–∑ Claude
                synthesis_context = {
                    "ai_results": ai_results,
                    "services_used": list(ai_results.keys()),
                    "analysis_input": analysis_input.metadata
                }
                
                synthesis_result = await self.claude_client.analyze_text(
                    text=analysis_input.text,
                    analysis_type="synthesis",
                    user_context=synthesis_context
                )
                
                # –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞–Ω–Ω—ã–º–∏ Watson
                if "watson" in ai_results and ai_results["watson"].get("status") == "success":
                    synthesis_result = self._enrich_with_watson_data(synthesis_result, ai_results["watson"])
                
                logger.info("‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                           confidence=synthesis_result.get('confidence_score', 0))
                
                return synthesis_result
            
            # –ï—Å–ª–∏ Watson –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            elif "claude" in ai_results:
                logger.info("üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return ai_results["claude"]
            
            # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ Watson –¥–æ—Å—Ç—É–ø–µ–Ω
            elif "watson" in ai_results:
                logger.info("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Watson —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return self._format_watson_only_result(ai_results["watson"])
            
            else:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")
                return {"error": "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞", "status": "no_results"}
                
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", error=str(e), exc_info=True)
            # Fallback –Ω–∞ Claude –µ—Å–ª–∏ –µ—Å—Ç—å
            return ai_results.get("claude", {"error": str(e), "status": "synthesis_failed"})
    
    def _enrich_with_watson_data(self, claude_result: Dict[str, Any], watson_result: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ Claude –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç Watson"""
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—É—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ Watson –≤ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if "psychological_profile" not in claude_result:
                claude_result["psychological_profile"] = {}
            
            # Watson Big Five –¥–∞–Ω–Ω—ã–µ
            watson_big_five = watson_result.get("big_five_traits", {})
            if watson_big_five:
                claude_result["psychological_profile"]["watson_big_five"] = watson_big_five
                claude_result["psychological_profile"]["scientific_validation"] = True
            
            # Watson –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –∏ —Ü–µ–Ω–Ω–æ—Å—Ç–∏
            if "psychological_needs" in watson_result:
                claude_result["psychological_profile"]["psychological_needs"] = watson_result["psychological_needs"]
            
            if "core_values" in watson_result:
                claude_result["psychological_profile"]["core_values"] = watson_result["core_values"]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º confidence score (—Å—Ä–µ–¥–Ω–∏–π –º–µ–∂–¥—É Claude –∏ Watson)
            watson_confidence = watson_result.get("confidence_score", 0)
            claude_confidence = claude_result.get("confidence_score", 0)
            
            if watson_confidence > 0 and claude_confidence > 0:
                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ: Watson –±–æ–ª—å—à–µ –≤–µ—Å–∞ –∏–∑-–∑–∞ –Ω–∞—É—á–Ω–æ–π –æ—Å–Ω–æ–≤—ã
                combined_confidence = (watson_confidence * 0.6 + claude_confidence * 0.4)
                claude_result["confidence_score"] = round(combined_confidence, 1)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
            claude_result["data_sources"] = {
                "claude": "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–∏–Ω—Ç–µ–∑ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è",
                "watson": "–ù–∞—É—á–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è IBM Research (Big Five –º–æ–¥–µ–ª—å)",
                "synthesis_method": "–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"
            }
            
            logger.info("‚úÖ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–æ–≥–∞—â–µ–Ω –¥–∞–Ω–Ω—ã–º–∏ Watson")
            return claude_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è Watson –¥–∞–Ω–Ω—ã–º–∏", error=str(e))
            return claude_result
    
    def _format_watson_only_result(self, watson_result: Dict[str, Any]) -> Dict[str, Any]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç–æ–ª—å–∫–æ –æ—Ç Watson –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Watson –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç –ø–æ—Ö–æ–∂–∏–π –Ω–∞ Claude
            formatted_result = {
                "analysis_type": "watson_personality",
                "hook_summary": "–ù–∞—É—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ IBM Watson",
                "personality_core": {
                    "essence": watson_result.get("personality_summary", "–ü—Ä–æ—Ñ–∏–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏ –ø–æ Watson"),
                    "unique_traits": [],
                    "hidden_depths": "–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –Ω–∞—É—á–Ω–æ–π –º–æ–¥–µ–ª–∏ Big Five"
                },
                "main_findings": {
                    "personality_traits": [],
                    "emotional_signature": "–ù–∞—É—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏",
                    "thinking_style": "–ê–Ω–∞–ª–∏–∑ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π"
                },
                "psychological_profile": {
                    "big_five_traits": watson_result.get("big_five_traits", {}),
                    "psychological_needs": watson_result.get("psychological_needs", {}),
                    "core_values": watson_result.get("core_values", {})
                },
                "confidence_score": watson_result.get("confidence_score", 80),
                "data_sources": {
                    "watson": "IBM Watson Personality Insights (–Ω–∞—É—á–Ω–∞—è –æ—Å–Ω–æ–≤–∞)",
                    "methodology": "Big Five –º–æ–¥–µ–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏"
                },
                "status": "watson_only"
            }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —á–µ—Ä—Ç—ã –∏–∑ Watson
            big_five = watson_result.get("big_five_traits", {})
            for trait_name, trait_data in big_five.items():
                if isinstance(trait_data, dict) and trait_data.get("percentile", 0) >= 70:
                    formatted_result["personality_core"]["unique_traits"].append(
                        f"{trait_name.title()}: {trait_data.get('description', '')}"
                    )
            
            return formatted_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Watson —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞", error=str(e))
            return watson_result
    
    async def _validate_analysis(self, synthesis_result: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return {"validation_score": 80}
    
    async def _generate_final_report(self, synthesis_result: Dict[str, Any], validation_result: Dict[str, Any], ai_results: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return self._format_quick_result(synthesis_result)
    
    def _calculate_confidence_score(self, ai_results: Dict[str, Any], validation_result: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        base_confidence = 75.0
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–∞–∂–¥—ã–π —É—Å–ø–µ—à–Ω—ã–π AI —Å–µ—Ä–≤–∏—Å
        successful_services = 0
        total_confidence = 0
        
        for service_name, service_result in ai_results.items():
            if service_result.get("status") != "failed" and "error" not in service_result:
                successful_services += 1
                service_confidence = service_result.get("confidence_score", 75)
                total_confidence += service_confidence
        
        if successful_services > 0:
            # –°—Ä–µ–¥–Ω–∏–π confidence —Å –±–æ–Ω—É—Å–æ–º –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            avg_confidence = total_confidence / successful_services
            
            # –ë–æ–Ω—É—Å –∑–∞ Watson (–Ω–∞—É—á–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è)
            if "watson" in ai_results and ai_results["watson"].get("status") == "success":
                avg_confidence += 10  # +10% –∑–∞ –Ω–∞—É—á–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é
            
            # –ë–æ–Ω—É—Å –∑–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ—Ä–≤–∏—Å–æ–≤)
            if successful_services > 1:
                avg_confidence += 5  # +5% –∑–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é
            
            return min(95.0, max(50.0, avg_confidence))
        
        return base_confidence
    
    def _detect_potential_bias(self, synthesis_result: Dict[str, Any], ai_results: Dict[str, Any]) -> List[str]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–µ–π"""
        return []
    
    def _get_methodology_used(self, ai_results: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏"""
        methodology = []
        
        if "claude" in ai_results and ai_results["claude"].get("status") != "failed":
            methodology.append("Anthropic Claude 3.5 Sonnet - –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–∏–Ω—Ç–µ–∑ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è")
        
        if "watson" in ai_results and ai_results["watson"].get("status") == "success":
            methodology.append("IBM Watson Personality Insights - –Ω–∞—É—á–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è Big Five –º–æ–¥–µ–ª–∏")
            methodology.append("IBM Research - –ø—Å–∏—Ö–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
        
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –æ–±–∞ —Å–µ—Ä–≤–∏—Å–∞
        if len([r for r in ai_results.values() if r.get("status") != "failed"]) > 1:
            methodology.append("–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –º–µ–∂–¥—É AI —Å–∏—Å—Ç–µ–º–∞–º–∏")
        
        return methodology if methodology else ["–ë–∞–∑–æ–≤—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"]
    
    async def _create_analysis_record(self, analysis_input: AnalysisInput) -> int:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return 1  # –ó–∞–≥–ª—É—à–∫–∞
    
    async def _save_analysis_result(self, analysis_id: int, result: AnalysisResult, ai_results: Dict[str, Any], synthesis_result: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        pass
    
    async def _save_analysis_error(self, analysis_id: int, service_name: str, error_message: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        pass


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–≤–∏–∂–∫–∞
analysis_engine = AnalysisEngine() 