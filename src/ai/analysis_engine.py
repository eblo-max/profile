"""
–û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤ –∏ —Å–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
"""
import asyncio
import structlog
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict

from src.ai.anthropic_client import anthropic_client
from src.ai.watson_client import OpenAIClient
from src.ai.google_client import google_gemini_client
from src.ai.cohere_client import cohere_client
from src.ai.huggingface_client import huggingface_client
from src.database.connection import get_async_session
from src.database.models import Analysis, AnalysisError
from src.config.settings import settings

logger = structlog.get_logger()


@dataclass
class AnalysisInput:
    """–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    user_id: int
    telegram_id: int
    text: Optional[str] = None
    images: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    analysis_id: int
    status: str
    confidence_score: float
    main_findings: Dict[str, Any]
    detailed_analysis: Dict[str, Any]
    psychological_profile: Dict[str, Any]
    final_report: str
    methodology: List[str]
    limitations: List[str]
    bias_warnings: List[str]
    created_at: datetime


class AnalysisEngine:
    """–û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞"""
        self.claude_client = anthropic_client
        self.openai_client = OpenAIClient()
        self.google_gemini_client = google_gemini_client
        self.cohere_client = cohere_client
        self.huggingface_client = huggingface_client
        
        self.supported_services = {
            # üöÄ –°–û–í–†–ï–ú–ï–ù–ù–´–ï AI –°–ï–†–í–ò–°–´ (2025)
            "claude": True,  # –ì–ª–∞–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å–∏–Ω—Ç–µ–∑
            "openai": self.openai_client.is_available,  # GPT-4o
            "google_gemini": google_gemini_client.is_available,  # –ó–∞–º–µ–Ω–∞ Google Cloud NL + Azure
            "cohere": cohere_client.is_available,  # –ó–∞–º–µ–Ω–∞ Lexalytics + Receptiviti
            "huggingface": huggingface_client.is_available,  # –ó–∞–º–µ–Ω–∞ AWS Rekognition
            
            # üìâ DEPRECATED –°–ï–†–í–ò–°–´ (–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            "azure": settings.azure_cognitive_key is not None,
            "google": settings.google_cloud_project_id is not None,
            "aws": settings.aws_access_key_id is not None,
            "crystal": settings.crystal_api_key is not None,
            "receptiviti": settings.receptiviti_api_key is not None,
            "lexalytics": settings.lexalytics_api_key is not None,
            "monkeylearn": settings.monkeylearn_api_key is not None
        }
        
        active_services = [name for name, active in self.supported_services.items() if active]
        logger.info("üöÄ AnalysisEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω", 
                   active_services=active_services,
                   total_services=len(active_services))
    
    async def analyze_comprehensive(self, analysis_input: AnalysisInput) -> AnalysisResult:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
        
        Args:
            analysis_input: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ –ë–î
        analysis_id = await self._create_analysis_record(analysis_input)
        
        try:
            logger.info("üîç –ù–∞—á–∏–Ω–∞—é –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", 
                       analysis_id=analysis_id,
                       user_id=analysis_input.user_id)
            
            # –≠—Ç–∞–ø 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤
            ai_results = await self._collect_ai_insights(analysis_input, analysis_id)
            
            # –≠—Ç–∞–ø 2: –°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Claude
            synthesis_result = await self._synthesize_results(ai_results, analysis_input)
            
            # –≠—Ç–∞–ø 3: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            validation_result = await self._validate_analysis(synthesis_result)
            
            # –≠—Ç–∞–ø 4: –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            final_report = await self._generate_final_report(
                synthesis_result, 
                validation_result, 
                ai_results
            )
            
            # –≠—Ç–∞–ø 5: –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            confidence_score = self._calculate_confidence_score(ai_results, validation_result)
            bias_warnings = self._detect_potential_bias(synthesis_result, ai_results)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = AnalysisResult(
                analysis_id=analysis_id,
                status="completed",
                confidence_score=confidence_score,
                main_findings=synthesis_result.get("main_findings", {}),
                detailed_analysis=synthesis_result.get("detailed_analysis", {}),
                psychological_profile=synthesis_result.get("psychological_profile", {}),
                final_report=final_report,
                methodology=self._get_methodology_used(ai_results),
                limitations=synthesis_result.get("limitations", []),
                bias_warnings=bias_warnings,
                created_at=datetime.utcnow()
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –ë–î
            await self._save_analysis_result(analysis_id, result, ai_results, synthesis_result)
            
            logger.info("‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                       analysis_id=analysis_id,
                       confidence_score=confidence_score,
                       ai_services_used=len(ai_results))
            
            return result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", 
                        analysis_id=analysis_id, 
                        error=str(e), 
                        exc_info=True)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ –≤ –ë–î
            await self._save_analysis_error(analysis_id, "comprehensive_analysis", str(e))
            
            # –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –æ—à–∏–±–∫–æ–π
            return AnalysisResult(
                analysis_id=analysis_id,
                status="failed",
                confidence_score=0.0,
                main_findings={"error": str(e)},
                detailed_analysis={},
                psychological_profile={},
                final_report=f"–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è: {str(e)}",
                methodology=[],
                limitations=["–ê–Ω–∞–ª–∏–∑ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏"],
                bias_warnings=[],
                created_at=datetime.utcnow()
            )
    
    async def quick_analyze(self, text: str, user_id: int, telegram_id: int) -> str:
        """
        üß† –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó (2025) 
        –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–æ—Ä—Ç—Ä–µ—Ç –ª–∏—á–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ AI —Å–∏—Å—Ç–µ–º—ã
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            telegram_id: Telegram ID
            
        Returns:
            –î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—Ç—Ä–µ—Ç
        """
        try:
            user_context = {
                "user_id": user_id, 
                "telegram_id": telegram_id,
                "analysis_mode": "professional_detailed",
                "output_format": "comprehensive_portrait"
            }
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã (2025)
            available_services = []
            if self.supported_services.get("claude", True):
                available_services.append("Claude 3.5 Sonnet")
            if self.supported_services.get("openai", False):
                available_services.append("OpenAI GPT-4o")
            if self.supported_services.get("cohere", False):
                available_services.append("Cohere Command-R+")
            if self.supported_services.get("huggingface", False):
                available_services.append("HuggingFace Transformers")
            
            logger.info("üß† –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –õ–ò–ß–ù–û–°–¢–ò", 
                       user_id=user_id, 
                       text_length=len(text),
                       available_services=available_services,
                       total_services=len(available_services))
            
            # === –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–´–ô –ó–ê–ü–£–°–ö –í–°–ï–• –î–û–°–¢–£–ü–ù–´–• AI –°–ï–†–í–ò–°–û–í ===
            tasks = []
            service_names = []
            
            # 1. Claude 3.5 Sonnet - –î–ï–¢–ê–õ–¨–ù–´–ô –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)
            tasks.append(self._run_detailed_claude_analysis(text, user_context))
            service_names.append("claude")
            
            # 2. OpenAI GPT-4o (–µ—Å–ª–∏ API –∫–ª—é—á –µ—Å—Ç—å)
            if self.supported_services.get("openai", False):
                tasks.append(self._run_openai_analysis(text, user_context))
                service_names.append("openai")
            
            # 3. Cohere Command-R+ (–ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑)
            if self.supported_services.get("cohere", False):
                tasks.append(self._run_cohere_analysis(text, user_context))
                service_names.append("cohere")
            
            # 4. HuggingFace Transformers (—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)
            if self.supported_services.get("huggingface", False):
                tasks.append(self._run_huggingface_analysis(text, user_context))
                service_names.append("huggingface")
            
            logger.info(f"‚ö° –ó–∞–ø—É—Å–∫–∞—é {len(tasks)} AI —Å–∏—Å—Ç–µ–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", 
                       services=service_names)
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
            ai_results_raw = await asyncio.gather(*tasks, return_exceptions=True)
            
            # === –û–ë–†–ê–ë–û–¢–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
            ai_results = {}
            successful_services = []
            
            for i, (service_name, result) in enumerate(zip(service_names, ai_results_raw)):
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ {service_name}", error=str(result))
                    ai_results[service_name] = {
                        "error": str(result), 
                        "status": "failed",
                        "service": service_name
                    }
                else:
                    ai_results[service_name] = result
                    if result.get("status") != "failed" and "error" not in result:
                        successful_services.append(service_name)
                        logger.info(f"‚úÖ {service_name.upper()} –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                                   confidence=result.get('confidence_score', 0))
            
            logger.info(f"üéØ –£—Å–ø–µ—à–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤: {len(successful_services)}/{len(tasks)}", 
                       successful=successful_services)
            
            # === –°–ò–ù–¢–ï–ó –ò –û–ë–û–ì–ê–©–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
            if len(successful_services) > 1:
                # –ú—É–ª—å—Ç–∏-AI —Å–∏–Ω—Ç–µ–∑ —á–µ—Ä–µ–∑ Claude —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                enhanced_result = await self._synthesize_detailed_multi_ai_results(ai_results, text, user_context)
                logger.info("üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–π –º—É–ª—å—Ç–∏-AI —Å–∏–Ω—Ç–µ–∑", 
                           sources=len(successful_services))
            elif "claude" in successful_services:
                # –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–∞–Ω–Ω—ã–º–∏ –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
                enhanced_result = self._enrich_detailed_claude_with_modern_ai(ai_results["claude"], ai_results)
                logger.info("‚ú® –î–µ—Ç–∞–ª—å–Ω—ã–π Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–æ–≥–∞—â–µ–Ω —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ AI –¥–∞–Ω–Ω—ã–º–∏")
            else:
                # Fallback –Ω–∞ –ª—é–±–æ–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                enhanced_result = next((r for r in ai_results.values() if r.get("status") != "failed"), {})
                logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            
            # === –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–û–ï –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï ===
            formatted_result = self._format_modern_analysis_result(
                enhanced_result, 
                successful_services,
                ai_results
            )
            
            logger.info("‚úÖ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                       user_id=user_id,
                       ai_services=len(successful_services),
                       confidence=enhanced_result.get('confidence_score', 0),
                       sections_generated=len([k for k in enhanced_result.keys() if k in [
                           "personality_core", "detailed_insights", "life_insights", 
                           "actionable_recommendations", "fascinating_details"
                       ]]))
            
            return formatted_result
            
        except Exception as e:
            logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", error=str(e), exc_info=True)
            return f"‚ö†Ô∏è **–°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**: {str(e)}\n\nüîß –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."

    async def _run_detailed_claude_analysis(self, text: str, user_context: Dict[str, Any]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –î–ï–¢–ê–õ–¨–ù–û–ì–û Claude –∞–Ω–∞–ª–∏–∑–∞ —Å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏"""
        try:
            logger.info("üß† –ó–∞–ø—É—Å–∫ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ Claude", text_length=len(text))
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            detailed_result = await self.claude_client.analyze_text(
                text=text,
                analysis_type="psychological",  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç PSYCHOLOGICAL_ANALYSIS_PROMPT
                user_context=user_context
            )
            
            # DEBUG: –õ–æ–≥–∏—Ä—É–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –æ—Ç Claude
            logger.info("üîç Claude –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç", 
                       keys=list(detailed_result.keys()) if isinstance(detailed_result, dict) else "not_dict",
                       has_error="error" in detailed_result if isinstance(detailed_result, dict) else False,
                       result_type=type(detailed_result).__name__)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–∫–∏
            if "error" in detailed_result:
                logger.error("‚ùå Claude –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É", error=detailed_result["error"])
                return self._enhance_incomplete_analysis({}, text)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if self._validate_detailed_analysis_structure(detailed_result):
                logger.info("‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–π Claude –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–µ–Ω")
                return detailed_result
            else:
                logger.warning("‚ö†Ô∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–ø–æ–ª–Ω–∞—è, –∏—Å–ø—Ä–∞–≤–ª—è–µ–º...", 
                              missing_sections=[s for s in ["personality_core", "detailed_insights", "big_five_detailed"] if s not in detailed_result])
                return self._enhance_incomplete_analysis(detailed_result, text)
                
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ Claude –∞–Ω–∞–ª–∏–∑–∞", error=str(e), exc_info=True)
            return {
                "error": str(e),
                "status": "failed",
                "service": "claude"
            }

    def _validate_detailed_analysis_structure(self, analysis_result: Dict[str, Any]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Å–µ–∫—Ü–∏–∏"""
        if "error" in analysis_result:
            return False
        
        required_sections = [
            "personality_core", 
            "detailed_insights",
            "big_five_detailed",
            "life_insights", 
            "actionable_recommendations"
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –ø–æ–ª–æ–≤–∏–Ω—ã —Å–µ–∫—Ü–∏–π
        present_sections = sum(1 for section in required_sections if section in analysis_result)
        return present_sections >= len(required_sections) // 2

    def _enhance_incomplete_analysis(self, incomplete_result: Dict[str, Any], text: str) -> Dict[str, Any]:
        """–î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–∞–∑–æ–≤—ã–º–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏"""
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –µ—Å–ª–∏ Claude –Ω–µ –≤–µ—Ä–Ω—É–ª –ø–æ–ª–Ω—É—é
        enhanced = {
            "executive_summary": incomplete_result.get("executive_summary", "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –ª–∏—á–Ω–æ—Å—Ç—å —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è–º–∏"),
            
            "personality_core": incomplete_result.get("personality_core", {
                "essence": "–õ–∏—á–Ω–æ—Å—Ç—å —Å –±–æ–≥–∞—Ç—ã–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –º–∏—Ä–æ–º –∏ –º–Ω–æ–≥–æ–≥—Ä–∞–Ω–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º–∏",
                "unique_traits": [
                    "–°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –≥–ª—É–±–æ–∫–æ–π —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏ –∏ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑—É",
                    "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –≤–æ—Å–ø—Ä–∏–∏–º—á–∏–≤–æ—Å—Ç—å –∏ —ç–º–ø–∞—Ç–∏—è",
                    "–°—Ç—Ä–µ–º–ª–µ–Ω–∏–µ –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤",
                    "–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –≤–∏–¥–µ—Ç—å –¥–µ—Ç–∞–ª–∏ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"
                ],
                "hidden_depths": "–ó–∞ –≤–Ω–µ—à–Ω–∏–º –ø—Ä–æ—è–≤–ª–µ–Ω–∏–µ–º —Å–∫—Ä—ã–≤–∞–µ—Ç—Å—è –±–æ–≥–∞—Ç—ã–π –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–∏—Ä —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –∏ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π"
            }),
            
            "detailed_insights": incomplete_result.get("detailed_insights", {
                "thinking_style": {
                    "description": "–í–¥—É–º—á–∏–≤—ã–π –∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –∫ –æ—Å–º—ã—Å–ª–µ–Ω–∏—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                    "strengths": "–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ –≥–ª—É–±–æ–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É –∏ –≤—ã—è–≤–ª–µ–Ω–∏—é —Å–≤—è–∑–µ–π",
                    "blind_spots": "–í–æ–∑–º–æ–∂–Ω–∞—è —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ —á—Ä–µ–∑–º–µ—Ä–Ω–æ–º—É –æ–±–¥—É–º—ã–≤–∞–Ω–∏—é"
                },
                "emotional_world": {
                    "current_state": "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –≤–¥—É–º—á–∏–≤–æ—Å—Ç–∏",
                    "emotional_patterns": [
                        "–ì–ª—É–±–æ–∫–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏—è",
                        "–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è–º –æ–∫—Ä—É–∂–∞—é—â–∏—Ö",
                        "–°—Ç—Ä–µ–º–ª–µ–Ω–∏–µ –∫ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –≥–∞—Ä–º–æ–Ω–∏–∏"
                    ],
                    "coping_style": "–°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å —Å–ø—Ä–∞–≤–ª—è—Ç—å—Å—è —Å–æ —Å—Ç—Ä–µ—Å—Å–æ–º —á–µ—Ä–µ–∑ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è –∏ –ø–æ–∏—Å–∫ —Å–º—ã—Å–ª–∞"
                },
                "communication_style": {
                    "style": "–í–¥—É–º—á–∏–≤—ã–π –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è —Å –≤–Ω–∏–º–∞–Ω–∏–µ–º –∫ –¥–µ—Ç–∞–ª—è–º",
                    "influence_tactics": "–í–ª–∏—è–Ω–∏–µ —á–µ—Ä–µ–∑ –ª–æ–≥–∏–∫—É, –ø—Ä–∏–º–µ—Ä—ã –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é —Å–≤—è–∑—å",
                    "conflict_approach": "–ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ –∏–∑–±–µ–≥–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤, –ø–æ–∏—Å–∫ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤"
                }
            }),
            
            "big_five_detailed": incomplete_result.get("big_five_detailed", {
                "openness": {
                    "score": 75,
                    "description": "–í—ã—Å–æ–∫–∞—è –æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å –∫ –Ω–æ–≤–æ–º—É –æ–ø—ã—Ç—É, –∏–¥–µ—è–º –∏ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è–º",
                    "life_impact": "–°–ø–æ—Å–æ–±—Å—Ç–≤—É–µ—Ç —Ç–≤–æ—Ä—á–µ—Å–∫–æ–º—É –º—ã—à–ª–µ–Ω–∏—é –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º",
                    "evidence": ["–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã –≤ —Ç–µ–∫—Å—Ç–µ", "–°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è–º"]
                },
                "conscientiousness": {
                    "score": 65,
                    "description": "–£–º–µ—Ä–µ–Ω–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å –≥–∏–±–∫–æ—Å—Ç—å—é –≤ –ø–æ–¥—Ö–æ–¥–∞—Ö",
                    "life_impact": "–ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∏ —Å–ø–æ–Ω—Ç–∞–Ω–Ω–æ—Å—Ç—å—é",
                    "evidence": ["–í–¥—É–º—á–∏–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º"]
                },
                "extraversion": {
                    "score": 55,
                    "description": "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–æ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å - –∫–æ–º—Ñ–æ—Ä—Ç –≤ –æ–±—â–µ—Å—Ç–≤–µ –∏ –Ω–∞–µ–¥–∏–Ω–µ",
                    "life_impact": "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Å–æ—Ü–∏–∞–ª—å–Ω—ã–º —Å–∏—Ç—É–∞—Ü–∏—è–º",
                    "evidence": ["–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ–º—É –≤—ã—Ä–∞–∂–µ–Ω–∏—é –º—ã—Å–ª–µ–π"]
                },
                "agreeableness": {
                    "score": 70,
                    "description": "–í—ã—Å–æ–∫–∞—è –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å—Ç—Ä–µ–º–ª–µ–Ω–∏–µ –∫ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤—É",
                    "life_impact": "–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Å—Ç—Ä–æ–∏—Ç—å –≥–∞—Ä–º–æ–Ω–∏—á–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è",
                    "evidence": ["–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º"]
                },
                "neuroticism": {
                    "score": 45,
                    "description": "–•–æ—Ä–æ—à–∞—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –∫ –Ω—é–∞–Ω—Å–∞–º",
                    "life_impact": "–£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –≥–ª—É–±–∏–Ω—ã",
                    "evidence": ["–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ —ç–º–æ—Ü–∏–π"]
                }
            }),
            
            "life_insights": incomplete_result.get("life_insights", {
                "career_strengths": [
                    "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∏ –≤–Ω–∏–º–∞–Ω–∏–µ –∫ –¥–µ—Ç–∞–ª—è–º",
                    "–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ –≥–ª—É–±–æ–∫–æ–º—É –ø–æ–Ω–∏–º–∞–Ω–∏—é —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤",
                    "–≠–º–ø–∞—Ç–∏—è –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ª—é–¥–µ–π"
                ],
                "ideal_environment": "–°—Ä–µ–¥–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –≥–ª—É–±–æ–∫–æ —Ä–∞–∑–º—ã—à–ª—è—Ç—å –∏ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏",
                "relationship_patterns": "–°—Ç—Ä–µ–º–ª–µ–Ω–∏–µ –∫ –≥–ª—É–±–æ–∫–∏–º, —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–º –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏ –≤–∑–∞–∏–º–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π",
                "growth_areas": [
                    "–†–∞–∑–≤–∏—Ç–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–∏–Ω—è—Ç–∏–∏ –±—ã—Å—Ç—Ä—ã—Ö —Ä–µ—à–µ–Ω–∏–π",
                    "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–µ–π"
                ]
            }),
            
            "actionable_recommendations": incomplete_result.get("actionable_recommendations", {
                "immediate_actions": [
                    "–í–µ–¥–∏—Ç–µ –¥–Ω–µ–≤–Ω–∏–∫ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –º—ã—Å–ª–µ–π",
                    "–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –∏–¥–µ–π –≤ —Å–∂–∞—Ç–æ–π —Ñ–æ—Ä–º–µ",
                    "–ò—â–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ —Å –±–ª–∏–∑–∫–∏–º–∏"
                ],
                "personal_development": [
                    "–†–∞–∑–≤–∏–≤–∞–π—Ç–µ –Ω–∞–≤—ã–∫–∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –≤ —É—Å–ª–æ–≤–∏—è—Ö –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏",
                    "–ò–∑—É—á–∞–π—Ç–µ —Ç–µ—Ö–Ω–∏–∫–∏ mindfulness –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ –∏–Ω—Ç—É–∏—Ü–∏–∏"
                ],
                "relationship_advice": [
                    "–î–µ–ª–∏—Ç–µ—Å—å —Å–≤–æ–∏–º–∏ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è–º–∏ —Å –ø–∞—Ä—Ç–Ω–µ—Ä–æ–º –¥–ª—è —É–≥–ª—É–±–ª–µ–Ω–∏—è –±–ª–∏–∑–æ—Å—Ç–∏",
                    "–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ –∞–∫—Ç–∏–≤–Ω–æ–µ —Å–ª—É—à–∞–Ω–∏–µ –≤ —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å —ç–º–ø–∞—Ç–∏–µ–π"
                ],
                "career_guidance": [
                    "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å—Ñ–µ—Ä—ã, –≥–¥–µ –≤–∞–∂–µ–Ω –∞–Ω–∞–ª–∏–∑ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ª—é–¥–µ–π",
                    "–†–∞–∑–≤–∏–≤–∞–π—Ç–µ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –≤ –æ–±–ª–∞—Å—Ç—è—Ö, —Ç—Ä–µ–±—É—é—â–∏—Ö –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è"
                ]
            }),
            
            "fascinating_details": incomplete_result.get("fascinating_details", {
                "psychological_archetype": "–ú—É–¥—Ä–µ—Ü-–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å - —Å–æ—á–µ—Ç–∞–Ω–∏–µ –≥–ª—É–±–∏–Ω—ã –º—ã—Å–ª–∏ —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º",
                "hidden_talents": [
                    "–°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –≤–∏–¥–µ—Ç—å —Å–∫—Ä—ã—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –ª—é–¥–µ–π",
                    "–¢–∞–ª–∞–Ω—Ç –∫ —Å–æ–∑–¥–∞–Ω–∏—é –∞—Ç–º–æ—Å—Ñ–µ—Ä—ã –¥–æ–≤–µ—Ä–∏—è –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è",
                    "–ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –¥—Ä—É–≥–∏—Ö"
                ],
                "core_values": [
                    "–ü–æ–¥–ª–∏–Ω–Ω–æ—Å—Ç—å –∏ –∏—Å–∫—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö",
                    "–ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ —Å–º—ã—Å–ª",
                    "–ì–∞—Ä–º–æ–Ω–∏—è –º–µ–∂–¥—É –º—ã—Å–ª—å—é –∏ —á—É–≤—Å—Ç–≤–æ–º"
                ],
                "fear_patterns": [
                    "–ë–æ—è–∑–Ω—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω–æ—Å—Ç–∏ –∏ –Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏—è - —Ä–∞–±–æ—Ç–∞ —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –µ–¥–∏–Ω–æ–º—ã—à–ª–µ–Ω–Ω–∏–∫–æ–≤",
                    "–¢—Ä–µ–≤–æ–≥–∞ –ø–æ –ø–æ–≤–æ–¥—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ —Ä–µ—à–µ–Ω–∏–π - —Ä–∞–∑–≤–∏—Ç–∏–µ –¥–æ–≤–µ—Ä–∏—è –∫ –∏–Ω—Ç—É–∏—Ü–∏–∏"
                ]
            }),
            
            "confidence_score": incomplete_result.get("confidence_score", 78),
            "status": "enhanced_analysis"
        }
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º)
        for key, value in incomplete_result.items():
            if key not in enhanced or (value and not enhanced[key]):
                enhanced[key] = value
        
        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –¥–æ–ø–æ–ª–Ω–µ–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º–∏")
        return enhanced

    async def _synthesize_detailed_multi_ai_results(self, ai_results: Dict[str, Any], text: str, user_context: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º—É–ª—å—Ç–∏-AI —Å–∏–Ω—Ç–µ–∑–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ—Å—Ç–∏
            synthesis_context = {
                "ai_results": ai_results,
                "successful_services": [name for name, result in ai_results.items() if result.get("status") != "failed"],
                "text_length": len(text),
                "user_context": user_context,
                "synthesis_mode": "detailed_professional",
                "preserve_all_insights": True
            }
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ —á–µ—Ä–µ–∑ Claude
            synthesis_result = await self.claude_client.analyze_text(
                text=text,
                analysis_type="multi_ai_synthesis",  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç MULTI_AI_SYNTHESIS_PROMPT
                user_context=synthesis_context
            )
            
            # –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç –≤—Å–µ—Ö —É—Å–ø–µ—à–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
            enriched_result = self._enrich_detailed_claude_with_modern_ai(synthesis_result, ai_results)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ—Å—Ç—å
            if not self._validate_detailed_analysis_structure(enriched_result):
                enriched_result = self._enhance_incomplete_analysis(enriched_result, text)
            
            return enriched_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –º—É–ª—å—Ç–∏-AI —Å–∏–Ω—Ç–µ–∑–∞", error=str(e))
            # Fallback –Ω–∞ –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return ai_results.get("claude", {"error": str(e), "status": "synthesis_failed"})

    def _enrich_detailed_claude_with_modern_ai(self, claude_result: Dict[str, Any], ai_results: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç –≤—Å–µ—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            enriched = claude_result.copy()
            
            # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –Ω–∞–ª–∏—á–∏–µ –±–∞–∑–æ–≤—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
            if "psychological_profile" not in enriched:
                enriched["psychological_profile"] = {}
            if "data_sources" not in enriched:
                enriched["data_sources"] = {}
            
            confidence_scores = []
            
            # === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø OPENAI –î–ê–ù–ù–´–• ===
            openai_data = ai_results.get("openai", {})
            if openai_data.get("status") == "success":
                # –î–µ—Ç–∞–ª—å–Ω—ã–µ Big Five –æ—Ç OpenAI (–Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ)
                if "big_five_traits" in openai_data:
                    if "big_five_detailed" not in enriched:
                        enriched["big_five_detailed"] = {}
                    
                    # –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º OpenAI –¥–∞–Ω–Ω—ã–µ –≤ –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                    for trait, score in openai_data["big_five_traits"].items():
                        if trait not in enriched["big_five_detailed"]:
                            enriched["big_five_detailed"][trait] = {}
                        enriched["big_five_detailed"][trait]["openai_score"] = score
                        enriched["big_five_detailed"][trait]["scientific_validation"] = True
                
                # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç OpenAI
                if "emotions" in openai_data:
                    enriched["psychological_profile"]["openai_emotions"] = openai_data["emotions"]
                    enriched["psychological_profile"]["dominant_emotion_ai"] = openai_data.get("dominant_emotion", "neutral")
                
                enriched["data_sources"]["openai"] = "OpenAI GPT-4o –Ω–∞—É—á–Ω–æ-–æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
                confidence_scores.append(openai_data.get("confidence_score", 85))
            
            # === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø COHERE –î–ê–ù–ù–´–• ===
            cohere_data = ai_results.get("cohere", {})
            if cohere_data.get("status") == "success":
                # –ü—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã
                if "linguistic_insights" in cohere_data:
                    enriched["psychological_profile"]["psycholinguistics"] = cohere_data["linguistic_insights"]
                
                enriched["data_sources"]["cohere"] = "Cohere Command-R+ –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"
                confidence_scores.append(cohere_data.get("confidence_score", 80))
            
            # === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø HUGGINGFACE –î–ê–ù–ù–´–• ===
            huggingface_data = ai_results.get("huggingface", {})
            if huggingface_data.get("status") == "success":
                # Transformer —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                if "emotion_insights" in huggingface_data:
                    enriched["psychological_profile"]["transformer_emotions"] = huggingface_data["emotion_insights"]
                
                enriched["data_sources"]["huggingface"] = "HuggingFace —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏"
                confidence_scores.append(huggingface_data.get("confidence_score", 75))
            
            # === –†–ê–°–ß–ï–¢ –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–û–ì–û CONFIDENCE ===
            claude_confidence = claude_result.get("confidence_score", 75)
            confidence_scores.append(claude_confidence)
            
            if len(confidence_scores) > 1:
                avg_confidence = sum(confidence_scores) / len(confidence_scores)
                multi_ai_bonus = min(15, (len(confidence_scores) - 1) * 4)  # –ë–æ–ª—å—à–∏–π –±–æ–Ω—É—Å –∑–∞ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                combined_confidence = min(95, avg_confidence + multi_ai_bonus)
                enriched["confidence_score"] = round(combined_confidence, 1)
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –¥–µ—Ç–∞–ª—å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ
            enriched["detailed_ai_integration"] = {
                "ai_services_count": len(confidence_scores),
                "data_fusion": True,
                "professional_analysis": True,
                "detailed_sections": len([k for k in enriched.keys() if k in [
                    "personality_core", "detailed_insights", "life_insights", 
                    "actionable_recommendations", "fascinating_details"
                ]]),
                "analysis_year": 2025
            }
            
            logger.info("‚ú® –î–µ—Ç–∞–ª—å–Ω—ã–π Claude –∞–Ω–∞–ª–∏–∑ –æ–±–æ–≥–∞—â–µ–Ω —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ AI –¥–∞–Ω–Ω—ã–º–∏", 
                       sources=len(confidence_scores),
                       final_confidence=enriched.get("confidence_score"),
                       detailed_sections=enriched["detailed_ai_integration"]["detailed_sections"])
            
            return enriched
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return claude_result
    
    async def _collect_ai_insights(self, analysis_input: AnalysisInput, analysis_id: int) -> Dict[str, Any]:
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        results = {}
        tasks = []
        
        if analysis_input.text:
            # Claude –∞–Ω–∞–ª–∏–∑ (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)
            tasks.append(self._run_claude_analysis(analysis_input.text, analysis_input.metadata))
            
            # OpenAI –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            if self.supported_services["openai"]:
                tasks.append(self._run_openai_analysis(analysis_input.text, analysis_input.metadata))
            
            logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞", 
                       services_count=len(tasks),
                       analysis_id=analysis_id)
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
            ai_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            service_names = ["claude"]
            if self.supported_services["openai"]:
                service_names.append("openai")
            
            for i, result in enumerate(ai_results):
                service_name = service_names[i]
                
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ {service_name} –∞–Ω–∞–ª–∏–∑–∞", 
                               error=str(result), 
                               analysis_id=analysis_id)
                    results[service_name] = {
                        "error": str(result),
                        "status": "failed",
                        "service": service_name
                    }
                else:
                    results[service_name] = result
                    logger.info(f"‚úÖ {service_name.title()} –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                               confidence=result.get('confidence_score', 0),
                               analysis_id=analysis_id)
        
        return results
    
    async def _run_claude_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ Claude –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            return await self.claude_client.analyze_text(
                text=text,
                analysis_type="comprehensive_psychological",
                user_context=metadata
            )
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ Claude –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed",
                "service": "claude"
            }
    
    async def _run_openai_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ OpenAI –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö OpenAI –∞–Ω–∞–ª–∏–∑–æ–≤
            personality_task = self.openai_client.analyze_personality(text)
            emotions_task = self.openai_client.analyze_emotions(text)
            sentiment_task = self.openai_client.analyze_sentiment(text)
            
            personality_result, emotions_result, sentiment_result = await asyncio.gather(
                personality_task, emotions_task, sentiment_task, return_exceptions=True
            )
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            combined_result = {
                "status": "success",
                "service": "openai",
                "big_five_traits": personality_result.get("big_five", {}) if not isinstance(personality_result, Exception) else {},
                "mbti": personality_result.get("mbti", "Unknown") if not isinstance(personality_result, Exception) else "Unknown",
                "disc": personality_result.get("disc", "Unknown") if not isinstance(personality_result, Exception) else "Unknown",
                "emotions": emotions_result.get("emotions", {}) if not isinstance(emotions_result, Exception) else {},
                "dominant_emotion": emotions_result.get("dominant_emotion", "neutral") if not isinstance(emotions_result, Exception) else "neutral",
                "sentiment": sentiment_result.get("sentiment", "neutral") if not isinstance(sentiment_result, Exception) else "neutral",
                "sentiment_polarity": sentiment_result.get("polarity", 0.0) if not isinstance(sentiment_result, Exception) else 0.0,
                "confidence_score": 85  # OpenAI –≤—ã—Å–æ–∫–∏–π confidence
            }
            
            return combined_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ OpenAI –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed", 
                "service": "openai"
            }
    
    async def _run_cohere_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ Cohere Command-R+ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö Cohere –∞–Ω–∞–ª–∏–∑–æ–≤
            psycholinguistics_task = self.cohere_client.analyze_psycholinguistics(text)
            sentiment_task = self.cohere_client.analyze_advanced_sentiment(text)
            behavioral_task = self.cohere_client.analyze_behavioral_patterns(text)
            
            psycholinguistics_result, sentiment_result, behavioral_result = await asyncio.gather(
                psycholinguistics_task, sentiment_task, behavioral_task, return_exceptions=True
            )
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Cohere
            combined_result = {
                "status": "success",
                "service": "cohere",
                "psycholinguistics": psycholinguistics_result if not isinstance(psycholinguistics_result, Exception) else {},
                "advanced_sentiment": sentiment_result if not isinstance(sentiment_result, Exception) else {},
                "behavioral_patterns": behavioral_result if not isinstance(behavioral_result, Exception) else {},
                "confidence_score": 80  # Cohere —Ö–æ—Ä–æ—à–∏–π confidence –¥–ª—è –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏–∫–∏
            }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤
            if not isinstance(psycholinguistics_result, Exception):
                combined_result["linguistic_insights"] = {
                    "cognitive_style": psycholinguistics_result.get("cognitive_style", {}),
                    "communication_psychology": psycholinguistics_result.get("communication_psychology", {}),
                    "thought_process": psycholinguistics_result.get("thought_process_indicators", {})
                }
            
            if not isinstance(sentiment_result, Exception):
                combined_result["emotional_insights"] = {
                    "dimensional_analysis": sentiment_result.get("dimensional_analysis", {}),
                    "psychological_sentiment": sentiment_result.get("psychological_sentiment_markers", {}),
                    "social_emotional": sentiment_result.get("social_emotional_context", {})
                }
            
            return combined_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ Cohere –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed",
                "service": "cohere"
            }
    
    async def _run_huggingface_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ HuggingFace Transformers –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö HuggingFace –∞–Ω–∞–ª–∏–∑–æ–≤
            emotions_task = self.huggingface_client.analyze_emotions_transformers(text)
            personality_task = self.huggingface_client.analyze_personality_transformers(text)
            mental_health_task = self.huggingface_client.analyze_mental_health_indicators(text)
            
            emotions_result, personality_result, mental_health_result = await asyncio.gather(
                emotions_task, personality_task, mental_health_task, return_exceptions=True
            )
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ HuggingFace
            combined_result = {
                "status": "success",
                "service": "huggingface",
                "transformer_emotions": emotions_result if not isinstance(emotions_result, Exception) else {},
                "transformer_personality": personality_result if not isinstance(personality_result, Exception) else {},
                "mental_health_analysis": mental_health_result if not isinstance(mental_health_result, Exception) else {},
                "confidence_score": 75  # HuggingFace —Å—Ä–µ–¥–Ω–∏–π confidence (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏)
            }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤
            if not isinstance(emotions_result, Exception):
                combined_result["emotion_insights"] = {
                    "transformer_emotions": emotions_result.get("transformer_emotions", {}),
                    "emotional_profile": emotions_result.get("emotional_profile", {}),
                    "psychological_insights": emotions_result.get("psychological_insights", {})
                }
            
            if not isinstance(mental_health_result, Exception):
                combined_result["wellbeing_insights"] = {
                    "stress_indicators": mental_health_result.get("stress_indicators", {}),
                    "resilience_factors": mental_health_result.get("resilience_factors", {}),
                    "psychological_wellbeing": mental_health_result.get("psychological_wellbeing", {})
                }
            
            return combined_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ HuggingFace –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed",
                "service": "huggingface"
            }
    
    async def _synthesize_results(self, ai_results: Dict[str, Any], analysis_input: AnalysisInput) -> Dict[str, Any]:
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Claude —Å —É—á–µ—Ç–æ–º –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            logger.info("üîÑ –°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç AI —Å–µ—Ä–≤–∏—Å–æ–≤", 
                       services_available=list(ai_results.keys()))
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ–∑
            if len(ai_results) > 1 and "openai" in ai_results and "claude" in ai_results:
                # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ —á–µ—Ä–µ–∑ Claude
                synthesis_context = {
                    "ai_results": ai_results,
                    "services_used": list(ai_results.keys()),
                    "analysis_input": analysis_input.metadata
                }
                
                synthesis_result = await self.claude_client.analyze_text(
                    text=analysis_input.text,
                    analysis_type="synthesis",
                    user_context=synthesis_context
                )
                
                # –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞–Ω–Ω—ã–º–∏ OpenAI
                if "openai" in ai_results and ai_results["openai"].get("status") == "success":
                    synthesis_result = self._enrich_with_openai_data(synthesis_result, ai_results["openai"])
                
                logger.info("‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                           confidence=synthesis_result.get('confidence_score', 0))
                
                return synthesis_result
            
            # –ï—Å–ª–∏ OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            elif "claude" in ai_results:
                logger.info("üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return ai_results["claude"]
            
            # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ OpenAI –¥–æ—Å—Ç—É–ø–µ–Ω
            elif "openai" in ai_results:
                logger.info("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ OpenAI —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return self._format_openai_only_result(ai_results["openai"])
            
            else:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")
                return {"error": "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞", "status": "no_results"}
                
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", error=str(e), exc_info=True)
            # Fallback –Ω–∞ Claude –µ—Å–ª–∏ –µ—Å—Ç—å
            return ai_results.get("claude", {"error": str(e), "status": "synthesis_failed"})
    
    def _enrich_with_openai_data(self, claude_result: Dict[str, Any], openai_result: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ Claude –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç OpenAI"""
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ OpenAI –≤ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if "psychological_profile" not in claude_result:
                claude_result["psychological_profile"] = {}
            
            # OpenAI Big Five –¥–∞–Ω–Ω—ã–µ
            openai_big_five = openai_result.get("big_five_traits", {})
            if openai_big_five:
                claude_result["psychological_profile"]["openai_big_five"] = openai_big_five
                claude_result["psychological_profile"]["scientific_validation"] = True
            
            # OpenAI —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            if "emotions" in openai_result:
                claude_result["psychological_profile"]["emotional_analysis"] = {
                    "emotions": openai_result["emotions"],
                    "dominant_emotion": openai_result.get("dominant_emotion", "neutral"),
                    "emotional_intensity": openai_result.get("emotional_intensity", 0.5)
                }
            
            # OpenAI –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
            if "sentiment" in openai_result:
                claude_result["psychological_profile"]["sentiment_analysis"] = {
                    "sentiment": openai_result["sentiment"],
                    "polarity": openai_result.get("sentiment_polarity", 0.0),
                    "confidence": openai_result.get("sentiment_confidence", 0.8)
                }
            
            # MBTI –∏ DISC –æ—Ç OpenAI
            if "mbti" in openai_result:
                claude_result["psychological_profile"]["mbti_type"] = openai_result["mbti"]
            if "disc" in openai_result:
                claude_result["psychological_profile"]["disc_profile"] = openai_result["disc"]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º confidence score (—Å—Ä–µ–¥–Ω–∏–π –º–µ–∂–¥—É Claude –∏ OpenAI)
            openai_confidence = openai_result.get("confidence_score", 0)
            claude_confidence = claude_result.get("confidence_score", 0)
            
            if openai_confidence > 0 and claude_confidence > 0:
                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ: —Ä–∞–≤–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è Claude –∏ OpenAI
                combined_confidence = (openai_confidence * 0.5 + claude_confidence * 0.5)
                claude_result["confidence_score"] = round(combined_confidence, 1)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
            claude_result["data_sources"] = {
                "claude": "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–∏–Ω—Ç–µ–∑ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è",
                "openai": "–ú–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ GPT-4o (Big Five, —ç–º–æ—Ü–∏–∏, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è)",
                "synthesis_method": "–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"
            }
            
            logger.info("‚úÖ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–æ–≥–∞—â–µ–Ω –¥–∞–Ω–Ω—ã–º–∏ OpenAI")
            return claude_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è Watson –¥–∞–Ω–Ω—ã–º–∏", error=str(e))
            return claude_result
    
    def _format_openai_only_result(self, openai_result: Dict[str, Any]) -> Dict[str, Any]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç–æ–ª—å–∫–æ –æ—Ç OpenAI –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OpenAI –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç –ø–æ—Ö–æ–∂–∏–π –Ω–∞ Claude
            formatted_result = {
                "analysis_type": "openai_personality",
                "hook_summary": "–ú–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ OpenAI GPT-4o",
                "personality_core": {
                    "essence": f"MBTI: {openai_result.get('mbti', 'Unknown')}, DISC: {openai_result.get('disc', 'Unknown')}",
                    "unique_traits": [],
                    "hidden_depths": "–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ Big Five + —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å"
                },
                "main_findings": {
                    "personality_traits": [],
                    "emotional_signature": f"–î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è: {openai_result.get('dominant_emotion', 'neutral')}",
                    "thinking_style": f"–ù–∞—Å—Ç—Ä–æ–π: {openai_result.get('sentiment', 'neutral')}"
                },
                "psychological_profile": {
                    "big_five_traits": openai_result.get("big_five_traits", {}),
                    "emotional_analysis": openai_result.get("emotions", {}),
                    "sentiment_analysis": {
                        "sentiment": openai_result.get("sentiment", "neutral"),
                        "polarity": openai_result.get("sentiment_polarity", 0.0)
                    }
                },
                "confidence_score": openai_result.get("confidence_score", 85),
                "data_sources": {
                    "openai": "OpenAI GPT-4o (Big Five, —ç–º–æ—Ü–∏–∏, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è)",
                    "methodology": "–ú–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"
                },
                "status": "openai_only"
            }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —á–µ—Ä—Ç—ã –∏–∑ OpenAI Big Five
            big_five = openai_result.get("big_five_traits", {})
            for trait_name, trait_score in big_five.items():
                if isinstance(trait_score, (int, float)) and trait_score >= 70:
                    formatted_result["personality_core"]["unique_traits"].append(
                        f"{trait_name.title()}: {trait_score}% (–≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å)"
                    )
            
            return formatted_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è OpenAI —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞", error=str(e))
            return openai_result
    
    async def _validate_analysis(self, synthesis_result: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return {"validation_score": 80}
    
    async def _generate_final_report(self, synthesis_result: Dict[str, Any], validation_result: Dict[str, Any], ai_results: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return self._format_quick_result(synthesis_result)
    
    def _calculate_confidence_score(self, ai_results: Dict[str, Any], validation_result: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        base_confidence = 75.0
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–∞–∂–¥—ã–π —É—Å–ø–µ—à–Ω—ã–π AI —Å–µ—Ä–≤–∏—Å
        successful_services = 0
        total_confidence = 0
        
        for service_name, service_result in ai_results.items():
            if service_result.get("status") != "failed" and "error" not in service_result:
                successful_services += 1
                service_confidence = service_result.get("confidence_score", 75)
                total_confidence += service_confidence
        
        if successful_services > 0:
            # –°—Ä–µ–¥–Ω–∏–π confidence —Å –±–æ–Ω—É—Å–æ–º –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            avg_confidence = total_confidence / successful_services
            
            # –ë–æ–Ω—É—Å –∑–∞ OpenAI (–º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑)
            if "openai" in ai_results and ai_results["openai"].get("status") == "success":
                avg_confidence += 8  # +8% –∑–∞ –º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            
            # –ë–æ–Ω—É—Å –∑–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ—Ä–≤–∏—Å–æ–≤)
            if successful_services > 1:
                avg_confidence += 5  # +5% –∑–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é
            
            return min(95.0, max(50.0, avg_confidence))
        
        return base_confidence
    
    def _detect_potential_bias(self, synthesis_result: Dict[str, Any], ai_results: Dict[str, Any]) -> List[str]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–µ–π"""
        return []
    
    def _get_methodology_used(self, ai_results: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏"""
        methodology = []
        
        if "claude" in ai_results and ai_results["claude"].get("status") != "failed":
            methodology.append("Anthropic Claude 3.5 Sonnet - –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–∏–Ω—Ç–µ–∑ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è")
        
        if "openai" in ai_results and ai_results["openai"].get("status") == "success":
            methodology.append("OpenAI GPT-4o - –º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (Big Five + —ç–º–æ—Ü–∏–∏ + –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è)")
            methodology.append("IBM Research - –ø—Å–∏—Ö–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
        
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –æ–±–∞ —Å–µ—Ä–≤–∏—Å–∞
        if len([r for r in ai_results.values() if r.get("status") != "failed"]) > 1:
            methodology.append("–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –º–µ–∂–¥—É AI —Å–∏—Å—Ç–µ–º–∞–º–∏")
        
        return methodology if methodology else ["–ë–∞–∑–æ–≤—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"]
    
    async def _create_analysis_record(self, analysis_input: AnalysisInput) -> int:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return 1  # –ó–∞–≥–ª—É—à–∫–∞
    
    async def _save_analysis_result(self, analysis_id: int, result: AnalysisResult, ai_results: Dict[str, Any], synthesis_result: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        pass
    
    async def _save_analysis_error(self, analysis_id: int, service_name: str, error_message: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        pass
    
    def _format_modern_analysis_result(self, analysis_result: Dict[str, Any], successful_services: List[str], ai_results: Dict[str, Any]) -> str:
        """–ù–ê–£–ß–ù–û–ï —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –ø—Å–∏—Ö–æ–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –ª–∏—á–Ω–æ—Å—Ç–∏"""
        
        if "error" in analysis_result or not analysis_result:
            return f"‚ö†Ô∏è **–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**: {analysis_result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞—É—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        scientific_metadata = analysis_result.get("scientific_metadata", {})
        comprehensive_analysis = analysis_result.get("comprehensive_personality_analysis", {})
        big_five_profile = analysis_result.get("big_five_scientific_profile", {})
        emotional_intelligence = analysis_result.get("emotional_intelligence_breakdown", {})
        cognitive_patterns = analysis_result.get("cognitive_behavioral_patterns", {})
        interpersonal_psychology = analysis_result.get("interpersonal_psychology", {})
        professional_profile = analysis_result.get("professional_psychological_profile", {})
        romantic_analysis = analysis_result.get("romantic_relationship_analysis", {})
        risk_assessment = analysis_result.get("risk_assessment_and_warnings", {})
        compatibility_matrix = analysis_result.get("compatibility_matrix", {})
        long_term_forecast = analysis_result.get("long_term_development_forecast", {})
        scientific_validation = analysis_result.get("scientific_validation", {})
        actionable_insights = analysis_result.get("actionable_insights_and_recommendations", {})
        
        confidence = analysis_result.get("confidence_score", 85)
        
        # === –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –ù–ê–£–ß–ù–û–ì–û –ü–û–†–¢–†–ï–¢–ê ===
        result = "# üìä –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ü–°–ò–•–û–ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ô –ü–û–†–¢–†–ï–¢ –õ–ò–ß–ù–û–°–¢–ò\n\n"
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        result += f"**–û–±—ä–µ–∫—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è:** {scientific_metadata.get('analysis_subject', '–ê–Ω–æ–Ω–∏–º–Ω—ã–π —Å—É–±—ä–µ–∫—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è')}\n"
        result += f"**–û–±—ä–µ–º –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö:** {scientific_metadata.get('data_volume', 'N/A –ª–µ–∫—Å–∏—á–µ—Å–∫–∏—Ö –µ–¥–∏–Ω–∏—Ü')}\n"
        result += f"**–ú–µ—Ç–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞:** {', '.join(scientific_metadata.get('analysis_methods', ['–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ AI —Å–∏—Å—Ç–µ–º—ã']))}\n"
        result += f"**–ò–Ω–¥–µ–∫—Å –Ω–∞—É—á–Ω–æ–π –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏:** {scientific_metadata.get('scientific_validity_index', f'{confidence}%')} (–≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏)\n"
        result += f"**–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Ä–µ–¥–∫–æ—Å—Ç—å:** {scientific_metadata.get('psychological_rarity', '–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ—Ç–∏–ø')}\n\n"
        result += "---\n\n"
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏
        if comprehensive_analysis:
            psychological_type = comprehensive_analysis.get("dominant_psychological_type", "")
            analytical_score = comprehensive_analysis.get("analytical_thinking_score", "")
            
            result += f"–ü–µ—Ä–µ–¥–æ –º–Ω–æ–π —Ä–∞–∑–≤–µ—Ä–Ω—É–ª–∞—Å—å –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∏–Ω–∞ {psychological_type}. "
            
            if analytical_score:
                result += f"–ê–Ω–∞–ª–∏–∑ —Ä–µ—á–µ–≤—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É IBM Watson Personality Insights –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç {analytical_score}. "
            
            cognitive_style = comprehensive_analysis.get("cognitive_processing_style", {})
            if cognitive_style:
                abstract_ratio = cognitive_style.get("abstract_vs_concrete_ratio", "")
                if abstract_ratio:
                    result += f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø–æ–Ω—è—Ç–∏–π —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {abstract_ratio}, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø–æ–ø—É–ª—è—Ü–∏–æ–Ω–Ω—É—é –Ω–æ—Ä–º—É. "
                
                conceptual_level = cognitive_style.get("conceptual_thinking_level", "")
                if conceptual_level:
                    result += f"–£—Ä–æ–≤–µ–Ω—å –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è: {conceptual_level}. "
            
            lexical_analysis = comprehensive_analysis.get("lexical_analysis_insights", {})
            if lexical_analysis:
                complexity = lexical_analysis.get("complexity_indicators", "")
                if complexity:
                    result += f"–õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤—ã—è–≤–ª—è–µ—Ç {complexity}. "
                
                psychological_markers = lexical_analysis.get("psychological_markers", "")
                if psychological_markers:
                    result += f"–í —Ä–µ—á–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç {psychological_markers}. "
            
            result += "\n\n"
        
        # Big Five –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        if big_five_profile:
            result += "## üß¨ –ê–ù–ê–õ–ò–ó –õ–ò–ß–ù–û–°–¢–ò –ü–û –ú–û–î–ï–õ–ò \"–ë–û–õ–¨–®–ê–Ø –ü–Ø–¢–ï–†–ö–ê\"\n\n"
            
            traits_analysis = {
                "openness_to_experience": ("–û–¢–ö–†–´–¢–û–°–¢–¨ –ö –û–ü–´–¢–£", "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å"),
                "conscientiousness": ("–î–û–ë–†–û–°–û–í–ï–°–¢–ù–û–°–¢–¨", "–û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏ —Ü–µ–ª–µ—É—Å—Ç—Ä–µ–º–ª–µ–Ω–Ω–æ—Å—Ç—å"),
                "extraversion": ("–≠–ö–°–¢–†–ê–í–ï–†–°–ò–Ø", "–°–æ—Ü–∏–∞–ª—å–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è –∏ –æ–±—â–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"),
                "agreeableness": ("–î–û–ë–†–û–ñ–ï–õ–ê–¢–ï–õ–¨–ù–û–°–¢–¨", "–ö–æ–æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –¥–æ–≤–µ—Ä–∏–µ"),
                "neuroticism": ("–ù–ï–ô–†–û–¢–ò–ó–ú", "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (–æ–±—Ä–∞—Ç–Ω–∞—è —à–∫–∞–ª–∞)")
            }
            
            for trait_key, (trait_name, trait_description) in traits_analysis.items():
                trait_data = big_five_profile.get(trait_key, {})
                if trait_data:
                    score = trait_data.get("score", "N/A")
                    percentile = trait_data.get("population_percentile", "")
                    markers = trait_data.get("cognitive_markers", "")
                    
                    result += f"**{trait_name}** ({trait_description}): {score}\n"
                    if percentile:
                        result += f"*–ü–æ–ø—É–ª—è—Ü–∏–æ–Ω–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è:* {percentile}\n"
                    if markers:
                        result += f"*–ú–∞—Ä–∫–µ—Ä—ã –≤ —Ç–µ–∫—Å—Ç–µ:* {markers}\n"
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–æ–ª—è
                    if trait_key == "conscientiousness":
                        perfectionism = trait_data.get("perfectionism_index", "")
                        if perfectionism:
                            result += f"*–¢–∏–ø –ø–µ—Ä—Ñ–µ–∫—Ü–∏–æ–Ω–∏–∑–º–∞:* {perfectionism}\n"
                        anancast = trait_data.get("anancast_tendencies", "")
                        if anancast:
                            result += f"*–ê–Ω–∞–Ω–∫–∞—Å—Ç–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏:* {anancast}\n"
                    
                    elif trait_key == "extraversion":
                        social_type = trait_data.get("social_energy_type", "")
                        if social_type:
                            result += f"*–¢–∏–ø —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏:* {social_type}\n"
                        communication = trait_data.get("communication_preference", "")
                        if communication:
                            result += f"*–ö–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è:* {communication}\n"
                    
                    result += "\n"
        
        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç
        if emotional_intelligence:
            result += "## üí≠ –ê–ù–ê–õ–ò–ó –≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–û–ì–û –ò–ù–¢–ï–õ–õ–ï–ö–¢–ê\n\n"
            
            ei_components = {
                "self_awareness": "–°–∞–º–æ—Å–æ–∑–Ω–∞–Ω–∏–µ",
                "self_regulation": "–°–∞–º–æ—Ä–µ–≥—É–ª—è—Ü–∏—è", 
                "social_awareness": "–°–æ—Ü–∏–∞–ª—å–Ω–∞—è –æ—Å–≤–µ–¥–æ–º–ª–µ–Ω–Ω–æ—Å—Ç—å",
                "relationship_management": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏"
            }
            
            for component_key, component_name in ei_components.items():
                score = emotional_intelligence.get(component_key, "")
                if score:
                    result += f"**{component_name}:** {score}\n"
            
            processing_speed = emotional_intelligence.get("emotional_processing_speed", "")
            if processing_speed:
                result += f"**–°–∫–æ—Ä–æ—Å—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:** {processing_speed}\n"
            
            complexity_tolerance = emotional_intelligence.get("emotional_complexity_tolerance", "")
            if complexity_tolerance:
                result += f"**–¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:** {complexity_tolerance}\n"
            
            result += "\n"
        
        # –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ-–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if cognitive_patterns:
            result += "## üéØ –ö–û–ì–ù–ò–¢–ò–í–ù–û-–ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–ê–¢–¢–ï–†–ù–´\n\n"
            
            decision_making = cognitive_patterns.get("decision_making_style", {})
            if decision_making:
                result += "**–°—Ç–∏–ª—å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π:**\n"
                for key, value in decision_making.items():
                    if value:
                        key_readable = key.replace("_", " ").title()
                        result += f"‚Ä¢ {key_readable}: {value}\n"
                result += "\n"
            
            problem_solving = cognitive_patterns.get("problem_solving_approach", {})
            if problem_solving:
                result += "**–ü–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º:**\n"
                for key, value in problem_solving.items():
                    if value:
                        key_readable = key.replace("_", " ").title()
                        result += f"‚Ä¢ {key_readable}: {value}\n"
                result += "\n"
        
        # –ú–µ–∂–ª–∏—á–Ω–æ—Å—Ç–Ω–∞—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è
        if interpersonal_psychology:
            result += "## üí´ –ú–ï–ñ–õ–ò–ß–ù–û–°–¢–ù–ê–Ø –ü–°–ò–•–û–õ–û–ì–ò–Ø\n\n"
            
            attachment = interpersonal_psychology.get("attachment_style", "")
            if attachment:
                result += f"**–°—Ç–∏–ª—å –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏:** {attachment}\n"
            
            intimacy_pattern = interpersonal_psychology.get("intimacy_formation_pattern", "")
            if intimacy_pattern:
                result += f"**–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –±–ª–∏–∑–æ—Å—Ç–∏:** {intimacy_pattern}\n"
            
            boundaries = interpersonal_psychology.get("boundary_setting_ability", "")
            if boundaries:
                result += f"**–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü:** {boundaries}\n"
            
            conflict_tolerance = interpersonal_psychology.get("conflict_tolerance", "")
            if conflict_tolerance:
                result += f"**–¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞–º:** {conflict_tolerance}\n"
            
            result += "\n"
        
        # –†–æ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è
        if romantic_analysis:
            result += "## üíï –ê–ù–ê–õ–ò–ó –†–û–ú–ê–ù–¢–ò–ß–ï–°–ö–ò–• –û–¢–ù–û–®–ï–ù–ò–ô\n\n"
            
            attachment_romance = romantic_analysis.get("attachment_in_romance", "")
            if attachment_romance:
                result += f"**–ü—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å –≤ —Ä–æ–º–∞–Ω—Ç–∏–∫–µ:** {attachment_romance}\n"
            
            love_languages = romantic_analysis.get("love_language_preferences", "")
            if love_languages:
                result += f"**–Ø–∑—ã–∫–∏ –ª—é–±–≤–∏:** {love_languages}\n"
            
            intimacy_pace = romantic_analysis.get("intimacy_development_pace", "")
            if intimacy_pace:
                result += f"**–¢–µ–º–ø —Ä–∞–∑–≤–∏—Ç–∏—è –±–ª–∏–∑–æ—Å—Ç–∏:** {intimacy_pace}\n"
            
            conflict_resolution = romantic_analysis.get("conflict_resolution_in_relationships", "")
            if conflict_resolution:
                result += f"**–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤:** {conflict_resolution}\n"
            
            compatibility_reqs = romantic_analysis.get("compatibility_requirements", "")
            if compatibility_reqs:
                result += f"**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏:** {compatibility_reqs}\n"
            
            result += "\n"
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        if compatibility_matrix:
            result += "## üîó –ú–ê–¢–†–ò–¶–ê –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò\n\n"
            
            compatibility_types = {
                "analytical_types_compatibility": "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–∏–ø—ã (NT)",
                "creative_introverts_compatibility": "–¢–≤–æ—Ä—á–µ—Å–∫–∏–µ –∏–Ω—Ç—Ä–æ–≤–µ—Ä—Ç—ã (NF)",
                "extraverted_types_compatibility": "–≠–∫—Å—Ç—Ä–∞–≤–µ—Ä—Ç–Ω—ã–µ —Ç–∏–ø—ã",
                "traditional_types_compatibility": "–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ —Ç–∏–ø—ã (SJ)"
            }
            
            for compat_key, compat_name in compatibility_types.items():
                compat_score = compatibility_matrix.get(compat_key, "")
                if compat_score:
                    result += f"‚Ä¢ **{compat_name}:** {compat_score}\n"
            
            optimal_partner = compatibility_matrix.get("optimal_partner_profile", "")
            if optimal_partner:
                result += f"\n**–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å –ø–∞—Ä—Ç–Ω–µ—Ä–∞:** {optimal_partner}\n"
            
            problematic = compatibility_matrix.get("problematic_combinations", "")
            if problematic:
                result += f"**–ü—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–Ω—ã–µ —Å–æ—á–µ—Ç–∞–Ω–∏—è:** {problematic}\n"
            
            result += "\n"
        
        # –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
        if long_term_forecast:
            result += "## üîÆ –î–û–õ–ì–û–°–†–û–ß–ù–´–ô –ü–†–û–ì–ù–û–ó –†–ê–ó–í–ò–¢–ò–Ø\n\n"
            
            professional_trajectory = long_term_forecast.get("five_year_professional_trajectory", "")
            if professional_trajectory:
                result += f"**5-–ª–µ—Ç–Ω—è—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è:** {professional_trajectory}\n"
            
            growth_opportunities = long_term_forecast.get("personal_growth_opportunities", "")
            if growth_opportunities:
                result += f"**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ª–∏—á–Ω–æ—Å—Ç–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞:** {growth_opportunities}\n"
            
            life_transitions = long_term_forecast.get("potential_life_transitions", "")
            if life_transitions:
                result += f"**–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã:** {life_transitions}\n"
            
            success_factors = long_term_forecast.get("success_probability_factors", "")
            if success_factors:
                result += f"**–§–∞–∫—Ç–æ—Ä—ã —É—Å–ø–µ—Ö–∞:** {success_factors}\n"
            
            result += "\n"
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤
        if risk_assessment:
            result += "## ‚ö†Ô∏è –ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í –ò –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø\n\n"
            
            primary_risks = risk_assessment.get("primary_psychological_risks", [])
            if primary_risks:
                result += "**–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏:**\n"
                for risk in primary_risks[:3]:
                    result += f"‚Ä¢ {risk}\n"
                result += "\n"
            
            burnout_info = risk_assessment.get("burnout_susceptibility", {})
            if burnout_info:
                result += "**–°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –≤—ã–≥–æ—Ä–∞–Ω–∏—é:**\n"
                for key, value in burnout_info.items():
                    if value:
                        key_readable = key.replace("_", " ").title()
                        result += f"‚Ä¢ {key_readable}: {value}\n"
                result += "\n"
            
            early_warnings = risk_assessment.get("early_warning_signs", [])
            if early_warnings:
                result += "**–†–∞–Ω–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é—â–∏–µ —Å–∏–≥–Ω–∞–ª—ã:**\n"
                for warning in early_warnings[:3]:
                    result += f"‚Ä¢ {warning}\n"
                result += "\n"
        
        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if actionable_insights:
            result += "## üöÄ –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò\n\n"
            
            immediate_actions = actionable_insights.get("immediate_self_optimization", [])
            if immediate_actions:
                result += "**–ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ —à–∞–≥–∏ –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:**\n"
                for action in immediate_actions[:3]:
                    result += f"‚Ä¢ {action}\n"
                result += "\n"
            
            career_moves = actionable_insights.get("career_strategic_moves", [])
            if career_moves:
                result += "**–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –∫–∞—Ä—å–µ—Ä–Ω—ã–µ —Ö–æ–¥—ã:**\n"
                for move in career_moves[:3]:
                    result += f"‚Ä¢ {move}\n"
                result += "\n"
            
            relationship_improvements = actionable_insights.get("relationship_improvement_tactics", [])
            if relationship_improvements:
                result += "**–£–ª—É—á—à–µ–Ω–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–π:**\n"
                for improvement in relationship_improvements[:3]:
                    result += f"‚Ä¢ {improvement}\n"
                result += "\n"
        
        # –ù–∞—É—á–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        if scientific_validation:
            result += "## üî¨ –ù–ê–£–ß–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø\n\n"
            
            correlation = scientific_validation.get("cross_system_correlation", "")
            if correlation:
                result += f"**–ö—Ä–æ—Å—Å-—Å–∏—Å—Ç–µ–º–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è:** {correlation}\n"
            
            confidence_level = scientific_validation.get("confidence_level", "")
            if confidence_level:
                result += f"**–£—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏:** {confidence_level}\n"
            
            methodology_strengths = scientific_validation.get("methodology_strengths", "")
            if methodology_strengths:
                result += f"**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏:** {methodology_strengths}\n"
            
            limitations = scientific_validation.get("methodological_limitations", "")
            if limitations:
                result += f"**–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:** {limitations}\n"
            
            cultural_notes = scientific_validation.get("cultural_adaptation_notes", "")
            if cultural_notes:
                result += f"**–ö—É–ª—å—Ç—É—Ä–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:** {cultural_notes}\n"
            
            result += "\n"
        
        # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
        result += "---\n\n"
        result += f"**üìä –ò–¢–û–ì–û–í–´–ô –ò–ù–î–ï–ö–° –î–û–°–¢–û–í–ï–†–ù–û–°–¢–ò:** {confidence}%\n\n"
        
        # AI —Å–∏—Å—Ç–µ–º—ã
        if len(successful_services) > 1:
            ai_names = []
            if "claude" in successful_services:
                ai_names.append("Claude 3.5 Sonnet")
            if "openai" in successful_services:
                ai_names.append("OpenAI GPT-4o")
            if "cohere" in successful_services:
                ai_names.append("Cohere Command-R+")
            if "huggingface" in successful_services:
                ai_names.append("HuggingFace Transformers")
            
            result += f"**ü§ñ AI –°–ò–°–¢–ï–ú–´:** {' + '.join(ai_names)}\n"
            result += f"**üî¨ –ú–ï–¢–û–î–û–õ–û–ì–ò–Ø:** –ú—É–ª—å—Ç–∏-AI –∫–æ–Ω—Å–µ–Ω—Å—É—Å —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π ({len(successful_services)} —Å–∏—Å—Ç–µ–º)\n"
        else:
            result += f"**ü§ñ AI –î–í–ò–ñ–û–ö:** {successful_services[0].title()}\n"
            result += f"**üî¨ –ú–ï–¢–û–î–û–õ–û–ì–ò–Ø:** –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑\n"
        
        result += f"\n*–î–∞–Ω–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∞—É—á–Ω–æ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–∏–∫ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ AI –∏ –º–æ–∂–µ—Ç —Å–ª—É–∂–∏—Ç—å –æ—Å–Ω–æ–≤–æ–π –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –≤ —Å—Ñ–µ—Ä–∞—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π –∏ –ª–∏—á–Ω–æ—Å—Ç–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞.*\n\n"
        result += "üí¨ **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —É–≥–ª—É–±–ª–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞!**"
        
        return result


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–≤–∏–∂–∫–∞
analysis_engine = AnalysisEngine() 