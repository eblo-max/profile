"""
–û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤ –∏ —Å–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
"""
import asyncio
import structlog
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict

from src.ai.anthropic_client import anthropic_client
from src.ai.watson_client import OpenAIClient
from src.ai.google_client import google_gemini_client
from src.ai.cohere_client import cohere_client
from src.ai.huggingface_client import huggingface_client
from src.database.connection import get_async_session
from src.database.models import Analysis, AnalysisError
from src.config.settings import settings

logger = structlog.get_logger()


@dataclass
class AnalysisInput:
    """–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    user_id: int
    telegram_id: int
    text: Optional[str] = None
    images: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    analysis_id: int
    status: str
    confidence_score: float
    main_findings: Dict[str, Any]
    detailed_analysis: Dict[str, Any]
    psychological_profile: Dict[str, Any]
    final_report: str
    methodology: List[str]
    limitations: List[str]
    bias_warnings: List[str]
    created_at: datetime


class AnalysisEngine:
    """–û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞"""
        self.claude_client = anthropic_client
        self.openai_client = OpenAIClient()
        self.google_gemini_client = google_gemini_client
        self.cohere_client = cohere_client
        self.huggingface_client = huggingface_client
        
        self.supported_services = {
            # üöÄ –°–û–í–†–ï–ú–ï–ù–ù–´–ï AI –°–ï–†–í–ò–°–´ (2025)
            "claude": True,  # –ì–ª–∞–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å–∏–Ω—Ç–µ–∑
            "openai": self.openai_client.is_available,  # GPT-4o
            "google_gemini": google_gemini_client.is_available,  # –ó–∞–º–µ–Ω–∞ Google Cloud NL + Azure
            "cohere": cohere_client.is_available,  # –ó–∞–º–µ–Ω–∞ Lexalytics + Receptiviti
            "huggingface": huggingface_client.is_available,  # –ó–∞–º–µ–Ω–∞ AWS Rekognition
            
            # üìâ DEPRECATED –°–ï–†–í–ò–°–´ (–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            "azure": settings.azure_cognitive_key is not None,
            "google": settings.google_cloud_project_id is not None,
            "aws": settings.aws_access_key_id is not None,
            "crystal": settings.crystal_api_key is not None,
            "receptiviti": settings.receptiviti_api_key is not None,
            "lexalytics": settings.lexalytics_api_key is not None,
            "monkeylearn": settings.monkeylearn_api_key is not None
        }
        
        active_services = [name for name, active in self.supported_services.items() if active]
        logger.info("üöÄ AnalysisEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω", 
                   active_services=active_services,
                   total_services=len(active_services))
    
    async def analyze_comprehensive(self, analysis_input: AnalysisInput) -> AnalysisResult:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã
        
        Args:
            analysis_input: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ –ë–î
        analysis_id = await self._create_analysis_record(analysis_input)
        
        try:
            logger.info("üîç –ù–∞—á–∏–Ω–∞—é –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", 
                       analysis_id=analysis_id,
                       user_id=analysis_input.user_id)
            
            # –≠—Ç–∞–ø 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤
            ai_results = await self._collect_ai_insights(analysis_input, analysis_id)
            
            # –≠—Ç–∞–ø 2: –°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Claude
            synthesis_result = await self._synthesize_results(ai_results, analysis_input)
            
            # –≠—Ç–∞–ø 3: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            validation_result = await self._validate_analysis(synthesis_result)
            
            # –≠—Ç–∞–ø 4: –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            final_report = await self._generate_final_report(
                synthesis_result, 
                validation_result, 
                ai_results
            )
            
            # –≠—Ç–∞–ø 5: –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            confidence_score = self._calculate_confidence_score(ai_results, validation_result)
            bias_warnings = self._detect_potential_bias(synthesis_result, ai_results)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = AnalysisResult(
                analysis_id=analysis_id,
                status="completed",
                confidence_score=confidence_score,
                main_findings=synthesis_result.get("main_findings", {}),
                detailed_analysis=synthesis_result.get("detailed_analysis", {}),
                psychological_profile=synthesis_result.get("psychological_profile", {}),
                final_report=final_report,
                methodology=self._get_methodology_used(ai_results),
                limitations=synthesis_result.get("limitations", []),
                bias_warnings=bias_warnings,
                created_at=datetime.utcnow()
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –ë–î
            await self._save_analysis_result(analysis_id, result, ai_results, synthesis_result)
            
            logger.info("‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                       analysis_id=analysis_id,
                       confidence_score=confidence_score,
                       ai_services_used=len(ai_results))
            
            return result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", 
                        analysis_id=analysis_id, 
                        error=str(e), 
                        exc_info=True)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ –≤ –ë–î
            await self._save_analysis_error(analysis_id, "comprehensive_analysis", str(e))
            
            # –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å –æ—à–∏–±–∫–æ–π
            return AnalysisResult(
                analysis_id=analysis_id,
                status="failed",
                confidence_score=0.0,
                main_findings={"error": str(e)},
                detailed_analysis={},
                psychological_profile={},
                final_report=f"–ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è: {str(e)}",
                methodology=[],
                limitations=["–ê–Ω–∞–ª–∏–∑ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏"],
                bias_warnings=[],
                created_at=datetime.utcnow()
            )
    
    async def quick_analyze(self, text: str, user_id: int, telegram_id: int) -> str:
        """
        üöÄ –°–û–í–†–ï–ú–ï–ù–ù–´–ô –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó (2025) 
        –ß–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–ø–æ–≤—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            telegram_id: Telegram ID
            
        Returns:
            –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            user_context = {"user_id": user_id, "telegram_id": telegram_id}
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã (2025)
            available_services = []
            if self.supported_services.get("claude", True):
                available_services.append("Claude 3.5 Sonnet")
            if self.supported_services.get("openai", False):
                available_services.append("OpenAI GPT-4o")
            if self.supported_services.get("cohere", False):
                available_services.append("Cohere Command-R+")
            if self.supported_services.get("huggingface", False):
                available_services.append("HuggingFace Transformers")
            
            logger.info("üöÄ –°–û–í–†–ï–ú–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó (2025)", 
                       user_id=user_id, 
                       text_length=len(text),
                       available_services=available_services,
                       total_services=len(available_services))
            
            # === –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–´–ô –ó–ê–ü–£–°–ö –í–°–ï–• –î–û–°–¢–£–ü–ù–´–• AI –°–ï–†–í–ò–°–û–í ===
            tasks = []
            service_names = []
            
            # 1. Claude 3.5 Sonnet (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)
            tasks.append(self._run_claude_analysis(text, user_context))
            service_names.append("claude")
            
            # 2. OpenAI GPT-4o (–µ—Å–ª–∏ API –∫–ª—é—á –µ—Å—Ç—å)
            if self.supported_services.get("openai", False):
                tasks.append(self._run_openai_analysis(text, user_context))
                service_names.append("openai")
            
            # 3. Cohere Command-R+ (–ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑)
            if self.supported_services.get("cohere", False):
                tasks.append(self._run_cohere_analysis(text, user_context))
                service_names.append("cohere")
            
            # 4. HuggingFace Transformers (—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)
            if self.supported_services.get("huggingface", False):
                tasks.append(self._run_huggingface_analysis(text, user_context))
                service_names.append("huggingface")
            
            logger.info(f"‚ö° –ó–∞–ø—É—Å–∫–∞—é {len(tasks)} AI —Å–µ—Ä–≤–∏—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ", 
                       services=service_names)
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
            ai_results_raw = await asyncio.gather(*tasks, return_exceptions=True)
            
            # === –û–ë–†–ê–ë–û–¢–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
            ai_results = {}
            successful_services = []
            
            for i, (service_name, result) in enumerate(zip(service_names, ai_results_raw)):
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ {service_name}", error=str(result))
                    ai_results[service_name] = {
                        "error": str(result), 
                        "status": "failed",
                        "service": service_name
                    }
                else:
                    ai_results[service_name] = result
                    if result.get("status") != "failed" and "error" not in result:
                        successful_services.append(service_name)
                        logger.info(f"‚úÖ {service_name.upper()} –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                                   confidence=result.get('confidence_score', 0))
            
            logger.info(f"üéØ –£—Å–ø–µ—à–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤: {len(successful_services)}/{len(tasks)}", 
                       successful=successful_services)
            
            # === –°–ò–ù–¢–ï–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
            if len(successful_services) > 1:
                # –ú—É–ª—å—Ç–∏-AI —Å–∏–Ω—Ç–µ–∑ —á–µ—Ä–µ–∑ Claude
                enhanced_result = await self._synthesize_multiple_ai_results(ai_results, text, user_context)
                logger.info("üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω –º—É–ª—å—Ç–∏-AI —Å–∏–Ω—Ç–µ–∑", 
                           sources=len(successful_services))
            elif "claude" in successful_services:
                # –û–±–æ–≥–∞—â–µ–Ω–∏–µ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–∞–Ω–Ω—ã–º–∏ –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
                enhanced_result = self._enrich_claude_with_modern_ai(ai_results["claude"], ai_results)
                logger.info("‚ú® Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–æ–≥–∞—â–µ–Ω —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ AI –¥–∞–Ω–Ω—ã–º–∏")
            else:
                # Fallback –Ω–∞ –ª—é–±–æ–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                enhanced_result = next((r for r in ai_results.values() if r.get("status") != "failed"), {})
                logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            
            # === –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –î–õ–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===
            formatted_result = self._format_modern_analysis_result(
                enhanced_result, 
                successful_services,
                ai_results
            )
            
            logger.info("‚úÖ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                       user_id=user_id,
                       ai_services=len(successful_services),
                       confidence=enhanced_result.get('confidence_score', 0))
            
            return formatted_result
            
        except Exception as e:
            logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞", error=str(e), exc_info=True)
            return f"‚ö†Ô∏è **–°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞**: {str(e)}\n\nüîß –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
    
    def _format_quick_result(self, analysis_result: Dict[str, Any], openai_available: bool = False) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è Telegram"""
        
        if "error" in analysis_result:
            return f"‚ö†Ô∏è **–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**: {analysis_result['error']}"
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        hook_summary = analysis_result.get("hook_summary", "")
        personality_core = analysis_result.get("personality_core", {})
        main_findings = analysis_result.get("main_findings", {})
        psychological_profile = analysis_result.get("psychological_profile", {})
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç OpenAI Big Five –¥–∞–Ω–Ω—ã–º –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        openai_big_five = psychological_profile.get("openai_big_five", {})
        claude_big_five = psychological_profile.get("big_five_traits", {})
        big_five_detailed = openai_big_five if openai_big_five else claude_big_five
        
        practical_insights = analysis_result.get("practical_insights", {})
        actionable_recommendations = analysis_result.get("actionable_recommendations", {})
        fascinating_details = analysis_result.get("fascinating_details", {})
        confidence = analysis_result.get("confidence_score", 80)
        
        # –î–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        data_sources = analysis_result.get("data_sources", {})
        
        # –ù–∞—á–∞–ª–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        result = "üß† **–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó**\n"
        result += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        # –ó–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π —Ö—É–∫
        if hook_summary:
            result += f"‚ú® **{hook_summary}**\n\n"
        
        # –°—É—Ç—å –ª–∏—á–Ω–æ—Å—Ç–∏
        if personality_core.get("essence"):
            result += f"üéØ **–°–£–¢–¨ –õ–ò–ß–ù–û–°–¢–ò:**\n{personality_core['essence']}\n\n"
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–µ—Ä—Ç—ã
        if personality_core.get("unique_traits"):
            result += "‚≠ê **–£–ù–ò–ö–ê–õ–¨–ù–´–ï –ß–ï–†–¢–´:**\n"
            for trait in personality_core["unique_traits"][:3]:
                result += f"‚Ä¢ {trait}\n"
            result += "\n"
        
        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–æ–¥–ø–∏—Å—å
        if main_findings.get("emotional_signature"):
            result += f"‚ù§Ô∏è **–≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–ê–Ø –ü–û–î–ü–ò–°–¨:**\n{main_findings['emotional_signature']}\n\n"
        
        # –°—Ç–∏–ª—å –º—ã—à–ª–µ–Ω–∏—è
        if main_findings.get("thinking_style"):
            result += f"üß† **–°–¢–ò–õ–¨ –ú–´–®–õ–ï–ù–ò–Ø:**\n{main_findings['thinking_style']}\n\n"
        
        # Big Five —Å –¥–µ—Ç–∞–ª—è–º–∏
        if big_five_detailed:
            result += "üìä **–ü–†–û–§–ò–õ–¨ –õ–ò–ß–ù–û–°–¢–ò (Big Five):**\n"
            traits_ru = {
                "openness": "üé® –û—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å",
                "conscientiousness": "üìã –î–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω–æ—Å—Ç—å", 
                "extraversion": "üë• –≠–∫—Å—Ç—Ä–∞–≤–µ—Ä—Å–∏—è",
                "agreeableness": "ü§ù –î–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
                "neuroticism": "üåä –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"
            }
            
            for trait, trait_data in big_five_detailed.items():
                if trait in traits_ru and isinstance(trait_data, dict):
                    score = trait_data.get("score", 50)
                    description = trait_data.get("description", "")
                    level = "üî¥ –ù–∏–∑–∫–∏–π" if score < 40 else "üü° –°—Ä–µ–¥–Ω–∏–π" if score < 70 else "üü¢ –í—ã—Å–æ–∫–∏–π"
                    result += f"‚Ä¢ {traits_ru[trait]}: {score}% {level}\n"
                    if description:
                        result += f"  ‚îî {description[:80]}...\n"
            result += "\n"
        
        # –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
        if practical_insights.get("strengths_to_leverage"):
            result += "üí™ **–í–ê–®–ò –°–£–ü–ï–†–°–ò–õ–´:**\n"
            for strength in practical_insights["strengths_to_leverage"][:2]:
                result += f"‚Ä¢ {strength}\n"
            result += "\n"
        
        # –°–∫—Ä—ã—Ç—ã–µ —Ç–∞–ª–∞–Ω—Ç—ã
        if fascinating_details.get("hidden_talents"):
            result += "üéÅ **–°–ö–†–´–¢–´–ï –¢–ê–õ–ê–ù–¢–´:**\n"
            for talent in fascinating_details["hidden_talents"][:2]:
                result += f"‚Ä¢ {talent}\n"
            result += "\n"
        
        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if actionable_recommendations.get("immediate_actions"):
            result += "üöÄ **–î–ï–ô–°–¢–í–ò–Ø –ù–ê –ù–ï–î–ï–õ–Æ:**\n"
            for action in actionable_recommendations["immediate_actions"][:3]:
                result += f"‚Ä¢ {action}\n"
            result += "\n"
        
        # –ö–∞—Ä—å–µ—Ä–Ω—ã–µ —Å–æ–≤–µ—Ç—ã
        if practical_insights.get("career_alignment"):
            result += f"üíº **–ö–ê–†–¨–ï–†–ê:**\n{practical_insights['career_alignment']}\n\n"
        
        # –û—Ç–Ω–æ—à–µ–Ω–∏—è
        if practical_insights.get("relationship_style"):
            result += f"üíï **–û–¢–ù–û–®–ï–ù–ò–Ø:**\n{practical_insights['relationship_style']}\n\n"
        
        # –°–∫—Ä—ã—Ç—ã–µ –≥–ª—É–±–∏–Ω—ã
        if personality_core.get("hidden_depths"):
            result += f"üîç **–ó–ê –§–ê–°–ê–î–û–ú:**\n{personality_core['hidden_depths']}\n\n"
        
        # –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        result += f"üìà **–ò–ù–î–ï–ö–° –£–í–ï–†–ï–ù–ù–û–°–¢–ò:** {confidence}%\n"
        
        # AI –¥–≤–∏–∂–∫–∏
        if openai_available and data_sources:
            result += f"ü§ñ **AI –î–í–ò–ñ–ö–ò:** Claude 3.5 Sonnet + OpenAI GPT-4o\n"
            result += f"üî¨ **–ú–ï–¢–û–î–´:** Big Five (OpenAI), —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (OpenAI), –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (Claude)\n"
            if psychological_profile.get("scientific_validation"):
                result += f"‚úÖ **–ù–ê–£–ß–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø:** OpenAI Research\n"
        else:
            result += f"ü§ñ **AI –î–í–ò–ñ–û–ö:** Claude 3.5 Sonnet\n"
            result += f"üî¨ **–ú–ï–¢–û–î–´:** Big Five, –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑\n"
        
        # OpenAI —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if openai_available and openai_big_five:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º OpenAI —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            openai_emotions = psychological_profile.get("emotional_analysis", {})
            if openai_emotions:
                dominant_emotion = openai_emotions.get("dominant_emotion", "")
                if dominant_emotion:
                    result += f"\nüéØ **–î–û–ú–ò–ù–ò–†–£–Æ–©–ê–Ø –≠–ú–û–¶–ò–Ø (OpenAI):** {dominant_emotion}\n"
                    
                sentiment = psychological_profile.get("sentiment_analysis", {})
                if sentiment:
                    polarity = sentiment.get("polarity", 0)
                    sentiment_text = "–ü–æ–∑–∏—Ç–∏–≤–Ω–æ–µ" if polarity > 0.3 else "–ù–µ–≥–∞—Ç–∏–≤–Ω–æ–µ" if polarity < -0.3 else "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ"
                    result += f"‚Ä¢ **–û–±—â–∏–π –Ω–∞—Å—Ç—Ä–æ–π:** {sentiment_text} ({polarity:.2f})\n"
        
        result += "\nüí¨ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â–µ —Ç–µ–∫—Å—Ç –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!"
        
        return result
    
    async def _collect_ai_insights(self, analysis_input: AnalysisInput, analysis_id: int) -> Dict[str, Any]:
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        results = {}
        tasks = []
        
        if analysis_input.text:
            # Claude –∞–Ω–∞–ª–∏–∑ (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)
            tasks.append(self._run_claude_analysis(analysis_input.text, analysis_input.metadata))
            
            # OpenAI –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            if self.supported_services["openai"]:
                tasks.append(self._run_openai_analysis(analysis_input.text, analysis_input.metadata))
            
            logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞", 
                       services_count=len(tasks),
                       analysis_id=analysis_id)
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
            ai_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            service_names = ["claude"]
            if self.supported_services["openai"]:
                service_names.append("openai")
            
            for i, result in enumerate(ai_results):
                service_name = service_names[i]
                
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ {service_name} –∞–Ω–∞–ª–∏–∑–∞", 
                               error=str(result), 
                               analysis_id=analysis_id)
                    results[service_name] = {
                        "error": str(result),
                        "status": "failed",
                        "service": service_name
                    }
                else:
                    results[service_name] = result
                    logger.info(f"‚úÖ {service_name.title()} –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                               confidence=result.get('confidence_score', 0),
                               analysis_id=analysis_id)
        
        return results
    
    async def _run_claude_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ Claude –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            return await self.claude_client.analyze_text(
                text=text,
                analysis_type="comprehensive_psychological",
                user_context=metadata
            )
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ Claude –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed",
                "service": "claude"
            }
    
    async def _run_openai_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ OpenAI –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö OpenAI –∞–Ω–∞–ª–∏–∑–æ–≤
            personality_task = self.openai_client.analyze_personality(text)
            emotions_task = self.openai_client.analyze_emotions(text)
            sentiment_task = self.openai_client.analyze_sentiment(text)
            
            personality_result, emotions_result, sentiment_result = await asyncio.gather(
                personality_task, emotions_task, sentiment_task, return_exceptions=True
            )
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            combined_result = {
                "status": "success",
                "service": "openai",
                "big_five_traits": personality_result.get("big_five", {}) if not isinstance(personality_result, Exception) else {},
                "mbti": personality_result.get("mbti", "Unknown") if not isinstance(personality_result, Exception) else "Unknown",
                "disc": personality_result.get("disc", "Unknown") if not isinstance(personality_result, Exception) else "Unknown",
                "emotions": emotions_result.get("emotions", {}) if not isinstance(emotions_result, Exception) else {},
                "dominant_emotion": emotions_result.get("dominant_emotion", "neutral") if not isinstance(emotions_result, Exception) else "neutral",
                "sentiment": sentiment_result.get("sentiment", "neutral") if not isinstance(sentiment_result, Exception) else "neutral",
                "sentiment_polarity": sentiment_result.get("polarity", 0.0) if not isinstance(sentiment_result, Exception) else 0.0,
                "confidence_score": 85  # OpenAI –≤—ã—Å–æ–∫–∏–π confidence
            }
            
            return combined_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ OpenAI –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed", 
                "service": "openai"
            }
    
    async def _run_cohere_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ Cohere Command-R+ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö Cohere –∞–Ω–∞–ª–∏–∑–æ–≤
            psycholinguistics_task = self.cohere_client.analyze_psycholinguistics(text)
            sentiment_task = self.cohere_client.analyze_advanced_sentiment(text)
            behavioral_task = self.cohere_client.analyze_behavioral_patterns(text)
            
            psycholinguistics_result, sentiment_result, behavioral_result = await asyncio.gather(
                psycholinguistics_task, sentiment_task, behavioral_task, return_exceptions=True
            )
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Cohere
            combined_result = {
                "status": "success",
                "service": "cohere",
                "psycholinguistics": psycholinguistics_result if not isinstance(psycholinguistics_result, Exception) else {},
                "advanced_sentiment": sentiment_result if not isinstance(sentiment_result, Exception) else {},
                "behavioral_patterns": behavioral_result if not isinstance(behavioral_result, Exception) else {},
                "confidence_score": 80  # Cohere —Ö–æ—Ä–æ—à–∏–π confidence –¥–ª—è –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏–∫–∏
            }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤
            if not isinstance(psycholinguistics_result, Exception):
                combined_result["linguistic_insights"] = {
                    "cognitive_style": psycholinguistics_result.get("cognitive_style", {}),
                    "communication_psychology": psycholinguistics_result.get("communication_psychology", {}),
                    "thought_process": psycholinguistics_result.get("thought_process_indicators", {})
                }
            
            if not isinstance(sentiment_result, Exception):
                combined_result["emotional_insights"] = {
                    "dimensional_analysis": sentiment_result.get("dimensional_analysis", {}),
                    "psychological_sentiment": sentiment_result.get("psychological_sentiment_markers", {}),
                    "social_emotional": sentiment_result.get("social_emotional_context", {})
                }
            
            return combined_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ Cohere –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed",
                "service": "cohere"
            }
    
    async def _run_huggingface_analysis(self, text: str, metadata: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ HuggingFace Transformers –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö HuggingFace –∞–Ω–∞–ª–∏–∑–æ–≤
            emotions_task = self.huggingface_client.analyze_emotions_transformers(text)
            personality_task = self.huggingface_client.analyze_personality_transformers(text)
            mental_health_task = self.huggingface_client.analyze_mental_health_indicators(text)
            
            emotions_result, personality_result, mental_health_result = await asyncio.gather(
                emotions_task, personality_task, mental_health_task, return_exceptions=True
            )
            
            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ HuggingFace
            combined_result = {
                "status": "success",
                "service": "huggingface",
                "transformer_emotions": emotions_result if not isinstance(emotions_result, Exception) else {},
                "transformer_personality": personality_result if not isinstance(personality_result, Exception) else {},
                "mental_health_analysis": mental_health_result if not isinstance(mental_health_result, Exception) else {},
                "confidence_score": 75  # HuggingFace —Å—Ä–µ–¥–Ω–∏–π confidence (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏)
            }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤
            if not isinstance(emotions_result, Exception):
                combined_result["emotion_insights"] = {
                    "transformer_emotions": emotions_result.get("transformer_emotions", {}),
                    "emotional_profile": emotions_result.get("emotional_profile", {}),
                    "psychological_insights": emotions_result.get("psychological_insights", {})
                }
            
            if not isinstance(mental_health_result, Exception):
                combined_result["wellbeing_insights"] = {
                    "stress_indicators": mental_health_result.get("stress_indicators", {}),
                    "resilience_factors": mental_health_result.get("resilience_factors", {}),
                    "psychological_wellbeing": mental_health_result.get("psychological_wellbeing", {})
                }
            
            return combined_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ HuggingFace –∞–Ω–∞–ª–∏–∑–∞", error=str(e))
            return {
                "error": str(e),
                "status": "failed",
                "service": "huggingface"
            }
    
    async def _synthesize_results(self, ai_results: Dict[str, Any], analysis_input: AnalysisInput) -> Dict[str, Any]:
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Claude —Å —É—á–µ—Ç–æ–º –¥–∞–Ω–Ω—ã—Ö –æ—Ç –≤—Å–µ—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            logger.info("üîÑ –°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç AI —Å–µ—Ä–≤–∏—Å–æ–≤", 
                       services_available=list(ai_results.keys()))
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ–∑
            if len(ai_results) > 1 and "openai" in ai_results and "claude" in ai_results:
                # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ —á–µ—Ä–µ–∑ Claude
                synthesis_context = {
                    "ai_results": ai_results,
                    "services_used": list(ai_results.keys()),
                    "analysis_input": analysis_input.metadata
                }
                
                synthesis_result = await self.claude_client.analyze_text(
                    text=analysis_input.text,
                    analysis_type="synthesis",
                    user_context=synthesis_context
                )
                
                # –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞–Ω–Ω—ã–º–∏ OpenAI
                if "openai" in ai_results and ai_results["openai"].get("status") == "success":
                    synthesis_result = self._enrich_with_openai_data(synthesis_result, ai_results["openai"])
                
                logger.info("‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                           confidence=synthesis_result.get('confidence_score', 0))
                
                return synthesis_result
            
            # –ï—Å–ª–∏ OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            elif "claude" in ai_results:
                logger.info("üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return ai_results["claude"]
            
            # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ OpenAI –¥–æ—Å—Ç—É–ø–µ–Ω
            elif "openai" in ai_results:
                logger.info("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ OpenAI —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return self._format_openai_only_result(ai_results["openai"])
            
            else:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")
                return {"error": "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞", "status": "no_results"}
                
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", error=str(e), exc_info=True)
            # Fallback –Ω–∞ Claude –µ—Å–ª–∏ –µ—Å—Ç—å
            return ai_results.get("claude", {"error": str(e), "status": "synthesis_failed"})
    
    def _enrich_with_openai_data(self, claude_result: Dict[str, Any], openai_result: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ Claude –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç OpenAI"""
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ OpenAI –≤ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if "psychological_profile" not in claude_result:
                claude_result["psychological_profile"] = {}
            
            # OpenAI Big Five –¥–∞–Ω–Ω—ã–µ
            openai_big_five = openai_result.get("big_five_traits", {})
            if openai_big_five:
                claude_result["psychological_profile"]["openai_big_five"] = openai_big_five
                claude_result["psychological_profile"]["scientific_validation"] = True
            
            # OpenAI —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            if "emotions" in openai_result:
                claude_result["psychological_profile"]["emotional_analysis"] = {
                    "emotions": openai_result["emotions"],
                    "dominant_emotion": openai_result.get("dominant_emotion", "neutral"),
                    "emotional_intensity": openai_result.get("emotional_intensity", 0.5)
                }
            
            # OpenAI –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
            if "sentiment" in openai_result:
                claude_result["psychological_profile"]["sentiment_analysis"] = {
                    "sentiment": openai_result["sentiment"],
                    "polarity": openai_result.get("sentiment_polarity", 0.0),
                    "confidence": openai_result.get("sentiment_confidence", 0.8)
                }
            
            # MBTI –∏ DISC –æ—Ç OpenAI
            if "mbti" in openai_result:
                claude_result["psychological_profile"]["mbti_type"] = openai_result["mbti"]
            if "disc" in openai_result:
                claude_result["psychological_profile"]["disc_profile"] = openai_result["disc"]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º confidence score (—Å—Ä–µ–¥–Ω–∏–π –º–µ–∂–¥—É Claude –∏ OpenAI)
            openai_confidence = openai_result.get("confidence_score", 0)
            claude_confidence = claude_result.get("confidence_score", 0)
            
            if openai_confidence > 0 and claude_confidence > 0:
                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ: —Ä–∞–≤–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è Claude –∏ OpenAI
                combined_confidence = (openai_confidence * 0.5 + claude_confidence * 0.5)
                claude_result["confidence_score"] = round(combined_confidence, 1)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
            claude_result["data_sources"] = {
                "claude": "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–∏–Ω—Ç–µ–∑ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è",
                "openai": "–ú–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ GPT-4o (Big Five, —ç–º–æ—Ü–∏–∏, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è)",
                "synthesis_method": "–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"
            }
            
            logger.info("‚úÖ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–æ–≥–∞—â–µ–Ω –¥–∞–Ω–Ω—ã–º–∏ OpenAI")
            return claude_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è Watson –¥–∞–Ω–Ω—ã–º–∏", error=str(e))
            return claude_result
    
    def _format_openai_only_result(self, openai_result: Dict[str, Any]) -> Dict[str, Any]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç–æ–ª—å–∫–æ –æ—Ç OpenAI –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OpenAI –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç –ø–æ—Ö–æ–∂–∏–π –Ω–∞ Claude
            formatted_result = {
                "analysis_type": "openai_personality",
                "hook_summary": "–ú–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ OpenAI GPT-4o",
                "personality_core": {
                    "essence": f"MBTI: {openai_result.get('mbti', 'Unknown')}, DISC: {openai_result.get('disc', 'Unknown')}",
                    "unique_traits": [],
                    "hidden_depths": "–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ Big Five + —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å"
                },
                "main_findings": {
                    "personality_traits": [],
                    "emotional_signature": f"–î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è: {openai_result.get('dominant_emotion', 'neutral')}",
                    "thinking_style": f"–ù–∞—Å—Ç—Ä–æ–π: {openai_result.get('sentiment', 'neutral')}"
                },
                "psychological_profile": {
                    "big_five_traits": openai_result.get("big_five_traits", {}),
                    "emotional_analysis": openai_result.get("emotions", {}),
                    "sentiment_analysis": {
                        "sentiment": openai_result.get("sentiment", "neutral"),
                        "polarity": openai_result.get("sentiment_polarity", 0.0)
                    }
                },
                "confidence_score": openai_result.get("confidence_score", 85),
                "data_sources": {
                    "openai": "OpenAI GPT-4o (Big Five, —ç–º–æ—Ü–∏–∏, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è)",
                    "methodology": "–ú–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"
                },
                "status": "openai_only"
            }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —á–µ—Ä—Ç—ã –∏–∑ OpenAI Big Five
            big_five = openai_result.get("big_five_traits", {})
            for trait_name, trait_score in big_five.items():
                if isinstance(trait_score, (int, float)) and trait_score >= 70:
                    formatted_result["personality_core"]["unique_traits"].append(
                        f"{trait_name.title()}: {trait_score}% (–≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å)"
                    )
            
            return formatted_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è OpenAI —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞", error=str(e))
            return openai_result
    
    async def _validate_analysis(self, synthesis_result: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return {"validation_score": 80}
    
    async def _generate_final_report(self, synthesis_result: Dict[str, Any], validation_result: Dict[str, Any], ai_results: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return self._format_quick_result(synthesis_result)
    
    def _calculate_confidence_score(self, ai_results: Dict[str, Any], validation_result: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        base_confidence = 75.0
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–∞–∂–¥—ã–π —É—Å–ø–µ—à–Ω—ã–π AI —Å–µ—Ä–≤–∏—Å
        successful_services = 0
        total_confidence = 0
        
        for service_name, service_result in ai_results.items():
            if service_result.get("status") != "failed" and "error" not in service_result:
                successful_services += 1
                service_confidence = service_result.get("confidence_score", 75)
                total_confidence += service_confidence
        
        if successful_services > 0:
            # –°—Ä–µ–¥–Ω–∏–π confidence —Å –±–æ–Ω—É—Å–æ–º –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            avg_confidence = total_confidence / successful_services
            
            # –ë–æ–Ω—É—Å –∑–∞ OpenAI (–º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑)
            if "openai" in ai_results and ai_results["openai"].get("status") == "success":
                avg_confidence += 8  # +8% –∑–∞ –º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            
            # –ë–æ–Ω—É—Å –∑–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ—Ä–≤–∏—Å–æ–≤)
            if successful_services > 1:
                avg_confidence += 5  # +5% –∑–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é
            
            return min(95.0, max(50.0, avg_confidence))
        
        return base_confidence
    
    def _detect_potential_bias(self, synthesis_result: Dict[str, Any], ai_results: Dict[str, Any]) -> List[str]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–µ–π"""
        return []
    
    def _get_methodology_used(self, ai_results: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏"""
        methodology = []
        
        if "claude" in ai_results and ai_results["claude"].get("status") != "failed":
            methodology.append("Anthropic Claude 3.5 Sonnet - –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–∏–Ω—Ç–µ–∑ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è")
        
        if "openai" in ai_results and ai_results["openai"].get("status") == "success":
            methodology.append("OpenAI GPT-4o - –º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (Big Five + —ç–º–æ—Ü–∏–∏ + –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è)")
            methodology.append("IBM Research - –ø—Å–∏—Ö–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
        
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –æ–±–∞ —Å–µ—Ä–≤–∏—Å–∞
        if len([r for r in ai_results.values() if r.get("status") != "failed"]) > 1:
            methodology.append("–ì–∏–±—Ä–∏–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –º–µ–∂–¥—É AI —Å–∏—Å—Ç–µ–º–∞–º–∏")
        
        return methodology if methodology else ["–ë–∞–∑–æ–≤—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"]
    
    async def _create_analysis_record(self, analysis_input: AnalysisInput) -> int:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        return 1  # –ó–∞–≥–ª—É—à–∫–∞
    
    async def _save_analysis_result(self, analysis_id: int, result: AnalysisResult, ai_results: Dict[str, Any], synthesis_result: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        pass
    
    async def _save_analysis_error(self, analysis_id: int, service_name: str, error_message: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        pass
    
    async def _synthesize_multiple_ai_results(self, ai_results: Dict[str, Any], text: str, user_context: Dict[str, Any]) -> Dict[str, Any]:
        """–°–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤ —á–µ—Ä–µ–∑ Claude"""
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
            synthesis_context = {
                "ai_results": ai_results,
                "successful_services": [name for name, result in ai_results.items() if result.get("status") != "failed"],
                "text_length": len(text),
                "user_context": user_context
            }
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º—É–ª—å—Ç–∏-AI —Å–∏–Ω—Ç–µ–∑–∞
            synthesis_result = await self.claude_client.analyze_text(
                text=text,
                analysis_type="multi_ai_synthesis",
                user_context=synthesis_context
            )
            
            # –û–±–æ–≥–∞—â–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ–∑–∞ –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç –≤—Å–µ—Ö —É—Å–ø–µ—à–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
            enriched_result = self._enrich_claude_with_modern_ai(synthesis_result, ai_results)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ –º—É–ª—å—Ç–∏-AI –∞–Ω–∞–ª–∏–∑–µ
            enriched_result["multi_ai_analysis"] = {
                "services_used": synthesis_context["successful_services"],
                "synthesis_method": "claude_coordination",
                "cross_validation": True,
                "confidence_boost": len(synthesis_context["successful_services"]) * 5  # –ë–æ–Ω—É—Å –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            }
            
            return enriched_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –º—É–ª—å—Ç–∏-AI —Å–∏–Ω—Ç–µ–∑–∞", error=str(e))
            # Fallback –Ω–∞ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ—Å–ª–∏ —Å–∏–Ω—Ç–µ–∑ –Ω–µ —É–¥–∞–ª—Å—è
            return ai_results.get("claude", {"error": str(e), "status": "synthesis_failed"})
    
    def _enrich_claude_with_modern_ai(self, claude_result: Dict[str, Any], ai_results: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ Claude —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤ (2025)"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if "psychological_profile" not in claude_result:
                claude_result["psychological_profile"] = {}
            if "data_sources" not in claude_result:
                claude_result["data_sources"] = {}
            
            confidence_scores = []
            
            # === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø OPENAI –î–ê–ù–ù–´–• ===
            openai_data = ai_results.get("openai", {})
            if openai_data.get("status") == "success":
                # Big Five –æ—Ç OpenAI (–Ω–∞–∏–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ)
                if "big_five_traits" in openai_data:
                    claude_result["psychological_profile"]["openai_big_five"] = openai_data["big_five_traits"]
                    claude_result["psychological_profile"]["mbti_type"] = openai_data.get("mbti", "Unknown")
                    claude_result["psychological_profile"]["disc_profile"] = openai_data.get("disc", "Unknown")
                
                # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç OpenAI
                if "emotions" in openai_data:
                    claude_result["psychological_profile"]["openai_emotions"] = {
                        "emotions": openai_data["emotions"],
                        "dominant_emotion": openai_data.get("dominant_emotion", "neutral"),
                        "sentiment": openai_data.get("sentiment", "neutral"),
                        "polarity": openai_data.get("sentiment_polarity", 0.0)
                    }
                
                claude_result["data_sources"]["openai"] = "GPT-4o –º–Ω–æ–≥–æ–∞—Å–ø–µ–∫—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (Big Five + —ç–º–æ—Ü–∏–∏)"
                confidence_scores.append(openai_data.get("confidence_score", 85))
            
            # === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø COHERE –î–ê–ù–ù–´–• ===
            cohere_data = ai_results.get("cohere", {})
            if cohere_data.get("status") == "success":
                # –ü—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã
                if "linguistic_insights" in cohere_data:
                    claude_result["psychological_profile"]["psycholinguistics"] = cohere_data["linguistic_insights"]
                
                # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
                if "emotional_insights" in cohere_data:
                    claude_result["psychological_profile"]["cohere_sentiment"] = cohere_data["emotional_insights"]
                
                # –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                if "behavioral_patterns" in cohere_data:
                    claude_result["psychological_profile"]["behavioral_analysis"] = cohere_data["behavioral_patterns"]
                
                claude_result["data_sources"]["cohere"] = "Command-R+ –ø—Å–∏—Ö–æ–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"
                confidence_scores.append(cohere_data.get("confidence_score", 80))
            
            # === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø HUGGINGFACE –î–ê–ù–ù–´–• ===
            huggingface_data = ai_results.get("huggingface", {})
            if huggingface_data.get("status") == "success":
                # Transformer —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                if "emotion_insights" in huggingface_data:
                    claude_result["psychological_profile"]["transformer_emotions"] = huggingface_data["emotion_insights"]
                
                # –ê–Ω–∞–ª–∏–∑ –º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∑–¥–æ—Ä–æ–≤—å—è
                if "wellbeing_insights" in huggingface_data:
                    claude_result["psychological_profile"]["mental_wellbeing"] = huggingface_data["wellbeing_insights"]
                
                claude_result["data_sources"]["huggingface"] = "Specialized Transformers —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
                confidence_scores.append(huggingface_data.get("confidence_score", 75))
            
            # === –†–ê–°–ß–ï–¢ –ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–û–ì–û CONFIDENCE ===
            claude_confidence = claude_result.get("confidence_score", 75)
            confidence_scores.append(claude_confidence)
            
            if len(confidence_scores) > 1:
                # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ —Å –±–æ–Ω—É—Å–æ–º –∑–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é
                avg_confidence = sum(confidence_scores) / len(confidence_scores)
                cross_validation_bonus = min(10, (len(confidence_scores) - 1) * 3)  # +3% –∑–∞ –∫–∞–∂–¥—ã–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
                combined_confidence = min(95, avg_confidence + cross_validation_bonus)
                claude_result["confidence_score"] = round(combined_confidence, 1)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ
            claude_result["modern_ai_integration"] = {
                "ai_services_count": len([r for r in ai_results.values() if r.get("status") == "success"]),
                "data_fusion": True,
                "cross_validation": len(confidence_scores) > 1,
                "analysis_year": 2025
            }
            
            logger.info("‚ú® Claude –æ–±–æ–≥–∞—â–µ–Ω —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ AI –¥–∞–Ω–Ω—ã–º–∏", 
                       sources=len(confidence_scores),
                       final_confidence=claude_result.get("confidence_score"))
            
            return claude_result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ AI", error=str(e))
            return claude_result
    
    def _format_modern_analysis_result(self, analysis_result: Dict[str, Any], successful_services: List[str], ai_results: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –º—É–ª—å—Ç–∏-AI –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è Telegram"""
        
        if "error" in analysis_result or not analysis_result:
            return f"‚ö†Ô∏è **–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**: {analysis_result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        hook_summary = analysis_result.get("hook_summary", "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")
        personality_core = analysis_result.get("personality_core", {})
        main_findings = analysis_result.get("main_findings", {})
        psychological_profile = analysis_result.get("psychological_profile", {})
        
        # –î–∞–Ω–Ω—ã–µ –æ—Ç —Ä–∞–∑–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤
        openai_big_five = psychological_profile.get("openai_big_five", {})
        claude_big_five = psychological_profile.get("big_five_traits", {})
        openai_emotions = psychological_profile.get("openai_emotions", {})
        cohere_sentiment = psychological_profile.get("cohere_sentiment", {})
        transformer_emotions = psychological_profile.get("transformer_emotions", {})
        
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ –¥–∞–Ω–Ω—ã–µ Big Five (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç OpenAI)
        best_big_five = openai_big_five if openai_big_five else claude_big_five
        
        confidence = analysis_result.get("confidence_score", 80)
        data_sources = analysis_result.get("data_sources", {})
        
        # === –ù–ê–ß–ê–õ–û –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø ===
        result = "üß† **–°–û–í–†–ï–ú–ï–ù–ù–´–ô –ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó (2025)**\n"
        result += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        # –ó–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π —Ö—É–∫
        if hook_summary and hook_summary != "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω":
            result += f"‚ú® **{hook_summary}**\n\n"
        
        # –°—É—Ç—å –ª–∏—á–Ω–æ—Å—Ç–∏
        if personality_core.get("essence"):
            result += f"üéØ **–°–£–¢–¨ –õ–ò–ß–ù–û–°–¢–ò:**\n{personality_core['essence']}\n\n"
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–µ—Ä—Ç—ã —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        if personality_core.get("unique_traits"):
            result += "‚≠ê **–£–ù–ò–ö–ê–õ–¨–ù–´–ï –ß–ï–†–¢–´:**\n"
            for trait in personality_core["unique_traits"][:3]:
                result += f"‚Ä¢ {trait}\n"
            result += "\n"
        
        # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–æ–¥–ø–∏—Å—å (—Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö AI)
        emotional_signature = main_findings.get("emotional_signature", "")
        if openai_emotions and openai_emotions.get("dominant_emotion"):
            emotional_signature += f" | OpenAI: –¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç {openai_emotions['dominant_emotion']}"
        if transformer_emotions and transformer_emotions.get("emotional_profile", {}).get("dominant_emotion"):
            emotional_signature += f" | HF: {transformer_emotions['emotional_profile']['dominant_emotion']}"
        
        if emotional_signature:
            result += f"‚ù§Ô∏è **–≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–ê–Ø –ü–û–î–ü–ò–°–¨:**\n{emotional_signature}\n\n"
        
        # –°—Ç–∏–ª—å –º—ã—à–ª–µ–Ω–∏—è
        if main_findings.get("thinking_style"):
            result += f"üß† **–°–¢–ò–õ–¨ –ú–´–®–õ–ï–ù–ò–Ø:**\n{main_findings['thinking_style']}\n\n"
        
        # Big Five —Å –º—É–ª—å—Ç–∏-–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        if best_big_five:
            result += "üìä **–ü–†–û–§–ò–õ–¨ –õ–ò–ß–ù–û–°–¢–ò (Big Five):**\n"
            traits_ru = {
                "openness": "üé® –û—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å",
                "conscientiousness": "üìã –î–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω–æ—Å—Ç—å", 
                "extraversion": "üë• –≠–∫—Å—Ç—Ä–∞–≤–µ—Ä—Å–∏—è",
                "agreeableness": "ü§ù –î–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
                "neuroticism": "üåä –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"
            }
            
            for trait, trait_data in best_big_five.items():
                if trait in traits_ru:
                    if isinstance(trait_data, dict):
                        score = trait_data.get("score", 50)
                        description = trait_data.get("description", "")
                    else:
                        score = trait_data
                        description = ""
                    
                    level = "üî¥ –ù–∏–∑–∫–∏–π" if score < 40 else "üü° –°—Ä–µ–¥–Ω–∏–π" if score < 70 else "üü¢ –í—ã—Å–æ–∫–∏–π"
                    result += f"‚Ä¢ {traits_ru[trait]}: {score}% {level}\n"
                    if description:
                        result += f"  ‚îî {description[:60]}...\n"
            
            # –£–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ Big Five
            if openai_big_five:
                result += "  üìç *–ò—Å—Ç–æ—á–Ω–∏–∫: OpenAI GPT-4o –Ω–∞—É—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑*\n"
            result += "\n"
        
        # MBTI –∏ DISC (–µ—Å–ª–∏ –µ—Å—Ç—å –æ—Ç OpenAI)
        mbti = psychological_profile.get("mbti_type", "")
        disc = psychological_profile.get("disc_profile", "")
        if mbti and mbti != "Unknown":
            result += f"üé≠ **–¢–ò–ü–û–õ–û–ì–ò–Ø:** MBTI: {mbti}"
            if disc and disc != "Unknown":
                result += f" | DISC: {disc}"
            result += "\n\n"
        
        # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã
        practical_insights = analysis_result.get("practical_insights", {})
        if practical_insights.get("strengths_to_leverage"):
            result += "üí™ **–í–ê–®–ò –°–£–ü–ï–†–°–ò–õ–´:**\n"
            for strength in practical_insights["strengths_to_leverage"][:2]:
                result += f"‚Ä¢ {strength}\n"
            result += "\n"
        
        # –ö–∞—Ä—å–µ—Ä–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if practical_insights.get("career_alignment"):
            result += f"üíº **–ö–ê–†–¨–ï–†–ê:**\n{practical_insights['career_alignment'][:120]}...\n\n"
        
        # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã –æ—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö AI
        if "cohere" in successful_services and cohere_sentiment:
            result += "üß¨ **–ü–°–ò–•–û–õ–ò–ù–ì–í–ò–°–¢–ò–ö–ê (Cohere):**\n"
            dimensional = cohere_sentiment.get("dimensional_analysis", {})
            if dimensional:
                valence = dimensional.get("valence", 0)
                arousal = dimensional.get("arousal", 0.5)
                result += f"‚Ä¢ –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å: {valence:.2f}\n"
                result += f"‚Ä¢ –£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: {arousal:.2f}\n\n"
        
        if "huggingface" in successful_services and transformer_emotions:
            result += "ü§ñ **TRANSFORMER –ê–ù–ê–õ–ò–ó:**\n"
            hf_emotions = transformer_emotions.get("transformer_emotions", {})
            if hf_emotions:
                top_emotion = max(hf_emotions.items(), key=lambda x: x[1])
                result += f"‚Ä¢ –î–æ–º–∏–Ω–∏—Ä—É—é—â–∞—è —ç–º–æ—Ü–∏—è: {top_emotion[0]} ({top_emotion[1]:.0f}%)\n\n"
        
        # === –ú–ï–¢–ê–î–ê–ù–ù–´–ï –ê–ù–ê–õ–ò–ó–ê ===
        result += f"üìà **–ò–ù–î–ï–ö–° –£–í–ï–†–ï–ù–ù–û–°–¢–ò:** {confidence}%\n"
        
        # AI —Å–µ—Ä–≤–∏—Å—ã —Å –¥–µ—Ç–∞–ª—è–º–∏
        if len(successful_services) > 1:
            result += f"üöÄ **AI –î–í–ò–ñ–ö–ò ({len(successful_services)}):** "
            ai_names = []
            if "claude" in successful_services:
                ai_names.append("Claude 3.5 Sonnet")
            if "openai" in successful_services:
                ai_names.append("OpenAI GPT-4o")
            if "cohere" in successful_services:
                ai_names.append("Cohere Command-R+")
            if "huggingface" in successful_services:
                ai_names.append("HuggingFace Transformers")
            
            result += " + ".join(ai_names) + "\n"
            result += f"üî¨ **–ú–ï–¢–û–î–´:** –ú—É–ª—å—Ç–∏-AI –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è ({len(successful_services)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)\n"
            result += f"‚úÖ **–ù–ê–£–ß–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø:** –ö–æ–Ω—Å–µ–Ω—Å—É—Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö AI —Å–∏—Å—Ç–µ–º\n"
        else:
            result += f"ü§ñ **AI –î–í–ò–ñ–û–ö:** {successful_services[0].title()}\n"
        
        # –°–æ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞
        modern_integration = analysis_result.get("modern_ai_integration", {})
        if modern_integration.get("data_fusion"):
            result += f"‚ö° **–¢–ï–•–ù–û–õ–û–ì–ò–Ø 2025:** –§—å—é–∂–Ω –¥–∞–Ω–Ω—ã—Ö –æ—Ç {modern_integration.get('ai_services_count', 1)} AI —Å–∏—Å—Ç–µ–º\n"
        
        result += "\nüí¨ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ—â–µ —Ç–µ–∫—Å—Ç –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞!"
        
        return result


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–≤–∏–∂–∫–∞
analysis_engine = AnalysisEngine() 