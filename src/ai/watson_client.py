"""
–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è IBM Watson Personality Insights
"""
import asyncio
import structlog
from typing import Dict, Any, Optional, List
import json
from ibm_watson import PersonalityInsightsV3
from ibm_cloud_sdk_core.authenticators import IAMAuthenticator
from ibm_cloud_sdk_core import ApiException

from src.config.settings import settings

logger = structlog.get_logger()


class WatsonClient:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è IBM Watson Personality Insights"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞"""
        self.client = None
        self.is_available = False
        
        if settings.ibm_watson_api_key and settings.ibm_watson_url:
            try:
                authenticator = IAMAuthenticator(settings.ibm_watson_api_key)
                self.client = PersonalityInsightsV3(
                    version='2017-10-13',
                    authenticator=authenticator
                )
                self.client.set_service_url(settings.ibm_watson_url)
                self.is_available = True
                logger.info("üß† Watson –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω", 
                           url=settings.ibm_watson_url[:50] + "...")
            except Exception as e:
                logger.error("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Watson", error=str(e))
                self.is_available = False
        else:
            logger.warning("‚ö†Ô∏è Watson API –∫–ª—é—á–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
    
    async def analyze_personality(self, 
                                 text: str, 
                                 user_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Watson Personality Insights
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–º–∏–Ω–∏–º—É–º 100 —Å–ª–æ–≤)
            user_context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ Watson —Å Big Five –∏ –¥—Ä—É–≥–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        if not self.is_available:
            return {
                "error": "Watson API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                "status": "unavailable",
                "fallback": True
            }
        
        try:
            logger.info("üîç –ó–∞–ø—É—Å–∫ Watson –∞–Ω–∞–ª–∏–∑–∞", 
                       text_length=len(text),
                       user_id=user_context.get('user_id') if user_context else None)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
            word_count = len(text.split())
            if word_count < 100:
                logger.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è Watson", word_count=word_count)
                return {
                    "error": f"–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 100 —Å–ª–æ–≤ –¥–ª—è Watson –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ–ª—É—á–µ–Ω–æ: {word_count})",
                    "status": "insufficient_text",
                    "word_count": word_count,
                    "fallback": True
                }
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ (Watson SDK —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π)
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                self._sync_analyze, 
                text
            )
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = self._process_watson_response(response, text, user_context)
            
            logger.info("‚úÖ Watson –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω", 
                       confidence=result.get('confidence_score', 0),
                       traits_count=len(result.get('big_five_traits', {})))
            
            return result
            
        except ApiException as e:
            logger.error("‚ùå Watson API –æ—à–∏–±–∫–∞", 
                        error_code=e.code, 
                        error_message=e.message,
                        exc_info=True)
            return {
                "error": f"Watson API –æ—à–∏–±–∫–∞: {e.message}",
                "error_code": e.code,
                "status": "api_error",
                "fallback": True
            }
        except Exception as e:
            logger.error("‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ Watson", error=str(e), exc_info=True)
            return {
                "error": f"–û—à–∏–±–∫–∞ Watson –∞–Ω–∞–ª–∏–∑–∞: {str(e)}",
                "status": "unexpected_error",
                "fallback": True
            }
    
    def _sync_analyze(self, text: str) -> Dict[str, Any]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ Watson API"""
        profile = self.client.profile(
            content=text,
            content_type='text/plain',
            consumption_preferences=True,
            raw_scores=True
        ).get_result()
        return profile
    
    def _process_watson_response(self, 
                                response: Dict[str, Any], 
                                original_text: str,
                                user_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ Watson –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        
        try:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ Big Five —á–µ—Ä—Ç
            big_five_traits = {}
            personality = response.get('personality', [])
            
            trait_mapping = {
                'big5_openness': 'openness',
                'big5_conscientiousness': 'conscientiousness', 
                'big5_extraversion': 'extraversion',
                'big5_agreeableness': 'agreeableness',
                'big5_neuroticism': 'neuroticism'
            }
            
            for trait in personality:
                trait_id = trait.get('trait_id')
                if trait_id in trait_mapping:
                    trait_name = trait_mapping[trait_id]
                    percentile = trait.get('percentile', 0) * 100  # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
                    raw_score = trait.get('raw_score', 0)
                    
                    big_five_traits[trait_name] = {
                        "percentile": round(percentile, 1),
                        "raw_score": round(raw_score, 3),
                        "description": self._get_trait_description(trait_name, percentile),
                        "level": self._get_trait_level(percentile),
                        "facets": self._extract_facets(trait)
                    }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π (Needs)
            needs = {}
            for need in response.get('needs', []):
                need_id = need.get('trait_id', '').replace('need_', '')
                percentile = need.get('percentile', 0) * 100
                needs[need_id] = {
                    "percentile": round(percentile, 1),
                    "name": need.get('name', need_id),
                    "description": self._get_need_description(need_id, percentile)
                }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω–Ω–æ—Å—Ç–µ–π (Values)
            values = {}
            for value in response.get('values', []):
                value_id = value.get('trait_id', '').replace('value_', '')
                percentile = value.get('percentile', 0) * 100
                values[value_id] = {
                    "percentile": round(percentile, 1),
                    "name": value.get('name', value_id),
                    "description": self._get_value_description(value_id, percentile)
                }
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è
            consumption_preferences = {}
            for category in response.get('consumption_preferences', []):
                category_name = category.get('consumption_preference_category_id', '').replace('consumption_preferences_', '')
                preferences = []
                
                for pref in category.get('consumption_preferences', []):
                    preferences.append({
                        "preference_id": pref.get('consumption_preference_id', ''),
                        "name": pref.get('name', ''),
                        "score": pref.get('score', 0)
                    })
                
                consumption_preferences[category_name] = {
                    "category_name": category.get('name', category_name),
                    "preferences": preferences
                }
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            word_count = response.get('word_count', len(original_text.split()))
            warnings = response.get('warnings', [])
            
            # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ confidence score
            confidence_score = self._calculate_confidence_score(word_count, warnings, big_five_traits)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤
            main_insights = self._generate_main_insights(big_five_traits, needs, values)
            
            # –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                "service": "watson",
                "status": "success",
                "confidence_score": confidence_score,
                "word_count": word_count,
                "warnings": [w.get('message', str(w)) for w in warnings],
                
                # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                "big_five_traits": big_five_traits,
                "psychological_needs": needs,
                "core_values": values,
                "consumption_preferences": consumption_preferences,
                
                # –ê–Ω–∞–ª–∏–∑ –∏ –∏–Ω—Å–∞–π—Ç—ã
                "main_insights": main_insights,
                "personality_summary": self._create_personality_summary(big_five_traits),
                "behavioral_predictions": self._generate_behavioral_predictions(big_five_traits, needs, values),
                
                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                "analysis_metadata": {
                    "watson_version": "2017-10-13",
                    "text_length": len(original_text),
                    "analysis_timestamp": asyncio.get_event_loop().time(),
                    "user_context": user_context
                },
                
                # –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                "raw_response": response
            }
            
            return result
            
        except Exception as e:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Watson –æ—Ç–≤–µ—Ç–∞", error=str(e), exc_info=True)
            return {
                "error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Watson –¥–∞–Ω–Ω—ã—Ö: {str(e)}",
                "status": "processing_error",
                "fallback": True,
                "raw_response": response
            }
    
    def _extract_facets(self, trait: Dict[str, Any]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞—Å–µ—Ç–æ–≤ —á–µ—Ä—Ç –ª–∏—á–Ω–æ—Å—Ç–∏"""
        facets = {}
        for child in trait.get('children', []):
            facet_id = child.get('trait_id', '')
            percentile = child.get('percentile', 0) * 100
            facets[facet_id] = {
                "percentile": round(percentile, 1),
                "name": child.get('name', facet_id),
                "description": f"–£—Ä–æ–≤–µ–Ω—å: {self._get_trait_level(percentile)}"
            }
        return facets
    
    def _get_trait_description(self, trait_name: str, percentile: float) -> str:
        """–û–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä—Ç –ª–∏—á–Ω–æ—Å—Ç–∏ Big Five"""
        descriptions = {
            "openness": {
                "high": "–û—Ç–∫—Ä—ã—Ç –∫ –Ω–æ–≤–æ–º—É –æ–ø—ã—Ç—É, –∫—Ä–µ–∞—Ç–∏–≤–µ–Ω, –ª—é–±–æ–∑–Ω–∞—Ç–µ–ª–µ–Ω",
                "medium": "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –Ω–æ–≤–∏–∑–Ω–µ –∏ —Ç—Ä–∞–¥–∏—Ü–∏—è–º", 
                "low": "–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –∑–Ω–∞–∫–æ–º–æ–µ –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ, –ø—Ä–∞–∫—Ç–∏—á–µ–Ω"
            },
            "conscientiousness": {
                "high": "–û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω, –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∏—Ä–æ–≤–∞–Ω, —Ü–µ–ª–µ—É—Å—Ç—Ä–µ–º–ª–µ–Ω",
                "medium": "–£–º–µ—Ä–µ–Ω–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω, –≥–∏–±–∫–∏–π –≤ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏",
                "low": "–°–ø–æ–Ω—Ç–∞–Ω–µ–Ω, –∞–¥–∞–ø—Ç–∏–≤–µ–Ω, –º–µ–Ω–µ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω"
            },
            "extraversion": {
                "high": "–û–±—â–∏—Ç–µ–ª—å–Ω—ã–π, —ç–Ω–µ—Ä–≥–∏—á–Ω—ã–π, –ª—é–±–∏—Ç –±—ã—Ç—å –≤ —Ü–µ–Ω—Ç—Ä–µ –≤–Ω–∏–º–∞–Ω–∏—è",
                "medium": "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–æ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å, –∞–º–±–∏–≤–µ—Ä—Ç",
                "low": "–ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ, —Ä–µ—Ñ–ª–µ–∫—Å–∏–≤–µ–Ω, —Å–¥–µ—Ä–∂–∞–Ω"
            },
            "agreeableness": {
                "high": "–î–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π, –æ—Ç–∑—ã–≤—á–∏–≤—ã–π, —Å–∫–ª–æ–Ω–µ–Ω –∫ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤—É",
                "medium": "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –ª—é–¥—è–º",
                "low": "–ù–µ–∑–∞–≤–∏—Å–∏–º—ã–π, –ø—Ä—è–º–æ–ª–∏–Ω–µ–π–Ω—ã–π, —Å–∫–µ–ø—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π"
            },
            "neuroticism": {
                "high": "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π, —Å–∫–ª–æ–Ω–µ–Ω –∫ –±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤—É",
                "medium": "–£–º–µ—Ä–µ–Ω–Ω–∞—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ä–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
                "low": "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π, —Å–ø–æ–∫–æ–π–Ω—ã–π, —É—Å—Ç–æ–π—á–∏–≤—ã–π –∫ —Å—Ç—Ä–µ—Å—Å—É"
            }
        }
        
        level = self._get_trait_level(percentile)
        return descriptions.get(trait_name, {}).get(level, f"–£—Ä–æ–≤–µ–Ω—å {trait_name}: {level}")
    
    def _get_trait_level(self, percentile: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —á–µ—Ä—Ç—ã"""
        if percentile >= 70:
            return "high"
        elif percentile >= 30:
            return "medium"
        else:
            return "low"
    
    def _get_need_description(self, need_id: str, percentile: float) -> str:
        """–û–ø–∏—Å–∞–Ω–∏–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π"""
        need_descriptions = {
            "challenge": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –∏ –∏—Å–ø—ã—Ç–∞–Ω–∏—è—Ö",
            "closeness": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ –±–ª–∏–∑–æ—Å—Ç–∏ –∏ –∏–Ω—Ç–∏–º–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö",
            "curiosity": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –∏ –ø–æ–∑–Ω–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ",
            "excitement": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ –æ—Å—Ç—Ä—ã—Ö –æ—â—É—â–µ–Ω–∏—è—Ö –∏ –ø—Ä–∏–∫–ª—é—á–µ–Ω–∏—è—Ö",
            "harmony": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ –≥–∞—Ä–º–æ–Ω–∏–∏ –∏ –∏–∑–±–µ–≥–∞–Ω–∏–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤",
            "ideal": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–µ –∏ –≤—ã—Å–æ–∫–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞—Ö",
            "liberty": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ —Å–≤–æ–±–æ–¥–µ –∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏",
            "love": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ –ª—é–±–≤–∏ –∏ –ø—Ä–∏–Ω—è—Ç–∏–∏",
            "practicality": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ—Å—Ç–∏ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
            "self_expression": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ —Å–∞–º–æ–≤—ã—Ä–∞–∂–µ–Ω–∏–∏ –∏ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏",
            "stability": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏",
            "structure": "–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"
        }
        
        base_desc = need_descriptions.get(need_id, f"–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ {need_id}")
        level = "–≤—ã—Å–æ–∫–∞—è" if percentile >= 70 else "—É–º–µ—Ä–µ–Ω–Ω–∞—è" if percentile >= 30 else "–Ω–∏–∑–∫–∞—è"
        return f"{base_desc} ({level} –≤–∞–∂–Ω–æ—Å—Ç—å)"
    
    def _get_value_description(self, value_id: str, percentile: float) -> str:
        """–û–ø–∏—Å–∞–Ω–∏–µ —Ü–µ–Ω–Ω–æ—Å—Ç–µ–π"""
        value_descriptions = {
            "conservation": "–¶–µ–Ω–Ω–æ—Å—Ç—å —Ç—Ä–∞–¥–∏—Ü–∏–π, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏",
            "openness_to_change": "–¶–µ–Ω–Ω–æ—Å—Ç—å –Ω–æ–≤–∏–∑–Ω—ã, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è",
            "hedonism": "–¶–µ–Ω–Ω–æ—Å—Ç—å —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏—è –∏ –Ω–∞—Å–ª–∞–∂–¥–µ–Ω–∏—è –∂–∏–∑–Ω—å—é",
            "self_enhancement": "–¶–µ–Ω–Ω–æ—Å—Ç—å –ª–∏—á–Ω—ã—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π –∏ —É—Å–ø–µ—Ö–∞",
            "self_transcendence": "–¶–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–º–æ—â–∏ –¥—Ä—É–≥–∏–º –∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–π —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏"
        }
        
        base_desc = value_descriptions.get(value_id, f"–¶–µ–Ω–Ω–æ—Å—Ç—å {value_id}")
        level = "–æ—á–µ–Ω—å –≤–∞–∂–Ω–∞" if percentile >= 70 else "—É–º–µ—Ä–µ–Ω–Ω–æ –≤–∞–∂–Ω–∞" if percentile >= 30 else "–º–µ–Ω–µ–µ –≤–∞–∂–Ω–∞"
        return f"{base_desc} ({level})"
    
    def _calculate_confidence_score(self, 
                                  word_count: int, 
                                  warnings: List[Dict], 
                                  big_five_traits: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö Watson"""
        base_confidence = 85.0
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ –º–∞–ª–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
        if word_count < 600:
            base_confidence -= (600 - word_count) * 0.05
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        base_confidence -= len(warnings) * 5
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö
        if len(big_five_traits) == 5:
            base_confidence += 5
        
        return max(50.0, min(95.0, base_confidence))
    
    def _generate_main_insights(self, 
                               big_five_traits: Dict[str, Any],
                               needs: Dict[str, Any], 
                               values: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤"""
        insights = {
            "dominant_traits": [],
            "key_motivators": [],
            "behavioral_tendencies": [],
            "strengths": [],
            "growth_areas": []
        }
        
        # –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —á–µ—Ä—Ç—ã (> 70 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)
        for trait_name, trait_data in big_five_traits.items():
            percentile = trait_data.get('percentile', 0)
            if percentile >= 70:
                insights["dominant_traits"].append({
                    "trait": trait_name,
                    "percentile": percentile,
                    "description": trait_data.get('description', '')
                })
        
        # –ö–ª—é—á–µ–≤—ã–µ –º–æ—Ç–∏–≤–∞—Ç–æ—Ä—ã (—Ç–æ–ø –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏)
        sorted_needs = sorted(needs.items(), key=lambda x: x[1]['percentile'], reverse=True)
        insights["key_motivators"] = [
            {"need": need_id, "strength": need_data['percentile'], "description": need_data['description']}
            for need_id, need_data in sorted_needs[:3]
        ]
        
        return insights
    
    def _create_personality_summary(self, big_five_traits: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ —Ä–µ–∑—é–º–µ –ª–∏—á–Ω–æ—Å—Ç–∏"""
        high_traits = []
        low_traits = []
        
        trait_names_ru = {
            "openness": "–æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å",
            "conscientiousness": "–¥–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω–æ—Å—Ç—å",
            "extraversion": "—ç–∫—Å—Ç—Ä–∞–≤–µ—Ä—Å–∏—è", 
            "agreeableness": "–¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
            "neuroticism": "–Ω–µ–π—Ä–æ—Ç–∏–∑–º"
        }
        
        for trait_name, trait_data in big_five_traits.items():
            percentile = trait_data.get('percentile', 0)
            trait_ru = trait_names_ru.get(trait_name, trait_name)
            
            if percentile >= 70:
                high_traits.append(trait_ru)
            elif percentile <= 30:
                low_traits.append(trait_ru)
        
        summary = "–ü—Ä–æ—Ñ–∏–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏ –ø–æ Watson: "
        
        if high_traits:
            summary += f"–≤—ã—Å–æ–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø–æ {', '.join(high_traits)}"
        
        if low_traits:
            if high_traits:
                summary += f", –Ω–∏–∑–∫–∏–µ –ø–æ {', '.join(low_traits)}"
            else:
                summary += f"–Ω–∏–∑–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø–æ {', '.join(low_traits)}"
        
        if not high_traits and not low_traits:
            summary += "—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å —Å —É–º–µ—Ä–µ–Ω–Ω—ã–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏"
        
        return summary
    
    def _generate_behavioral_predictions(self, 
                                       big_five_traits: Dict[str, Any],
                                       needs: Dict[str, Any],
                                       values: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        predictions = []
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Big Five
        for trait_name, trait_data in big_five_traits.items():
            percentile = trait_data.get('percentile', 0)
            level = trait_data.get('level', 'medium')
            
            if trait_name == "conscientiousness" and level == "high":
                predictions.append("–°–∫–ª–æ–Ω–µ–Ω –∫ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –∏ —Å–æ–±–ª—é–¥–µ–Ω–∏—é –¥–µ–¥–ª–∞–π–Ω–æ–≤")
            elif trait_name == "extraversion" and level == "high": 
                predictions.append("–ê–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è")
            elif trait_name == "openness" and level == "high":
                predictions.append("–û—Ç–∫—Ä—ã—Ç –∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º –∏ –Ω–æ–≤—ã–º –∏–¥–µ—è–º")
        
        return predictions[:5]  # –¢–æ–ø 5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    
    async def validate_api_connection(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Watson API"""
        if not self.is_available:
            return {"status": "unavailable", "error": "API –∫–ª—é—á–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã"}
        
        try:
            # –¢–µ—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            test_text = "This is a test message for Watson API validation. " * 20  # ~100 —Å–ª–æ–≤
            
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                self._sync_analyze,
                test_text
            )
            
            return {
                "status": "connected",
                "version": "2017-10-13",
                "word_count": response.get('word_count', 0),
                "traits_detected": len(response.get('personality', []))
            }
            
        except Exception as e:
            return {
                "status": "error", 
                "error": str(e),
                "error_type": type(e).__name__
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞
watson_client = WatsonClient() 