"""AI service for text analysis using Claude Sonnet 4 via OpenRouter"""

import asyncio
import json
import time
from typing import Dict, Any, Optional, List

import httpx
from loguru import logger

from app.core.config import settings
from app.core.redis import redis_client
from app.utils.exceptions import AIServiceError
from app.utils.helpers import safe_json_loads, create_cache_key, extract_json_from_text
from app.prompts.analysis_prompts import (
    ANALYSIS_SYSTEM_PROMPT,
    COMPATIBILITY_SYSTEM_PROMPT,
    get_text_analysis_prompt,
    get_compatibility_prompt
)
from app.utils.enums import UrgencyLevel
import traceback


class AIService:
    """–ü—Ä–æ—Å—Ç–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π AI —Å–µ—Ä–≤–∏—Å —Å Claude Sonnet 4"""
    
    def __init__(self):
        # OpenRouter API configuration
        self.openrouter_api_key = settings.OPENAI_API_KEY  # –ò—Å–ø–æ–ª—å–∑—É–µ–º OPENAI_API_KEY –¥–ª—è OpenRouter
        self.openrouter_base_url = "https://openrouter.ai/api/v1"
        self.model = "anthropic/claude-sonnet-4"
        
        # Request limiting
        self._request_semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_AI_REQUESTS)
        self._last_request_time = 0
        self._last_model_used = self.model
        
        logger.info(f"‚úÖ AIService initialized with {self.model}")
    
    def _get_last_model_used(self) -> str:
        """Get the last model used for analysis"""
        return self._last_model_used
    
    async def _rate_limit(self):
        """Simple rate limiting"""
        current_time = time.time()
        time_since_last = current_time - self._last_request_time
        if time_since_last < settings.AI_RATE_LIMIT_SECONDS:
            await asyncio.sleep(settings.AI_RATE_LIMIT_SECONDS - time_since_last)
        self._last_request_time = time.time()
    
    async def _get_ai_response(
        self,
        system_prompt: str,
        user_prompt: str,
        response_format: str = "text",
        max_tokens: int = 4000,
        temperature: float = 0.7
    ) -> str:
        """Get response from Claude Sonnet 4 via OpenRouter"""
        
        if not self.openrouter_api_key:
            raise AIServiceError("OpenRouter API key –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
        if not self.openrouter_api_key.startswith('sk-or-'):
            raise AIServiceError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç OpenRouter API –∫–ª—é—á–∞")
        
        await self._rate_limit()
        
        headers = {
            "Authorization": f"Bearer {self.openrouter_api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://psychodetective.ai",
            "X-Title": "PsychoDetective AI"
        }
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        data = {
            "model": self.model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "stream": False
        }
        
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{self.openrouter_base_url}/chat/completions",
                    headers=headers,
                    json=data
                )
                
                if response.status_code != 200:
                    error_text = response.text
                    logger.error(f"OpenRouter API error {response.status_code}: {error_text}")
                    raise AIServiceError(f"OpenRouter API –æ—à–∏–±–∫–∞: {response.status_code}")
                
                result = response.json()
                
                if 'choices' not in result or not result['choices']:
                    logger.error(f"Invalid OpenRouter response: {result}")
                    raise AIServiceError("–ù–µ–≤–µ—Ä–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenRouter API")
                
                content = result['choices'][0]['message']['content']
                logger.info(f"‚úÖ OpenRouter response received: {len(content)} chars")
                
                return content
                
        except httpx.TimeoutException:
            logger.error("OpenRouter API timeout")
            raise AIServiceError("–¢–∞–π–º–∞—É—Ç OpenRouter API")
        except Exception as e:
            logger.error(f"OpenRouter API error: {e}")
            raise AIServiceError(f"–û—à–∏–±–∫–∞ OpenRouter API: {str(e)}")
    
    async def analyze_text(
        self,
        text: str,
        analysis_type: str = "general",
        user_id: Optional[int] = None,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        start_time = time.time()
        
        # Cache key
        cache_key = create_cache_key("text_analysis", user_id or 0, hash(text + analysis_type))
        
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"üì¶ Text analysis cache hit")
                return cached_result
        
        try:
            # Create prompts
            system_prompt = ANALYSIS_SYSTEM_PROMPT
            user_prompt = get_text_analysis_prompt(text, analysis_type)
            
            # Get AI response
            async with self._request_semaphore:
                response = await self._get_ai_response(
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    response_format="json",
                    max_tokens=3000
                )
            
            # Parse response
            result = safe_json_loads(response)
            if not result:
                raise AIServiceError("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –æ—Ç–≤–µ—Ç AI")
            
            # Cache result
            if use_cache:
                await redis_client.set(cache_key, result, ex=3600)  # 1 hour
            
            logger.info(f"üìù Text analysis completed")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Text analysis failed: {e}")
            raise AIServiceError(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞: {str(e)}")
    
    async def profile_partner(
        self,
        answers: List[Dict[str, Any]],
        user_id: int,
        partner_name: str = "–ø–∞—Ä—Ç–Ω–µ—Ä",
        partner_description: str = "",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ä—Ç–Ω–µ—Ä–∞ —Å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ—Ä—Ç—Ä–µ—Ç–æ–º"""
        start_time = time.time()
        
        # Cache key
        cache_key = create_cache_key("profile_partner", user_id, 
                                   hash(str(answers) + partner_name + partner_description))
        
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"üì¶ Profile analysis cache hit for user {user_id}")
                return cached_result
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_data = {
                'questionnaire_data': {
                    f'question_{i}': {
                        'question': answer.get('question', f'–í–æ–ø—Ä–æ—Å {i}'),
                        'answer': answer.get('answer', str(answer))
                    } for i, answer in enumerate(answers, 1)
                },
                'partner_name': partner_name,
                'partner_description': partner_description
            }
            
            # Create enhanced prompts
            user_prompt = self._create_enhanced_user_prompt(analysis_data)
            
            # Get detailed analysis from Claude Sonnet 4
            async with self._request_semaphore:
                response = await self._get_ai_response(
                    system_prompt="",  # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤–∫–ª—é—á–µ–Ω –≤ user_prompt
                    user_prompt=user_prompt,
                    response_format="text",  # –¢–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
                    max_tokens=8000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                    temperature=0.7  # –ë–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                )
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
            metrics_prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–∞–π –∫—Ä–∞—Ç–∫—É—é –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–æ–≤ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:

–ü–ê–†–¢–ù–ï–†: {partner_name}
–û–¢–í–ï–¢–´: {str(answers)[:1000]}...

–í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏:
- overall_risk_score: —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 100 (–ø—Ä–æ—Ü–µ–Ω—Ç —Ä–∏—Å–∫–∞)
- urgency_level: "LOW", "MEDIUM", "HIGH", "CRITICAL" 
- block_scores: –æ–±—ä–µ–∫—Ç —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –æ—Ç 0 –¥–æ 10 –¥–ª—è narcissism, control, gaslighting, emotion, intimacy, social
- red_flags: –º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏
- personality_type: –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–∏–ø–∞ –ª–∏—á–Ω–æ—Å—Ç–∏

–ü—Ä–∏–º–µ—Ä:
{{"overall_risk_score": 75, "urgency_level": "HIGH", "block_scores": {{"narcissism": 8.5, "control": 7.2, "gaslighting": 6.8, "emotion": 7.5, "intimacy": 6.0, "social": 7.8}}, "red_flags": ["–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ", "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å"], "personality_type": "–ù–∞—Ä—Ü–∏—Å—Å–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª–µ—Ä"}}
"""
            
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            async with self._request_semaphore:
                metrics_response = await self._get_ai_response(
                    system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–ø—Å–∏—Ö–æ–ª–æ–≥. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.",
                    user_prompt=metrics_prompt,
                    response_format="json",
                    max_tokens=1000,
                    temperature=0.3
                )
            
            # –ü–∞—Ä—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏
            try:
                metrics_data = extract_json_from_text(metrics_response)
                if not metrics_data:
                    metrics_data = safe_json_loads(metrics_response, {})
            except:
                metrics_data = {}
            
            # –û—á–∏—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç markdown —Å–∏–º–≤–æ–ª–æ–≤
            cleaned_response = self._clean_markdown_formatting(response)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                "psychological_profile": cleaned_response,  # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
                "overall_risk_score": metrics_data.get("overall_risk_score", 50),
                "urgency_level": metrics_data.get("urgency_level", "MEDIUM"),
                "block_scores": metrics_data.get("block_scores", {
                    "narcissism": 5.0, "control": 5.0, "gaslighting": 5.0,
                    "emotion": 5.0, "intimacy": 5.0, "social": 5.0
                }),
                "red_flags": metrics_data.get("red_flags", ["–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è"]),
                "personality_type": metrics_data.get("personality_type", "–°–º–µ—à–∞–Ω–Ω—ã–π —Ç–∏–ø"),
                "processing_time": time.time() - start_time,
                "ai_model_used": self._get_last_model_used(),
                "analysis_mode": "detailed_portrait_with_metrics",
                "cost_estimate": 0.18,  # –£–≤–µ–ª–∏—á–µ–Ω–∞ –∏–∑-–∑–∞ –¥–≤—É—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                "word_count": len(response.split()),
                "character_count": len(response),
                "partner_name": partner_name
            }
            
            # Cache result
            if use_cache:
                await redis_client.set(cache_key, result, expire=settings.ANALYSIS_CACHE_TTL)
            
            logger.info(f"‚úÖ Profile analysis completed in {result['processing_time']:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Profile analysis failed: {e}")
            raise AIServiceError(f"–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {str(e)}")
    
    async def profile_partner_free_form(
        self,
        text_answers: List[Dict[str, Any]],
        user_id: int,
        partner_name: str = "–ø–∞—Ä—Ç–Ω–µ—Ä",
        partner_description: str = "",
        partner_basic_info: str = "",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ä—Ç–Ω–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–æ–±–æ–¥–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"""
        start_time = time.time()
        
        # Cache key
        cache_key = create_cache_key("profile_partner_free_form", user_id, 
                                   hash(str(text_answers) + partner_name + partner_description))
        
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"üì¶ Free form profile analysis cache hit for user {user_id}")
                return cached_result
        
        try:
            # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º—ã
            user_prompt = self._create_free_form_user_prompt(
                text_answers, partner_name, partner_description, partner_basic_info
            )
            
            # Get detailed analysis from Claude Sonnet 4
            async with self._request_semaphore:
                response = await self._get_ai_response(
                    system_prompt="",  # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤–∫–ª—é—á–µ–Ω –≤ user_prompt
                    user_prompt=user_prompt,
                    response_format="text",  # –¢–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
                    max_tokens=12000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                    temperature=0.7  # –ë–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                )
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            metrics_prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–∞–π –∫—Ä–∞—Ç–∫—É—é –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–æ–≤ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:

–ü–ê–†–¢–ù–ï–†: {partner_name}
–û–ü–ò–°–ê–ù–ò–ï: {partner_description}
–ë–ê–ó–û–í–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø: {partner_basic_info}

–î–ï–¢–ê–õ–¨–ù–´–ï –û–¢–í–ï–¢–´:
{self._format_text_answers_for_metrics(text_answers)}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç –∏ –≤–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏:
- overall_risk_score: —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 100 (–ø—Ä–æ—Ü–µ–Ω—Ç —Ä–∏—Å–∫–∞)
- urgency_level: "LOW", "MEDIUM", "HIGH", "CRITICAL" 
- block_scores: –æ–±—ä–µ–∫—Ç —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –æ—Ç 0 –¥–æ 10 –¥–ª—è narcissism, control, gaslighting, emotion, intimacy, social
- red_flags: –º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏ (–º–∏–Ω–∏–º—É–º 5-7 —Ñ–ª–∞–≥–æ–≤)
- personality_type: –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–∏–ø–∞ –ª–∏—á–Ω–æ—Å—Ç–∏
- key_concerns: –º–∞—Å—Å–∏–≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –≤ –æ—Ç–≤–µ—Ç–∞—Ö

–ü—Ä–∏–º–µ—Ä:
{{"overall_risk_score": 75, "urgency_level": "HIGH", "block_scores": {{"narcissism": 8.5, "control": 7.2, "gaslighting": 6.8, "emotion": 7.5, "intimacy": 6.0, "social": 7.8}}, "red_flags": ["–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ", "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å", "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —ç–º–ø–∞—Ç–∏–∏"], "personality_type": "–ù–∞—Ä—Ü–∏—Å—Å–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª–µ—Ä", "key_concerns": ["–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ –∫—Ä–∏—Ç–∏–∫—É", "–ò–∑–æ–ª—è—Ü–∏—è –æ—Ç –¥—Ä—É–∑–µ–π"]}}
"""
            
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            async with self._request_semaphore:
                metrics_response = await self._get_ai_response(
                    system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–ø—Å–∏—Ö–æ–ª–æ–≥. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.",
                    user_prompt=metrics_prompt,
                    response_format="json",
                    max_tokens=1500,
                    temperature=0.3
                )
            
            # –ü–∞—Ä—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏
            try:
                metrics_data = extract_json_from_text(metrics_response)
                if not metrics_data:
                    metrics_data = safe_json_loads(metrics_response, {})
            except:
                metrics_data = {}
            
            # –û—á–∏—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç markdown —Å–∏–º–≤–æ–ª–æ–≤
            cleaned_response = self._clean_markdown_formatting(response)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = {
                "psychological_profile": cleaned_response,  # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
                "overall_risk_score": metrics_data.get("overall_risk_score", 50),
                "urgency_level": metrics_data.get("urgency_level", "MEDIUM"),
                "block_scores": metrics_data.get("block_scores", {
                    "narcissism": 5.0, "control": 5.0, "gaslighting": 5.0,
                    "emotion": 5.0, "intimacy": 5.0, "social": 5.0
                }),
                "red_flags": metrics_data.get("red_flags", ["–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è"]),
                "personality_type": metrics_data.get("personality_type", "–°–º–µ—à–∞–Ω–Ω—ã–π —Ç–∏–ø"),
                "key_concerns": metrics_data.get("key_concerns", ["–ù–µ–æ–±—Ö–æ–¥–∏–º –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑"]),
                "processing_time": time.time() - start_time,
                "ai_model_used": self._get_last_model_used(),
                "analysis_mode": "free_form_detailed_analysis",
                "cost_estimate": 0.25,  # –£–≤–µ–ª–∏—á–µ–Ω–∞ –∏–∑-–∑–∞ –±–æ–ª—å—à–µ–≥–æ –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö
                "word_count": len(response.split()),
                "character_count": len(response),
                "partner_name": partner_name,
                "text_answers_count": len(text_answers)
            }
            
            # Cache result
            if use_cache:
                await redis_client.set(cache_key, result, expire=settings.ANALYSIS_CACHE_TTL)
            
            logger.info(f"‚úÖ Free form profile analysis completed in {result['processing_time']:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Free form profile analysis failed: {e}")
            raise AIServiceError(f"–ê–Ω–∞–ª–∏–∑ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º—ã –Ω–µ —É–¥–∞–ª—Å—è: {str(e)}")
    
    def _create_free_form_user_prompt(self, text_answers: List[Dict[str, Any]], partner_name: str, partner_description: str, partner_basic_info: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–≤–æ–±–æ–¥–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"""
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã
        answers_text = ""
        for i, answer_data in enumerate(text_answers, 1):
            question = answer_data.get('question', f'–í–æ–ø—Ä–æ—Å {i}')
            answer = answer_data.get('answer', '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞')
            block = answer_data.get('block', 'unknown')
            
            answers_text += f"–í–û–ü–†–û–° {i} (–±–ª–æ–∫: {block}):\n{question}\n\n–û–¢–í–ï–¢:\n{answer}\n\n" + "="*50 + "\n\n"
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç
        user_prompt = f"""
–¢—ã - –≤–µ–¥—É—â–∏–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω–æ–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏ –∏ –ø—Ä–æ—Ñ–∞–π–ª–∏–Ω–≥—É —Å 25-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã —Å —Ç–æ–∫—Å–∏—á–Ω—ã–º–∏ –ª–∏—á–Ω–æ—Å—Ç—è–º–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—Ç—Ä–µ—Ç –ø–∞—Ä—Ç–Ω–µ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–ü–ê–†–¢–ù–ï–†: {partner_name}
–û–ü–ò–°–ê–ù–ò–ï: {partner_description}
–ë–ê–ó–û–í–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø: {partner_basic_info}

–î–ï–¢–ê–õ–¨–ù–´–ï –û–¢–í–ï–¢–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{answers_text}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:

1. –û–ë–™–ï–ú: –°–¢–†–û–ì–û 3000-3500 —Å–ª–æ–≤ (—ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞!)
2. –ü–ï–†–°–û–ù–ê–õ–ò–ó–ê–¶–ò–Ø: –£–ø–æ–º–∏–Ω–∞–π –∏–º—è {partner_name} –º–∏–Ω–∏–º—É–º 15-20 —Ä–∞–∑ –≤ —Ç–µ–∫—Å—Ç–µ
3. –¶–ò–¢–ê–¢–´: –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–Ø–ú–´–ï —Ü–∏—Ç–∞—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–∏–Ω–∏–º—É–º 25-30 —Ä–∞–∑
4. –°–¢–†–£–ö–¢–£–†–ê: –ë–ï–ó —Å–º–∞–π–ª–∏–∫–æ–≤, —Ä–µ—à–µ—Ç–æ–∫, –∑–≤–µ–∑–¥–æ—á–µ–∫, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π - —Ç–æ–ª—å–∫–æ –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
5. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–ò–ó–ú: –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–∏–ª—å, –Ω–∞—É—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
6. –î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø: –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –º–∏–Ω–∏–º—É–º 500-600 —Å–ª–æ–≤ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê (3000-3500 —Å–ª–æ–≤):

–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ü–û–†–¢–†–ï–¢: [–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏ {partner_name}]

–û–ë–©–ê–Ø –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ê –õ–ò–ß–ù–û–°–¢–ò

–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –∏–º–µ–Ω–∏ {partner_name}. –ú–æ–¥–µ–ª—å "–¢–µ–º–Ω–æ–π —Ç—Ä–∏–∞–¥—ã" —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –±–∞–ª–ª–∞–º–∏. –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Å –ø—Ä—è–º—ã–º–∏ —Ü–∏—Ç–∞—Ç–∞–º–∏. –í–ª–∏—è–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–∞ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —á–µ—Ä—Ç—ã. (600-700 —Å–ª–æ–≤)

–î–û–ú–ò–ù–ò–†–£–Æ–©–ò–ï –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–ê–¢–¢–ï–†–ù–´

–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —á–µ—Ä—Ç—ã {partner_name} —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏. –¢—Ä–∏–≥–≥–µ—Ä—ã –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è. –°–ø–æ—Å–æ–±—ã –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π –∏ –∫–æ–Ω—Ç—Ä–æ–ª—è. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ –µ—ë –ø—Ä–æ—è–≤–ª–µ–Ω–∏—è. (700-800 —Å–ª–æ–≤)

–ê–ù–ê–õ–ò–ó –û–¢–ù–û–®–ï–ù–ò–ô –ò –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–ô

–ö–∞–∫ {partner_name} —Å—Ç—Ä–æ–∏—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å —Ä–∞–∑–Ω—ã–º–∏ –ª—é–¥—å–º–∏. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ–±—â–µ–Ω–∏—è –≤ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö. –°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ —ç–º–ø–∞—Ç–∏–∏ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ. –†–µ–∞–∫—Ü–∏—è –Ω–∞ —É—Å–ø–µ—Ö–∏ –∏ –Ω–µ—É–¥–∞—á–∏ –æ–∫—Ä—É–∂–∞—é—â–∏—Ö. (600-700 —Å–ª–æ–≤)

–ö–†–ê–°–ù–´–ï –§–õ–ê–ì–ò –ò –ü–†–ï–î–£–ü–†–ï–ñ–î–ê–Æ–©–ò–ï –ó–ù–ê–ö–ò

–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –æ–ø–∞—Å–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è. –≠—Å–∫–∞–ª–∞—Ü–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –∏ –∞–≥—Ä–µ—Å—Å–∏–∏. –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –Ω–∞—Å–∏–ª–∏—è. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ä–∏—Å–∫–∏ –¥–ª—è –ø–∞—Ä—Ç–Ω–µ—Ä–∞. (500-600 —Å–ª–æ–≤)

–ü–†–û–ì–ù–û–ó –†–ê–ó–í–ò–¢–ò–Ø –û–¢–ù–û–®–ï–ù–ò–ô

–í–µ—Ä–æ—è—Ç–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Ä–∞–∑–≤–∏—Ç–∏—è —Å–æ–±—ã—Ç–∏–π. –†–∏—Å–∫–∏ –¥–ª—è —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –∏ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∑–¥–æ—Ä–æ–≤—å—è. –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è {partner_name}. –í–ª–∏—è–Ω–∏–µ –Ω–∞ –¥–µ—Ç–µ–π –∏ —Å–µ–º—å—é. (600-700 —Å–ª–æ–≤)

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ò –°–¢–†–ê–¢–ï–ì–ò–ò –ó–ê–©–ò–¢–´

–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —à–∞–≥–∏ –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –¢–µ—Ö–Ω–∏–∫–∏ –æ–±—â–µ–Ω–∏—è —Å {partner_name}. –ö–æ–≥–¥–∞ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∑–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø–æ–º–æ—â—å—é. –ü–ª–∞–Ω—ã –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π. (500-600 —Å–ª–æ–≤)

–í–ê–ñ–ù–û:
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
- –ü—Ä–∏–≤–æ–¥–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è
- –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Ü–∏—Ç–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –î–µ–ª–∞–π –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –≤—ã–≤–æ–¥—ã
- –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä—É–π –∞–Ω–∞–ª–∏–∑ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–∞—Ä—Ç–Ω–µ—Ä–∞

–°–æ–∑–¥–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä—Ç—Ä–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.
"""
        
        return user_prompt
    
    def _format_text_answers_for_metrics(self, text_answers: List[Dict[str, Any]]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç—Ä–∏–∫"""
        formatted = ""
        for i, answer_data in enumerate(text_answers, 1):
            question = answer_data.get('question', f'–í–æ–ø—Ä–æ—Å {i}')
            answer = answer_data.get('answer', '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞')
            block = answer_data.get('block', 'unknown')
            
            formatted += f"–í–æ–ø—Ä–æ—Å {i} ({block}): {question}\n–û—Ç–≤–µ—Ç: {answer}\n\n"
        
        return formatted
    
    async def check_compatibility(
        self,
        user_profile: Dict[str, Any],
        partner_profile: Dict[str, Any],
        user_id: Optional[int] = None,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        start_time = time.time()
        
        # Cache key
        cache_key = create_cache_key("compatibility", user_id or 0, 
                                   hash(str(user_profile) + str(partner_profile)))
        
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"üì¶ Compatibility analysis cache hit")
                return cached_result
        
        try:
            # Create prompts
            system_prompt = COMPATIBILITY_SYSTEM_PROMPT
            user_prompt = get_compatibility_prompt(user_profile, partner_profile)
            
            # Get AI response
            async with self._request_semaphore:
                response = await self._get_ai_response(
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    response_format="json",
                    max_tokens=3000
                )
            
            # Parse response
            result = self._parse_compatibility_response(response)
            result["processing_time"] = time.time() - start_time
            result["ai_model_used"] = self._get_last_model_used()
            
            # Cache result
            if use_cache:
                await redis_client.set(cache_key, result, expire=settings.ANALYSIS_CACHE_TTL)
            
            logger.info(f"‚úÖ Compatibility analysis completed in {result['processing_time']:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Compatibility analysis failed: {e}")
            raise AIServiceError(f"–ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –Ω–µ —É–¥–∞–ª—Å—è: {str(e)}")
    
    def _create_enhanced_system_prompt(self) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        return """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–ø—Å–∏—Ö–æ–ª–æ–≥ —Å 15-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º –∞–Ω–∞–ª–∏–∑–∞ –ª–∏—á–Ω–æ—Å—Ç–∏ –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏–π. 

–¢–≤–æ—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:
- –ö–ª–∏–Ω–∏—á–µ—Å–∫–∞—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤ –ª–∏—á–Ω–æ—Å—Ç–∏
- –°–µ–º–µ–π–Ω–∞—è —Ç–µ—Ä–∞–ø–∏—è –∏ –∞–Ω–∞–ª–∏–∑ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π  
- –ö—Ä–∏–º–∏–Ω–∞–ª—å–Ω–∞—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è –∏ –ø—Ä–æ—Ñ–∞–π–ª–∏–Ω–≥
- –ù–µ–π—Ä–æ–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è –∏ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

–í–ê–ñ–ù–û: 
- –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
- –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–µ–Ω –∏ –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –≤ –æ—Ü–µ–Ω–∫–∞—Ö
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
- –£–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –∫—Ä–∞—Å–Ω—ã–µ —Ñ–ª–∞–≥–∏"""
    
    def _create_enhanced_user_prompt(self, analysis_data: dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∫–µ—Ç—ã"""
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        system_prompt = """
–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫—Ä–∏–º–∏–Ω–∞–ª—å–Ω–æ–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏ –∏ –ø—Ä–æ—Ñ–∞–π–ª–∏–Ω–≥—É —Å 20-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã —Å —Ç–æ–∫—Å–∏—á–Ω—ã–º–∏ –ª–∏—á–Ω–æ—Å—Ç—è–º–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞–≤–∞—Ç—å –≥–ª—É–±–æ–∫–∏–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–æ—Ä—Ç—Ä–µ—Ç—ã –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã.

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ü–û–†–¢–†–ï–¢–£:

1. –û–ë–™–ï–ú: 2000-2500 —Å–ª–æ–≤ (—ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ!)
2. –Ø–ó–´–ö: –ù–∞—É—á–Ω–æ-–ø–æ–ø—É–ª—è—Ä–Ω—ã–π, –¥–æ—Å—Ç—É–ø–Ω—ã–π —Ä—É—Å—Å–∫–æ–º—É —á–∏—Ç–∞—Ç–µ–ª—é
3. –°–¢–†–£–ö–¢–£–†–ê: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —ç–º–æ–¥–∑–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
4. –ü–†–ò–ú–ï–†–´: –ú–∏–Ω–∏–º—É–º 5-7 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏–π —Å –∏–º–µ–Ω–∞–º–∏ –∏ –¥–µ—Ç–∞–ª—è–º–∏
5. –ù–ê–£–ß–ù–û–°–¢–¨: –°—Å—ã–ª–∫–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ –º–æ–¥–µ–ª–∏

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –ü–û–†–¢–†–ï–¢–ê:

–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ü–û–†–¢–†–ï–¢: "[–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏]"

–û–ë–©–ê–Ø –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ê –õ–ò–ß–ù–û–°–¢–ò
- –ü–µ—Ä–≤–æ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ vs —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å
- –û—Ü–µ–Ω–∫–∞ –ø–æ –º–æ–¥–µ–ª–∏ "–¢–µ–º–Ω–æ–π —Ç—Ä–∏–∞–¥—ã" (–Ω–∞—Ä—Ü–∏—Å—Å–∏–∑–º/–º–∞–∫–∏–∞–≤–µ–ª–ª–∏–∑–º/–ø—Å–∏—Ö–æ–ø–∞—Ç–∏—è)
- –ö–ª—é—á–µ–≤—ã–µ –ª–∏—á–Ω–æ—Å—Ç–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

–û–°–ù–û–í–ù–û–ô –ü–ê–¢–¢–ï–†–ù –ü–û–í–ï–î–ï–ù–ò–Ø –í –û–¢–ù–û–®–ï–ù–ò–Ø–•
- –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π —Ç–æ–∫—Å–∏—á–Ω–æ–π —á–µ—Ä—Ç—ã
- 2-3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞ —Å –∏–º–µ–Ω–∞–º–∏ –∏ —Å–∏—Ç—É–∞—Ü–∏—è–º–∏
- –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã

–ö–û–ù–¢–†–û–õ–ò–†–£–Æ–©–ï–ï –ü–û–í–ï–î–ï–ù–ò–ï
- –≠–≤–æ–ª—é—Ü–∏—è –∫–æ–Ω—Ç—Ä–æ–ª—è: –æ—Ç "–∑–∞–±–æ—Ç—ã" –∫ —Ç–æ—Ç–∞–ª—å–Ω–æ–º—É –Ω–∞–¥–∑–æ—Ä—É
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –∫–æ–Ω—Ç—Ä–æ–ª—è
- –ò—Å—Ç–æ—Ä–∏—è –∏–∑ –∂–∏–∑–Ω–∏ —Å –¥–µ—Ç–∞–ª—è–º–∏

–ú–ê–ù–ò–ü–£–õ–Ø–¢–ò–í–ù–´–ï –¢–ï–•–ù–ò–ö–ò
- –ì–∞–∑–ª–∞–π—Ç–∏–Ω–≥ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ —Ñ—Ä–∞–∑
- –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —à–∞–Ω—Ç–∞–∂
- –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤

–≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–ê–Ø –î–ò–ó–†–ï–ì–£–õ–Ø–¶–ò–Ø
- –ù–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç—å —Ä–µ–∞–∫—Ü–∏–π
- –î–≤–æ–π–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
- –ü—Ä–æ–µ–∫—Ü–∏—è –∏ –æ–±–≤–∏–Ω–µ–Ω–∏—è

–ò–ù–¢–ò–ú–ù–û–°–¢–¨ –ö–ê–ö –ò–ù–°–¢–†–£–ú–ï–ù–¢
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–ª–∏–∑–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è
- –¢—Ä–∞–≤–º–∞—Ç–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã

–°–û–¶–ò–ê–õ–¨–ù–ê–Ø –ú–ê–°–ö–ê
- –ü—É–±–ª–∏—á–Ω—ã–π –æ–±—Ä–∞–∑ vs —á–∞—Å—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
- –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–∏—Å—Å–æ–Ω–∞–Ω—Å —É –ø–∞—Ä—Ç–Ω–µ—Ä–∞
- –ü—Ä–∏–º–µ—Ä—ã –¥–≤–æ–π—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏

–ü–†–û–ì–ù–û–ó –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
- –°–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º
- –¶–∏–∫–ª–∏—á–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–∞—Ä—Ç–Ω–µ—Ä–∞–º

–°–¢–ò–õ–ò–°–¢–ò–ß–ï–°–ö–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:

1. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö (–ê–Ω–Ω–∞, –ú–∞—Ä–∏–Ω–∞, –ï–ª–µ–Ω–∞ –∏ —Ç.–¥.)
2. –í–∫–ª—é—á–∞–π –ø—Ä—è–º—É—é —Ä–µ—á—å –∏ —Ü–∏—Ç–∞—Ç—ã ("—Ñ—Ä–∞–∑—ã –≤ –∫–∞–≤—ã—á–∫–∞—Ö")
3. –û–ø–∏—Å—ã–≤–∞–π —Ñ–∏–∑–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∞–∫—Ü–∏–∏ –∏ –Ω–µ–≤–µ—Ä–±–∞–ª–∏–∫—É
4. –°—Å—ã–ª–∞–π—Å—è –Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ –∞–≤—Ç–æ—Ä–æ–≤ (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ)
5. –ò—Å–ø–æ–ª—å–∑—É–π –º–µ—Ç–∞—Ñ–æ—Ä—ã –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
6. –ß–µ—Ä–µ–¥—É–π –¥–ª–∏–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∞–±–∑–∞—Ü—ã —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –≤—ã–≤–æ–¥–∞–º–∏

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ï –ö–û–ù–¶–ï–ü–¶–ò–ò:
- –ú–æ–¥–µ–ª—å "–¢–µ–º–Ω–æ–π —Ç—Ä–∏–∞–¥—ã"
- –¢–µ–æ—Ä–∏—è –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏
- –¶–∏–∫–ª –∞–±—å—é–∑–∞
- –ì–∞–∑–ª–∞–π—Ç–∏–Ω–≥
- –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –¥–∏–∑—Ä–µ–≥—É–ª—è—Ü–∏—è
- –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–∏—Å—Å–æ–Ω–∞–Ω—Å
- –ü—Ä–æ–µ–∫—Ü–∏—è –∏ –¥—Ä—É–≥–∏–µ –∑–∞—â–∏—Ç–Ω—ã–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã

–ó–ê–ü–†–ï–©–ï–ù–û:
- –ü–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã–µ –æ–±–æ–±—â–µ–Ω–∏—è
- –ö–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã –±–µ–∑ –ø—Ä–∏–º–µ—Ä–æ–≤
- –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏
- –ò–∑–ª–∏—à–Ω—è—è –Ω–∞—É—á–Ω–æ—Å—Ç—å –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
- –ü–æ—Ä—Ç—Ä–µ—Ç—ã –∫–æ—Ä–æ—á–µ 2000 —Å–ª–æ–≤
"""

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        answers_text = ""
        partner_name = "–ø–∞—Ä—Ç–Ω–µ—Ä"
        partner_description = ""
        
        questionnaire_data = analysis_data.get('questionnaire_data', {})
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –ø–∞—Ä—Ç–Ω–µ—Ä–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if 'partner_name' in analysis_data:
            partner_name = analysis_data['partner_name']
        if 'partner_description' in analysis_data:
            partner_description = analysis_data['partner_description']
        
        for question_id, answer_data in questionnaire_data.items():
            if isinstance(answer_data, dict):
                question = answer_data.get('question', f'–í–æ–ø—Ä–æ—Å {question_id}')
                answer = answer_data.get('answer', '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞')
                answers_text += f"–í–æ–ø—Ä–æ—Å: {question}\n–û—Ç–≤–µ—Ç: {answer}\n\n"
            else:
                answers_text += f"–í–æ–ø—Ä–æ—Å {question_id}: {answer_data}\n\n"
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç —Å –¥–∞–Ω–Ω—ã–º–∏
        user_prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å–æ–∑–¥–∞–π –≥–ª—É–±–æ–∫–∏–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—Ç—Ä–µ—Ç –ø–∞—Ä—Ç–Ω–µ—Ä–∞.

–ü–ê–†–¢–ù–ï–†: {partner_name} ({partner_description})

[–û–¢–í–ï–¢–´ –ù–ê –í–û–ü–†–û–°–´]
{answers_text}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:

1. –û–ë–™–ï–ú: –°–¢–†–û–ì–û 2400-2700 —Å–ª–æ–≤ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø—Ä–æ–≤–µ—Ä—è–π –∏—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ!)
2. –ü–ï–†–°–û–ù–ê–õ–ò–ó–ê–¶–ò–Ø: –£–ø–æ–º–∏–Ω–∞–π –∏–º—è {partner_name} –º–∏–Ω–∏–º—É–º 10-12 —Ä–∞–∑ –≤ —Ç–µ–∫—Å—Ç–µ
3. –¶–ò–¢–ê–¢–´: –ò—Å–ø–æ–ª—å–∑—É–π –ü–†–Ø–ú–´–ï —Ü–∏—Ç–∞—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–∏–Ω–∏–º—É–º 15-20 —Ä–∞–∑
4. –°–¢–†–£–ö–¢–£–†–ê: –ë–ï–ó —Å–º–∞–π–ª–∏–∫–æ–≤, —Ä–µ—à–µ—Ç–æ–∫, –∑–≤–µ–∑–¥–æ—á–µ–∫, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π - —Ç–æ–ª—å–∫–æ –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
5. –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–ò–ó–ú: –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–∏–ª—å, –Ω–∞—É—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏
6. –î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø: –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –º–∏–Ω–∏–º—É–º 350-400 —Å–ª–æ–≤ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê (2400-2700 —Å–ª–æ–≤):

–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ü–û–†–¢–†–ï–¢: [–¢–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏ {partner_name}]

–û–ë–©–ê–Ø –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ê –õ–ò–ß–ù–û–°–¢–ò

–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –∏–º–µ–Ω–∏ {partner_name}. –ú–æ–¥–µ–ª—å "–¢–µ–º–Ω–æ–π —Ç—Ä–∏–∞–¥—ã" —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –±–∞–ª–ª–∞–º–∏. –ü–µ—Ä–≤–æ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ vs —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏. –í–ª–∏—è–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –Ω–∞ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —á–µ—Ä—Ç—ã. (400-450 —Å–ª–æ–≤)

–î–û–ú–ò–ù–ò–†–£–Æ–©–ò–ï –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–ê–¢–¢–ï–†–ù–´

–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —á–µ—Ä—Ç—ã {partner_name}. 4-5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –∏–º–µ–Ω–∞–º–∏ –ø–∞—Ä—Ç–Ω–µ—Ä—à. –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º—ã —Å –Ω–∞—É—á–Ω—ã–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏. –≠–≤–æ–ª—é—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏. (450-500 —Å–ª–æ–≤)

–°–ò–°–¢–ï–ú–ê –ö–û–ù–¢–†–û–õ–Ø –ò –ú–ê–ù–ò–ü–£–õ–Ø–¶–ò–ô

–≠–≤–æ–ª—é—Ü–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è {partner_name}. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ —Å —Ü–∏—Ç–∞—Ç–∞–º–∏ –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤. –§–∏–Ω–∞–Ω—Å–æ–≤—ã–π, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π, —Å–æ—Ü–∏–∞–ª—å–Ω—ã–π, —Ü–∏—Ñ—Ä–æ–≤–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å. –ò–∑–æ–ª—è—Ü–∏—è –æ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏. (450-500 —Å–ª–æ–≤)

–≠–ú–û–¶–ò–û–ù–ê–õ–¨–ù–ê–Ø –î–ò–ó–†–ï–ì–£–õ–Ø–¶–ò–Ø –ò –ê–ì–†–ï–°–°–ò–Ø

–ü–∞—Ç—Ç–µ—Ä–Ω—ã –≥–Ω–µ–≤–∞ –∏ –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏ {partner_name}. –ü—Ä–æ–µ–∫—Ü–∏—è –∏ –¥–≤–æ–π–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã. –í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Å–∏—Ö–∏—á–µ—Å–∫–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ –ø–∞—Ä—Ç–Ω–µ—Ä—à–∏. –¶–∏–∫–ª—ã –Ω–∞—Å–∏–ª–∏—è –∏ –ø—Ä–∏–º–∏—Ä–µ–Ω–∏—è. (400-450 —Å–ª–æ–≤)

–ò–ù–¢–ò–ú–ù–û–°–¢–¨ –ò –ù–ê–†–£–®–ï–ù–ò–ï –ì–†–ê–ù–ò–¶

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–ª–∏–∑–æ—Å—Ç–∏ –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤–ª–∞—Å—Ç–∏. –ü—Ä–∏–Ω—É–∂–¥–µ–Ω–∏–µ –∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —à–∞–Ω—Ç–∞–∂. –¢—Ä–∞–≤–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã –æ—Ç–Ω–æ—à–µ–Ω–∏–π. –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –¥–ª—è –∂–µ—Ä—Ç–≤—ã. (400-450 —Å–ª–æ–≤)

–°–û–¶–ò–ê–õ–¨–ù–ê–Ø –ú–ê–°–ö–ê –ò –ò–ó–û–õ–Ø–¶–ò–Ø

–ü—É–±–ª–∏—á–Ω—ã–π –æ–±—Ä–∞–∑ vs —á–∞—Å—Ç–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ {partner_name}. –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –¥–∏—Å—Å–æ–Ω–∞–Ω—Å —É –∂–µ—Ä—Ç–≤—ã. –ò–∑–æ–ª—è—Ü–∏—è –æ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –í–ª–∏—è–Ω–∏–µ –Ω–∞ –æ–∫—Ä—É–∂–µ–Ω–∏–µ. (350-400 —Å–ª–æ–≤)

–ü–†–û–ì–ù–û–ó –ò –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò

–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π {partner_name}. –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã—Ö–æ–¥–∞. –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–±–∏–ª–∏—Ç–∞—Ü–∏—è. –ü—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≤–∏–∫—Ç–∏–º–∏–∑–∞—Ü–∏–∏. (450-500 —Å–ª–æ–≤)

–°–ü–ï–¶–ò–ê–õ–¨–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –Ω–∞—á–∏–Ω–∞–π —Å –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è {partner_name}
- –ò—Å–ø–æ–ª—å–∑—É–π —Ñ—Ä–∞–∑—ã: "–ü–æ–≤–µ–¥–µ–Ω–∏–µ {partner_name} —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞...", "{partner_name} –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç..."
- –í–∫–ª—é—á–∞–π –ø—Ä—è–º—ã–µ —Ü–∏—Ç–∞—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–æ–≤: "–ö–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ –æ—Ç–≤–µ—Ç–∞—Ö: '[—Ü–∏—Ç–∞—Ç–∞]'"
- –î–æ–±–∞–≤–ª—è–π –Ω–∞—É—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏: "–°–æ–≥–ª–∞—Å–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º –¥–æ–∫—Ç–æ—Ä–∞ X..."
- –°–æ–∑–¥–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å –∏–º–µ–Ω–∞–º–∏: "–ê–Ω–Ω–∞, 28 –ª–µ—Ç, —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç..."

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –ü—Ä–æ–≤–µ—Ä—å –∏—Ç–æ–≥–æ–≤—ã–π –æ–±—ä–µ–º - –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –°–¢–†–û–ì–û 2400-2700 —Å–ª–æ–≤!
- –£–±–µ—Ä–∏ –í–°–ï —Ä–µ—à–µ—Ç–∫–∏, –∑–≤–µ–∑–¥–æ—á–∫–∏ –∏ –¥—Ä—É–≥–∏–µ —Å–∏–º–≤–æ–ª—ã –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
- –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
- –ö–∞–∂–¥—ã–π —Ä–∞–∑–¥–µ–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–º
- –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º—è–Ω–∏ –∏–º—è {partner_name} –≤ –∫–∞–∂–¥–æ–º —Ä–∞–∑–¥–µ–ª–µ
"""
        
        return system_prompt + "\n\n" + user_prompt
    
    def _parse_analysis_response(self, response: str) -> Dict[str, Any]:
        """Parse general analysis response"""
        try:
            data = extract_json_from_text(response)
            if not data:
                data = safe_json_loads(response, {})
            
            return {
                "analysis": data.get("analysis", "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"),
                "sentiment": data.get("sentiment", "neutral"),
                "key_points": data.get("key_points", []),
                "recommendations": data.get("recommendations", []),
                "confidence": float(data.get("confidence", 75.0))
            }
        except Exception as e:
            logger.error(f"Failed to parse analysis response: {e}")
        return {
                "analysis": "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞",
                "sentiment": "neutral", 
                "key_points": [],
                "recommendations": [],
                "confidence": 50.0
            }
    
    def _parse_profile_response(self, response: str) -> Dict[str, Any]:
        """Parse partner profile response"""
        try:
            data = extract_json_from_text(response)
            if not data:
                data = safe_json_loads(response, {})
            
            # Validate and extract all required fields
            result = {
                "psychological_profile": data.get("psychological_profile", "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"),
                "personality_traits": data.get("personality_traits", ["–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å", "–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å"]),
                "behavioral_patterns": data.get("behavioral_patterns", ["–ü—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ"]),
                "red_flags": data.get("red_flags", []),
                "relationship_style": data.get("relationship_style", "–ó–¥–æ—Ä–æ–≤—ã–π —Å—Ç–∏–ª—å –æ—Ç–Ω–æ—à–µ–Ω–∏–π"),
                "strengths": data.get("strengths", ["–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å"]),
                "potential_challenges": data.get("potential_challenges", ["–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è"]),
                "compatibility_factors": data.get("compatibility_factors", ["–û—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å –∫ –æ–±—â–µ–Ω–∏—é"]),
                "recommendations": data.get("recommendations", ["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ"]),
                "overall_risk_score": float(data.get("overall_risk_score", 25.0)),
                "dark_triad": data.get("dark_triad", {"narcissism": 2.0, "machiavellianism": 1.5, "psychopathy": 1.0}),
                "confidence_level": float(data.get("confidence_level", 85.0)),
                "summary": data.get("summary", "–û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–¥–æ—Ä–æ–≤—É—é –ª–∏—á–Ω–æ—Å—Ç—å —Å —Ö–æ—Ä–æ—à–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º –¥–ª—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π."),
                "survival_guide": data.get("survival_guide", ["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ"]),
                "safety_alerts": data.get("safety_alerts", []),
                "urgency_level": data.get("urgency_level", "LOW"),
                "block_scores": data.get("block_scores", {
                    "narcissism": 2.0, "control": 1.7, "gaslighting": 1.5, 
                    "emotion": 1.3, "intimacy": 1.0, "social": 1.4
                }),
                # –ù–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                "manipulation_tactics": data.get("manipulation_tactics", ["–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ"]),
                "escalation_triggers": data.get("escalation_triggers", ["–ö—Ä–∏—Ç–∏–∫–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è"]),
                "control_mechanisms": data.get("control_mechanisms", ["–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –æ–±—â–µ–Ω–∏—è"])
            }
            
            # Validate urgency level
            valid_urgency = ["LOW", "MEDIUM", "HIGH", "CRITICAL"]
            if result["urgency_level"] not in valid_urgency:
                result["urgency_level"] = "LOW"
            
            return result
                
        except Exception as e:
            logger.error(f"Failed to parse profile response: {e}")
            return {
                "psychological_profile": "–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                "personality_traits": ["–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å", "–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å"],
                "behavioral_patterns": ["–ü—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ"],
                "red_flags": [],
                "relationship_style": "–ó–¥–æ—Ä–æ–≤—ã–π —Å—Ç–∏–ª—å –æ—Ç–Ω–æ—à–µ–Ω–∏–π",
                "strengths": ["–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å"],
                "potential_challenges": ["–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è"],
                "compatibility_factors": ["–û—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å –∫ –æ–±—â–µ–Ω–∏—é"],
                "recommendations": ["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ"],
                "overall_risk_score": 25.0,
                "dark_triad": {"narcissism": 2.0, "machiavellianism": 1.5, "psychopathy": 1.0},
                "confidence_level": 60.0,
                "summary": "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.",
                "survival_guide": ["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ"],
                "safety_alerts": [],
                "urgency_level": "LOW",
                "block_scores": {"narcissism": 2.0, "control": 1.7, "gaslighting": 1.5, "emotion": 1.3, "intimacy": 1.0, "social": 1.4},
                "manipulation_tactics": ["–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ"],
                "escalation_triggers": ["–ö—Ä–∏—Ç–∏–∫–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è"],
                "control_mechanisms": ["–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –æ–±—â–µ–Ω–∏—è"]
            }
    
    def _parse_compatibility_response(self, response: str) -> Dict[str, Any]:
        """Parse compatibility analysis response"""
        try:
            data = extract_json_from_text(response)
            if not data:
                data = safe_json_loads(response, {})
            
            return {
                "compatibility_score": float(data.get("compatibility_score", 75.0)),
                "strengths": data.get("strengths", ["–û–±—â–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã"]),
                "challenges": data.get("challenges", ["–†–∞–∑–ª–∏—á–∏—è –≤ –ø–æ–¥—Ö–æ–¥–∞—Ö"]),
                "recommendations": data.get("recommendations", ["–û—Ç–∫—Ä—ã—Ç–æ–µ –æ–±—â–µ–Ω–∏–µ"]),
                "long_term_potential": data.get("long_term_potential", "–•–æ—Ä–æ—à–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª"),
                "areas_to_work_on": data.get("areas_to_work_on", ["–í–∑–∞–∏–º–æ–ø–æ–Ω–∏–º–∞–Ω–∏–µ"]),
                "summary": data.get("summary", "–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –Ω–∞ —Ö–æ—Ä–æ—à–µ–º —É—Ä–æ–≤–Ω–µ")
            }
        except Exception as e:
            logger.error(f"Failed to parse compatibility response: {e}")
        return {
                "compatibility_score": 70.0,
                "strengths": ["–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è"],
                "challenges": ["–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"],
                "recommendations": ["–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∏–∑—É—á–µ–Ω–∏–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"],
                "long_term_potential": "–¢—Ä–µ–±—É–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏",
                "areas_to_work_on": ["–í–∑–∞–∏–º–æ–ø–æ–Ω–∏–º–∞–Ω–∏–µ"],
                "summary": "–¢—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"
            }
    
    def _clean_markdown_formatting(self, text: str) -> str:
        """–£–±–∏—Ä–∞–µ—Ç markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç HTML —Å—Ç–∏–ª–∏ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
        if not text:
            return text
            
        # –£–±–∏—Ä–∞–µ–º —Ä–µ—à–µ—Ç–∫–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        lines = text.split('\n')
        cleaned_lines = []
        first_title_found = False
        
        for line in lines:
            line_clean = line.strip()
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if ('–ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó' in line_clean or 
                '–ü–ï–†–°–û–ù–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó' in line_clean) and len(line_clean) < 100:
                continue
            
            # –£–±–∏—Ä–∞–µ–º —Ä–µ—à–µ—Ç–∫–∏ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
            cleaned_line = line.lstrip('#').strip()
            
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –±—ã–ª–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
            if line.startswith('#') and cleaned_line:
                cleaned_line = cleaned_line.upper()
                
                # –ü–µ—Ä–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–æ—Å–Ω–æ–≤–Ω–æ–π) - —É–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∏ —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º
                if not first_title_found and '–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ü–û–†–¢–†–ï–¢' in cleaned_line:
                    # –£–±–∏—Ä–∞–µ–º "–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ü–û–†–¢–†–ï–¢:" –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è –∏ –¥–∏–∞–≥–Ω–æ–∑
                    cleaned_line = cleaned_line.replace('–ü–°–ò–•–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ü–û–†–¢–†–ï–¢:', '').strip()
                    cleaned_line = f'<div class="analysis-main-title">{cleaned_line}</div>'
                    first_title_found = True
                # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ - –∫—Ä–∞—Å–Ω—ã–µ —Å —Ç–µ–Ω—å—é
                else:
                    cleaned_line = f'<div class="analysis-section-header">{cleaned_line}</div>'
            
            cleaned_lines.append(cleaned_line)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        result = '\n'.join(cleaned_lines)
        
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        while '\n\n\n' in result:
            result = result.replace('\n\n\n', '\n\n')
            
        return result.strip()


# Global AI service instance
ai_service = AIService() 