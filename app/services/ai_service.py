"""AI service for text analysis using Claude with OpenAI fallback"""

import asyncio
import json
import time
from typing import Dict, Any, Optional, List

import httpx
from anthropic import AsyncAnthropic
from openai import AsyncOpenAI
from loguru import logger

from app.core.config import settings
from app.core.redis import redis_client
from app.utils.exceptions import AIServiceError
from app.utils.helpers import safe_json_loads, create_cache_key
from app.prompts.analysis_prompts import (
    TEXT_ANALYSIS_SYSTEM_PROMPT,
    PROFILER_SYSTEM_PROMPT, 
    COMPATIBILITY_SYSTEM_PROMPT,
    get_text_analysis_prompt,
    get_profiler_prompt,
    get_compatibility_prompt
)


class AIService:
    """AI service for psychological analysis"""
    
    def __init__(self):
        # Initialize AI clients
        self.claude_client = AsyncAnthropic(api_key=settings.CLAUDE_API_KEY) if settings.CLAUDE_API_KEY else None
        self.openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY) if settings.OPENAI_API_KEY else None
        
        # Configuration
        self.max_retries = settings.AI_RETRY_ATTEMPTS
        self.retry_delay = settings.AI_RETRY_DELAY
        self.timeout = settings.AI_REQUEST_TIMEOUT
        
        # Rate limiting
        self._request_semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_AI_REQUESTS)
        self._last_requests = {}
    
    async def analyze_text(
        self,
        text: str,
        user_id: int,
        context: str = "",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Analyze text for manipulation patterns and risks
        
        Args:
            text: Text to analyze
            user_id: User ID for rate limiting
            context: Additional context
            use_cache: Whether to use cache
            
        Returns:
            Analysis results
        """
        start_time = time.time()
        
        # Create cache key
        cache_key = create_cache_key("text_analysis", user_id, hash(text + context))
        
        # Try to get from cache
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"Text analysis cache hit for user {user_id}")
                return cached_result
        
        # Check rate limiting
        await self._check_rate_limit(user_id)
        
        try:
            # Prepare prompt
            user_prompt = get_text_analysis_prompt(text, context)
            
            # Get analysis from AI
            async with self._request_semaphore:
                result = await self._get_ai_response(
                    system_prompt=TEXT_ANALYSIS_SYSTEM_PROMPT,
                    user_prompt=user_prompt,
                    response_format="json"
                )
            
            # Parse and validate response
            analysis = self._parse_analysis_response(result)
            
            # Add metadata
            analysis["processing_time"] = time.time() - start_time
            analysis["ai_model_used"] = self._get_last_model_used()
            
            # Cache result
            if use_cache:
                await redis_client.set(
                    cache_key,
                    analysis,
                    expire=1800  # 30 minutes
                )
            
            logger.info(f"Text analysis completed for user {user_id} in {analysis['processing_time']:.2f}s")
            return analysis
            
        except Exception as e:
            logger.error(f"Text analysis failed for user {user_id}: {e}")
            raise AIServiceError(f"Failed to analyze text: {str(e)}")
    
    async def profile_partner(
        self,
        answers: Dict[str, int],
        user_id: int,
        partner_name: str = "–ø–∞—Ä—Ç–Ω–µ—Ä",
        partner_description: str = "",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Create partner psychological profile using FULL questionnaire (28 questions, 6 blocks)
        
        Args:
            answers: Full questionnaire answers (question_id -> answer_index) 
            user_id: User ID
            partner_name: Partner's name
            partner_description: Partner description
            use_cache: Whether to use cache
            
        Returns:
            Comprehensive profile analysis with safety assessment
        """
        start_time = time.time()
        
        # Create cache key
        answers_hash = hash(json.dumps(answers, sort_keys=True) + partner_name + partner_description)
        cache_key = create_cache_key("partner_profile_full", user_id, answers_hash)
        
        # Try cache
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"Partner profile cache hit for user {user_id}")
                return cached_result
        
        # Check rate limiting
        await self._check_rate_limit(user_id)
        
        try:
            # Import full profiler functions
            from app.prompts.profiler_full_questions import calculate_weighted_scores, get_safety_alerts
            from app.prompts.profiler_full_prompts import get_profiler_full_analysis_prompt
            
            # Calculate scores and safety alerts
            scores = calculate_weighted_scores(answers)
            safety_alerts = get_safety_alerts(answers)
            
            # Prepare prompt for AI analysis
            user_prompt = get_profiler_full_analysis_prompt(
                partner_name=partner_name,
                partner_description=partner_description,
                answers=answers,
                block_scores=scores["block_scores"],
                overall_risk_score=scores["overall_risk_score"]
            )
            
            # Get analysis from AI
            async with self._request_semaphore:
                result = await self._get_ai_response(
                    system_prompt=PROFILER_SYSTEM_PROMPT,
                    user_prompt=user_prompt,
                    response_format="text",  # Full version uses text format for rich content
                    max_tokens=8000  # Increased for comprehensive analysis
                )
            
            # Create comprehensive profile
            profile = {
                "analysis": result,
                "block_scores": scores["block_scores"],
                "overall_risk_score": scores["overall_risk_score"],
                "urgency_level": scores["urgency_level"].value,
                "safety_alerts": safety_alerts,
                "partner_name": partner_name,
                "partner_description": partner_description,
                "processing_time": time.time() - start_time,
                "ai_model_used": self._get_last_model_used(),
                "total_questions": 28,
                "questionnaire_version": "full_v1.0"
            }
            
            # Cache result
            if use_cache:
                await redis_client.set(
                    cache_key,
                    profile,
                    expire=3600  # 1 hour
                )
            
            logger.info(f"Full partner profile completed for user {user_id} in {profile['processing_time']:.2f}s, risk: {profile['urgency_level']}")
            return profile
            
        except Exception as e:
            logger.error(f"Partner profiling failed for user {user_id}: {e}")
            # Return fallback analysis with calculated scores
            try:
                from app.prompts.profiler_full_questions import calculate_weighted_scores
                scores = calculate_weighted_scores(answers)
                return self._create_full_fallback_analysis(answers, scores, partner_name)
            except:
                return self._create_basic_fallback_analysis(answers, partner_name)
    
    async def analyze_compatibility(
        self,
        user_answers: Dict[int, str],
        partner_answers: Dict[int, str],
        user_id: int,
        user_name: str = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å",
        partner_name: str = "–ü–∞—Ä—Ç–Ω–µ—Ä",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Analyze compatibility between two people
        
        Args:
            user_answers: User's answers
            partner_answers: Partner's answers
            user_id: User ID
            user_name: User's name
            partner_name: Partner's name
            use_cache: Whether to use cache
            
        Returns:
            Compatibility analysis
        """
        start_time = time.time()
        
        # Create cache key
        combined_hash = hash(
            json.dumps(user_answers, sort_keys=True) + 
            json.dumps(partner_answers, sort_keys=True)
        )
        cache_key = create_cache_key("compatibility", user_id, combined_hash)
        
        # Try cache
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"Compatibility analysis cache hit for user {user_id}")
                return cached_result
        
        # Check rate limiting
        await self._check_rate_limit(user_id)
        
        try:
            # Prepare prompt
            user_prompt = get_compatibility_prompt(
                user_answers, partner_answers, user_name, partner_name
            )
            
            # Get analysis from AI
            async with self._request_semaphore:
                result = await self._get_ai_response(
                    system_prompt=COMPATIBILITY_SYSTEM_PROMPT,
                    user_prompt=user_prompt,
                    response_format="json"
                )
            
            # Parse response
            compatibility = self._parse_compatibility_response(result)
            
            # Add metadata
            compatibility["processing_time"] = time.time() - start_time
            compatibility["ai_model_used"] = self._get_last_model_used()
            
            # Cache result
            if use_cache:
                await redis_client.set(
                    cache_key,
                    compatibility,
                    expire=3600  # 1 hour
                )
            
            logger.info(f"Compatibility analysis completed for user {user_id} in {compatibility['processing_time']:.2f}s")
            return compatibility
            
        except Exception as e:
            logger.error(f"Compatibility analysis failed for user {user_id}: {e}")
            raise AIServiceError(f"Failed to analyze compatibility: {str(e)}")
    
    async def _get_ai_response(
        self,
        system_prompt: str,
        user_prompt: str,
        response_format: str = "json",
        max_tokens: int = 4000
    ) -> str:
        """Get response from AI with fallback"""
        
        # Try Claude first
        if self.claude_client:
            try:
                response = await self._get_claude_response(
                    system_prompt, user_prompt, max_tokens
                )
                self._last_model_used = settings.CLAUDE_MODEL
                return response
            except Exception as e:
                logger.warning(f"Claude request failed: {e}, trying OpenAI fallback")
        
        # Fallback to OpenAI
        if self.openai_client:
            try:
                response = await self._get_openai_response(
                    system_prompt, user_prompt, response_format, max_tokens
                )
                self._last_model_used = settings.OPENAI_MODEL
                return response
            except Exception as e:
                logger.error(f"OpenAI request also failed: {e}")
                raise AIServiceError("All AI services are unavailable")
        
        raise AIServiceError("No AI services configured")
    
    async def _get_claude_response(
        self,
        system_prompt: str,
        user_prompt: str,
        max_tokens: int
    ) -> str:
        """Get response from Claude"""
        
        for attempt in range(self.max_retries):
            try:
                async with httpx.AsyncClient(timeout=self.timeout) as client:
                    response = await self.claude_client.messages.create(
                        model=settings.CLAUDE_MODEL,
                        max_tokens=max_tokens,
                        system=system_prompt,
                        messages=[
                            {"role": "user", "content": user_prompt}
                        ]
                    )
                
                return response.content[0].text
                
            except Exception as e:
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay * (attempt + 1))
                    continue
                raise e
    
    async def _get_openai_response(
        self,
        system_prompt: str,
        user_prompt: str,
        response_format: str,
        max_tokens: int
    ) -> str:
        """Get response from OpenAI"""
        
        # Prepare messages
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        # Add JSON format instruction if needed
        if response_format == "json":
            messages.append({
                "role": "system", 
                "content": "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ –ø—Ä–æ–º–ø—Ç–µ."
            })
        
        for attempt in range(self.max_retries):
            try:
                response = await self.openai_client.chat.completions.create(
                    model=settings.OPENAI_MODEL,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=0.7,
                    response_format={"type": "json_object"} if response_format == "json" else None
                )
                
                return response.choices[0].message.content
                
            except Exception as e:
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay * (attempt + 1))
                    continue
                raise e
    
    def _parse_analysis_response(self, response: str) -> Dict[str, Any]:
        """Parse text analysis response"""
        try:
            data = safe_json_loads(response, {})
            toxicity_score = float(data.get("toxicity_score", 0))
            if not (0 <= toxicity_score <= 10):
                raise AIServiceError("toxicity_score –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-10")
            sentiment_score = data.get("sentiment_score")
            if sentiment_score is not None:
                sentiment_score = float(sentiment_score)
                if not (-1 <= sentiment_score <= 1):
                    raise AIServiceError("sentiment_score –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ -1..1")
            return {
                "toxicity_score": toxicity_score,
                "urgency_level": data.get("urgency_level", "low"),
                "red_flags": data.get("red_flags", []),
                "patterns_detected": data.get("patterns_detected", []),
                "analysis": data.get("analysis", ""),
                "recommendation": data.get("recommendation", ""),
                "keywords": data.get("keywords", []),
                "confidence_score": float(data.get("confidence_score", 0.5)),
                "sentiment_score": sentiment_score,
            }
        except Exception as e:
            logger.error(f"Failed to parse analysis response: {e}")
            raise AIServiceError("Invalid response format from AI")
    
    def _parse_profile_response(self, response: str) -> Dict[str, Any]:
        """Parse partner profile response"""
        try:
            data = safe_json_loads(response, {})
            manipulation_risk = float(data.get("manipulation_risk", 5.0))
            if not (0 <= manipulation_risk <= 10):
                raise AIServiceError("manipulation_risk –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-10")
            overall_compatibility = data.get("overall_compatibility")
            if overall_compatibility is not None:
                overall_compatibility = float(overall_compatibility)
                if not (0 <= overall_compatibility <= 1):
                    raise AIServiceError("overall_compatibility –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-1")
            return {
                "personality_type": data.get("personality_type", ""),
                "manipulation_risk": manipulation_risk,
                "urgency_level": data.get("urgency_level", "medium"),
                "red_flags": data.get("red_flags", []),
                "positive_traits": data.get("positive_traits", []),
                "warning_signs": data.get("warning_signs", []),
                "psychological_profile": data.get("psychological_profile", ""),
                "relationship_advice": data.get("relationship_advice", ""),
                "communication_tips": data.get("communication_tips", ""),
                "trust_indicators": data.get("trust_indicators", []),
                "overall_compatibility": overall_compatibility,
            }
        except Exception as e:
            logger.error(f"Failed to parse profile response: {e}")
            raise AIServiceError("Invalid response format from AI")
    
    def _parse_compatibility_response(self, response: str) -> Dict[str, Any]:
        """Parse compatibility analysis response"""
        try:
            data = safe_json_loads(response, {})
            overall_compatibility = float(data.get("overall_compatibility", 5.0))
            if not (0 <= overall_compatibility <= 1):
                raise AIServiceError("overall_compatibility –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-1")
            return {
                "overall_compatibility": overall_compatibility,
                "communication_compatibility": float(data.get("communication_compatibility", 5.0)),
                "values_compatibility": float(data.get("values_compatibility", 5.0)),
                "lifestyle_compatibility": float(data.get("lifestyle_compatibility", 5.0)),
                "emotional_compatibility": float(data.get("emotional_compatibility", 5.0)),
                "similarity_score": float(data.get("similarity_score", 5.0)),
                "complement_score": float(data.get("complement_score", 5.0)),
                "conflict_potential": float(data.get("conflict_potential", 5.0)),
                "strengths": data.get("strengths", []),
                "challenges": data.get("challenges", []),
                "recommendations": data.get("recommendations", []),
                "compatibility_analysis": data.get("compatibility_analysis", ""),
                "relationship_advice": data.get("relationship_advice", ""),
                "growth_areas": data.get("growth_areas", "")
            }
        except Exception as e:
            logger.error(f"Failed to parse compatibility response: {e}")
            raise AIServiceError("Invalid response format from AI")
    
    async def _check_rate_limit(self, user_id: int) -> None:
        """Check rate limiting for user"""
        now = time.time()
        rate_limit = getattr(settings, 'AI_RATE_LIMIT_SECONDS', 3.0)
        # Simple rate limiting - max 1 request per N seconds per user
        if user_id in self._last_requests:
            time_since_last = now - self._last_requests[user_id]
            if time_since_last < rate_limit:
                wait_time = rate_limit - time_since_last
                await asyncio.sleep(wait_time)
        self._last_requests[user_id] = now
    
    def _get_last_model_used(self) -> str:
        """Get the last AI model used"""
        return getattr(self, '_last_model_used', 'unknown')
    
    def _create_fallback_analysis(self, answers: Dict[str, int]) -> Dict[str, Any]:
        """Create fallback analysis if AI fails"""
        from app.prompts.profiler_full_questions import calculate_weighted_scores, get_safety_alerts
        
        # Calculate weighted risk scores
        scores = calculate_weighted_scores(answers)
        safety_alerts = get_safety_alerts(answers)
        overall_risk = scores.get("overall_risk_score", 50.0)
        block_scores = scores.get("block_scores", {})
        
        # Determine urgency level
        if overall_risk >= 75.0:
            urgency = "CRITICAL"
            recommendations = [
                "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –£–†–û–í–ï–ù–¨ –†–ò–°–ö–ê - –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø–æ–º–æ—â—å—é –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ",
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–ª–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
                "–°–≤—è–∂–∏—Ç–µ—Å—å —Å–æ —Å–ª—É–∂–±–∞–º–∏ –ø–æ–º–æ—â–∏ –∂–µ—Ä—Ç–≤–∞–º –¥–æ–º–∞—à–Ω–µ–≥–æ –Ω–∞—Å–∏–ª–∏—è"
            ]
        elif overall_risk >= 50.0:
            urgency = "HIGH"
            recommendations = [
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —á–µ—Ç–∫–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö",
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –ø—Å–∏—Ö–æ–ª–æ–≥–∞",
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫ –±–ª–∏–∑–∫–∏–º"
            ]
        elif overall_risk >= 25.0:
            urgency = "MEDIUM" 
            recommendations = [
                "–†–∞–±–æ—Ç–∞–π—Ç–µ –Ω–∞–¥ —É–ª—É—á—à–µ–Ω–∏–µ–º –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏",
                "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã",
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–∞—Ä–Ω—É—é —Ç–µ—Ä–∞–ø–∏—é"
            ]
        else:
            urgency = "LOW"
            recommendations = [
                "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ä–∞–∑–≤–∏–≤–∞—Ç—å –∑–¥–æ—Ä–æ–≤—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è",
                "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç–æ–µ –æ–±—â–µ–Ω–∏–µ",
                "–ò–∑—É—á–∞–π—Ç–µ –Ω–∞–≤—ã–∫–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏"
            ]
        
        return {
            "overall_risk_score": overall_risk,
            "urgency_level": urgency,
            "block_scores": block_scores,
            "block_analysis": {
                "narcissism": {
                    "score": block_scores.get("narcissism", 0),
                    "level": self._risk_to_level(block_scores.get("narcissism", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "control": {
                    "score": block_scores.get("control", 0),
                    "level": self._risk_to_level(block_scores.get("control", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "gaslighting": {
                    "score": block_scores.get("gaslighting", 0),
                    "level": self._risk_to_level(block_scores.get("gaslighting", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "emotion": {
                    "score": block_scores.get("emotion", 0),
                    "level": self._risk_to_level(block_scores.get("emotion", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "intimacy": {
                    "score": block_scores.get("intimacy", 0),
                    "level": self._risk_to_level(block_scores.get("intimacy", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "social": {
                    "score": block_scores.get("social", 0),
                    "level": self._risk_to_level(block_scores.get("social", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                }
            },
            "psychological_profile": "–ü—Ä–æ—Ñ–∏–ª—å —Å–æ–∑–¥–∞–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤. –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞.",
            "risk_factors": ["–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ - —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–º"],
            "protective_factors": ["–û–±—Ä–∞—â–µ–Ω–∏–µ –∑–∞ –ø–æ–º–æ—â—å—é –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞"],
            "red_flags": safety_alerts if safety_alerts else [],
            "safety_alerts": safety_alerts,
            "immediate_recommendations": recommendations,
            "long_term_recommendations": [
                "–†–∞–∑–≤–∏–≤–∞–π—Ç–µ –Ω–∞–≤—ã–∫–∏ –∑–¥–æ—Ä–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è",
                "–ò–∑—É—á–∞–π—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∑–¥–æ—Ä–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π",
                "–†–∞–±–æ—Ç–∞–π—Ç–µ –Ω–∞–¥ –ø–æ–≤—ã—à–µ–Ω–∏–µ–º —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏"
            ],
            "communication_advice": [
                "–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç–æ–µ –∏ —á–µ—Å—Ç–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ",
                "–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ —á–µ—Ç–∫–∏–µ –ª–∏—á–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã",
                "–ò–∑—É—á–∞–π—Ç–µ —Ç–µ—Ö–Ω–∏–∫–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤"
            ],
            "support_resources": [
                "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø–æ–º–æ—â—å: 8-800-2000-122",
                "–ö—Ä–∏–∑–∏—Å–Ω–∞—è –ª–∏–Ω–∏—è –¥–æ–≤–µ—Ä–∏—è: 8-800-7000-600",
                "–°–ª—É–∂–±–∞ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è: 112"
            ],
            "relationship_prognosis": "–ü—Ä–æ–≥–Ω–æ–∑ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–¥ –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏",
            "confidence_score": 0.7,
            "immediate_recommendations": recommendations,
            "analysis": f"–ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó\n\n–û–±—â–∏–π –±–∞–ª–ª —Ä–∏—Å–∫–∞: {overall_risk}% ({urgency})\n\n–≠—Ç–æ—Ç –∞–Ω–∞–ª–∏–∑ —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞."
        }
    
    def _risk_to_level(self, risk_score: float) -> str:
        """Convert risk score to text level"""
        if risk_score >= 8.0:
            return "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
        elif risk_score >= 6.0:
            return "–≤—ã—Å–æ–∫–∏–π"
        elif risk_score >= 3.0:
            return "—É–º–µ—Ä–µ–Ω–Ω—ã–π"
        else:
            return "–Ω–∏–∑–∫–∏–π"
    
    def _validate_profiler_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """Validate and sanitize profiler AI response"""
        # Ensure required fields exist
        required_fields = [
            "overall_risk_score", "urgency_level", "block_analysis",
            "psychological_profile", "immediate_recommendations"
        ]
        
        for field in required_fields:
            if field not in response:
                logger.warning(f"Missing required field in AI response: {field}")
                if field == "overall_risk_score":
                    response[field] = 50.0
                elif field == "urgency_level":
                    response[field] = "MEDIUM"
                elif field == "block_analysis":
                    response[field] = {}
                else:
                    response[field] = []
        
        # Validate risk score range (0-100% for full version)
        if not isinstance(response["overall_risk_score"], (int, float)):
            response["overall_risk_score"] = 50.0
        else:
            response["overall_risk_score"] = max(0, min(100, float(response["overall_risk_score"])))
        
        # Validate urgency level
        valid_urgency_levels = ["LOW", "MEDIUM", "HIGH", "CRITICAL"]
        if response["urgency_level"] not in valid_urgency_levels:
            response["urgency_level"] = "MEDIUM"
        
        return response
    
    async def health_check(self) -> Dict[str, Any]:
        """Check AI service health"""
        status = {
            "claude_available": bool(self.claude_client),
            "openai_available": bool(self.openai_client),
            "services_configured": 0
        }
        
        if self.claude_client:
            status["services_configured"] += 1
            
        if self.openai_client:
            status["services_configured"] += 1
        
        status["status"] = "healthy" if status["services_configured"] > 0 else "unhealthy"
        
        return status

    def _create_full_fallback_analysis(self, answers: Dict[str, int], scores: Dict[str, Any], partner_name: str) -> Dict[str, Any]:
        """Create fallback analysis for full profiler when AI fails"""
        try:
            from app.prompts.profiler_full_questions import get_safety_alerts
            
            # Get safety alerts
            alerts = get_safety_alerts(answers)
            
            # Generate basic analysis based on scores
            block_scores = scores["block_scores"]
            overall_risk = scores["overall_risk_score"]
            urgency_level = scores["urgency_level"].value
            
            # Generate immediate recommendations
            immediate_recommendations = []
            if overall_risk >= 75:
                immediate_recommendations = [
                    "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –£–†–û–í–ï–ù–¨ –†–ò–°–ö–ê - –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø–æ–º–æ—â—å—é –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ",
                    "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–ª–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑—ä–µ–∑–¥–∞",
                    "–°–≤—è–∂–∏—Ç–µ—Å—å —Å —Å–ª—É–∂–±–∞–º–∏ –ø–æ–º–æ—â–∏ –∂–µ—Ä—Ç–≤–∞–º –¥–æ–º–∞—à–Ω–µ–≥–æ –Ω–∞—Å–∏–ª–∏—è"
                ]
            elif overall_risk >= 50:
                immediate_recommendations = [
                    "‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞",
                    "–û–±—Å—É–¥–∏—Ç–µ —Å–∏—Ç—É–∞—Ü–∏—é —Å –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –ª—é–¥—å–º–∏",
                    "–ò–∑—É—á–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–¥–æ—Ä–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö"
                ]
            else:
                immediate_recommendations = [
                    "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫",
                    "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–¥ —É–ª—É—á—à–µ–Ω–∏–µ–º –æ—Ç–Ω–æ—à–µ–Ω–∏–π",
                    "–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É"
                ]
            
            # Create basic analysis text
            analysis_parts = [
                f"**–ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –ü–†–û–§–ò–õ–Ø: {partner_name}**\n",
                f"–û–±—â–∏–π –±–∞–ª–ª —Ä–∏—Å–∫–∞: {overall_risk}% ({urgency_level})\n",
                "**–ê–ù–ê–õ–ò–ó –ü–û –ë–õ–û–ö–ê–ú:**"
            ]
            
            block_names = {
                "narcissism": "üß† –ù–∞—Ä—Ü–∏—Å—Å–∏–∑–º –∏ –≥—Ä–∞–Ω–¥–∏–æ–∑–Ω–æ—Å—Ç—å",
                "control": "üéØ –ö–æ–Ω—Ç—Ä–æ–ª—å –∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏",
                "gaslighting": "üîÑ –ì–∞–∑–ª–∞–π—Ç–∏–Ω–≥ –∏ –∏—Å–∫–∞–∂–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏",
                "emotion": "üí≠ –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ü–∏—è",
                "intimacy": "üíï –ò–Ω—Ç–∏–º–Ω–æ—Å—Ç—å –∏ –ø—Ä–∏–Ω—É–∂–¥–µ–Ω–∏–µ",
                "social": "üë• –°–æ—Ü–∏–∞–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ"
            }
            
            for block, score in block_scores.items():
                block_name = block_names.get(block, block)
                risk_level = "–í–´–°–û–ö–ò–ô" if score >= 7 else "–°–†–ï–î–ù–ò–ô" if score >= 4 else "–ù–ò–ó–ö–ò–ô"
                analysis_parts.append(f"- {block_name}: {score}/10 ({risk_level})")
            
            if alerts:
                analysis_parts.append("\n**–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:**")
                analysis_parts.extend([f"- {alert}" for alert in alerts])
            
            analysis_parts.append("\n**–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**")
            analysis_parts.extend([f"- {rec}" for rec in immediate_recommendations])
            
            return {
                "analysis": "\n".join(analysis_parts),
                "block_scores": block_scores,
                "overall_risk_score": overall_risk,
                "urgency_level": urgency_level,
                "safety_alerts": alerts,
                "immediate_recommendations": immediate_recommendations,
                "partner_name": partner_name,
                "total_questions": 28,
                "questionnaire_version": "full_v1.0",
                "ai_available": False,
                "fallback_reason": "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑",
                "created_at": time.time()
            }
            
        except Exception as e:
            logger.error(f"Full fallback analysis failed: {e}")
            return self._create_basic_fallback_analysis(answers, partner_name)

    def _create_basic_fallback_analysis(self, answers: Dict[str, int], partner_name: str) -> Dict[str, Any]:
        """Create basic fallback when everything else fails"""
        return {
            "analysis": f"**–û–®–ò–ë–ö–ê –ê–ù–ê–õ–ò–ó–ê –ü–†–û–§–ò–õ–Ø: {partner_name}**\n\n–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∞—à–∏ –æ—Ç–≤–µ—Ç—ã –∏–∑-–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Å–∏—Ç—É–∞—Ü–∏–∏.",
            "block_scores": {},
            "overall_risk_score": 50.0,
            "urgency_level": "MEDIUM",
            "safety_alerts": [],
            "immediate_recommendations": [
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏",
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–π –ø–æ–º–æ—â–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"
            ],
            "partner_name": partner_name,
            "total_questions": len(answers),
            "error": True,
            "fallback_reason": "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–∏—Å—Ç–µ–º—ã",
            "emergency_contacts": [
                "112 - –°–ª—É–∂–±–∞ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è", 
                "8-800-7000-600 - –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –≥–æ—Ä—è—á–∞—è –ª–∏–Ω–∏—è"
            ],
            "created_at": time.time()
        }


# Global AI service instance
ai_service = AIService() 