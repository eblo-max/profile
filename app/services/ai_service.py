"""AI service for text analysis using Claude with OpenAI fallback"""

import asyncio
import json
import time
from typing import Dict, Any, Optional, List

import httpx
from anthropic import AsyncAnthropic
from openai import AsyncOpenAI
from loguru import logger

from app.core.config import settings
from app.core.redis import redis_client
from app.utils.exceptions import AIServiceError
from app.utils.helpers import safe_json_loads, create_cache_key
from app.prompts.analysis_prompts import (
    TEXT_ANALYSIS_SYSTEM_PROMPT,
    PROFILER_SYSTEM_PROMPT, 
    COMPATIBILITY_SYSTEM_PROMPT,
    get_text_analysis_prompt,
    get_profiler_prompt,
    get_compatibility_prompt
)
from app.utils.enums import UrgencyLevel
import traceback


class AIService:
    """AI service for psychological analysis"""
    
    def __init__(self):
        # Initialize AI clients
        self.claude_client = AsyncAnthropic(api_key=settings.CLAUDE_API_KEY) if settings.CLAUDE_API_KEY else None
        self.openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY) if settings.OPENAI_API_KEY else None
        
        # Configuration
        self.max_retries = settings.AI_RETRY_ATTEMPTS
        self.retry_delay = settings.AI_RETRY_DELAY
        self.timeout = settings.AI_REQUEST_TIMEOUT
        
        # Rate limiting
        self._request_semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_AI_REQUESTS)
        self._last_requests = {}
    
    async def analyze_text(
        self,
        text: str,
        user_id: int,
        context: str = "",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Analyze text for manipulation patterns and risks
        
        Args:
            text: Text to analyze
            user_id: User ID for rate limiting
            context: Additional context
            use_cache: Whether to use cache
            
        Returns:
            Analysis results
        """
        start_time = time.time()
        
        # Create cache key
        cache_key = create_cache_key("text_analysis", user_id, hash(text + context))
        
        # Try to get from cache
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"Text analysis cache hit for user {user_id}")
                return cached_result
        
        # Check rate limiting
        await self._check_rate_limit(user_id)
        
        try:
            # Prepare prompt
            user_prompt = get_text_analysis_prompt(text, context)
            
            # Get analysis from AI
            async with self._request_semaphore:
                result = await self._get_ai_response(
                    system_prompt=TEXT_ANALYSIS_SYSTEM_PROMPT,
                    user_prompt=user_prompt,
                    response_format="json"
                )
            
            # Parse and validate response
            analysis = self._parse_analysis_response(result)
            
            # Add metadata
            analysis["processing_time"] = time.time() - start_time
            analysis["ai_model_used"] = self._get_last_model_used()
            
            # Cache result
            if use_cache:
                await redis_client.set(
                    cache_key,
                    analysis,
                    expire=1800  # 30 minutes
                )
            
            logger.info(f"Text analysis completed for user {user_id} in {analysis['processing_time']:.2f}s")
            return analysis
            
        except Exception as e:
            logger.error(f"Text analysis failed for user {user_id}: {e}")
            raise AIServiceError(f"Failed to analyze text: {str(e)}")
    
    async def profile_partner(
        self,
        answers: List[Dict[str, Any]],  # Changed from Dict[str, int] to List[Dict]
        user_id: int,
        partner_name: str = "–ø–∞—Ä—Ç–Ω–µ—Ä",
        partner_description: str = "",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Analyze partner profile based on questionnaire answers
        
        Args:
            answers: List of answer dictionaries with question_id, question, answer
            user_id: User ID
            partner_name: Partner's name
            partner_description: Additional context
            use_cache: Whether to use cache
            
        Returns:
            Partner profile analysis
        """
        start_time = time.time()
        
        # Convert answers to expected format if needed
        if isinstance(answers, list):
            # Convert from bot format to analysis format
            answers_text = []
            for answer in answers:
                question_text = answer.get('question', f"Question {answer.get('question_id', 'N/A')}")
                answer_text = answer.get('answer', 'No answer')
                answers_text.append(f"Q: {question_text}\nA: {answer_text}")
            
            # Create combined text for analysis
            combined_answers = "\n\n".join(answers_text)
        else:
            # Legacy format support
            combined_answers = str(answers)
        
        # Create cache key
        answers_hash = hash(combined_answers + partner_name)
        cache_key = create_cache_key("profile", user_id, answers_hash)
        
        # Try cache
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"Partner profile cache hit for user {user_id}")
                return cached_result
        
        # Check rate limiting
        await self._check_rate_limit(user_id)
        
        try:
            # Format answers for AI analysis
            answers_text = ""
            for i, answer in enumerate(answers, 1):
                question = answer.get('question', f'–í–æ–ø—Ä–æ—Å {i}')
                answer_text = answer.get('answer', '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞')
                answers_text += f"{i}. {question}\n   –û—Ç–≤–µ—Ç: {answer_text}\n\n"
            
            # Prepare prompt with formatted answers
            user_prompt = get_profiler_prompt(
                answers_text=answers_text,
                partner_name=partner_name,
                partner_description=partner_description
            )
            
            # Get analysis from AI
            async with self._request_semaphore:
                result = await self._get_ai_response(
                    system_prompt=PROFILER_SYSTEM_PROMPT,
                    user_prompt=user_prompt,
                    response_format="json",
                    max_tokens=6000  # Increased for detailed analysis
                )
            
            # Parse and validate response
            profile = self._parse_profile_response(result)
            profile = self._validate_profiler_response(profile)
            
            # Add metadata
            profile["processing_time"] = time.time() - start_time
            profile["ai_model_used"] = self._get_last_model_used()
            profile["partner_name"] = partner_name
            profile["total_questions"] = len(answers)
            
            # Cache result
            if use_cache:
                await redis_client.set(
                    cache_key,
                    profile,
                    expire=7200  # 2 hours
                )
            
            logger.info(f"Partner profiling completed for user {user_id} in {profile['processing_time']:.2f}s")
            return profile
            
        except Exception as e:
            logger.error(f"Partner profiling failed for user {user_id}: {e}")
            logger.error(f"Error details: {traceback.format_exc()}")
            # Return fallback analysis with calculated scores
            try:
                from app.prompts.profiler_full_questions import calculate_weighted_scores
                scores = calculate_weighted_scores(answers)
                return self._create_full_fallback_analysis(answers, scores, partner_name)
            except Exception as fallback_error:
                logger.error(f"Fallback analysis also failed: {fallback_error}")
                return self._create_basic_fallback_analysis(answers, partner_name)
    
    async def analyze_compatibility(
        self,
        user_answers: Dict[int, str],
        partner_answers: Dict[int, str],
        user_id: int,
        user_name: str = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å",
        partner_name: str = "–ü–∞—Ä—Ç–Ω–µ—Ä",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Analyze compatibility between two people
        
        Args:
            user_answers: User's answers
            partner_answers: Partner's answers
            user_id: User ID
            user_name: User's name
            partner_name: Partner's name
            use_cache: Whether to use cache
            
        Returns:
            Compatibility analysis
        """
        start_time = time.time()
        
        # Create cache key
        combined_hash = hash(
            json.dumps(user_answers, sort_keys=True) + 
            json.dumps(partner_answers, sort_keys=True)
        )
        cache_key = create_cache_key("compatibility", user_id, combined_hash)
        
        # Try cache
        if use_cache:
            cached_result = await redis_client.get(cache_key)
            if cached_result:
                logger.info(f"Compatibility analysis cache hit for user {user_id}")
                return cached_result
        
        # Check rate limiting
        await self._check_rate_limit(user_id)
        
        try:
            # Prepare prompt
            user_prompt = get_compatibility_prompt(
                user_answers, partner_answers, user_name, partner_name
            )
            
            # Get analysis from AI
            async with self._request_semaphore:
                result = await self._get_ai_response(
                    system_prompt=COMPATIBILITY_SYSTEM_PROMPT,
                    user_prompt=user_prompt,
                    response_format="json"
                )
            
            # Parse response
            compatibility = self._parse_compatibility_response(result)
            
            # Add metadata
            compatibility["processing_time"] = time.time() - start_time
            compatibility["ai_model_used"] = self._get_last_model_used()
            
            # Cache result
            if use_cache:
                await redis_client.set(
                    cache_key,
                    compatibility,
                    expire=3600  # 1 hour
                )
            
            logger.info(f"Compatibility analysis completed for user {user_id} in {compatibility['processing_time']:.2f}s")
            return compatibility
            
        except Exception as e:
            logger.error(f"Compatibility analysis failed for user {user_id}: {e}")
            raise AIServiceError(f"Failed to analyze compatibility: {str(e)}")
    
    async def _get_ai_response(
        self,
        system_prompt: str,
        user_prompt: str,
        response_format: str = "json",
        max_tokens: int = 4000
    ) -> str:
        """Get response from AI with fallback"""
        
        # Try Claude first
        if self.claude_client:
            try:
                response = await self._get_claude_response(
                    system_prompt, user_prompt, max_tokens
                )
                self._last_model_used = settings.CLAUDE_MODEL
                return response
            except Exception as e:
                logger.warning(f"Claude request failed: {e}, trying OpenAI fallback")
        
        # Fallback to OpenAI
        if self.openai_client:
            try:
                response = await self._get_openai_response(
                    system_prompt, user_prompt, response_format, max_tokens
                )
                self._last_model_used = settings.OPENAI_MODEL
                return response
            except Exception as e:
                logger.error(f"OpenAI request also failed: {e}")
                raise AIServiceError("All AI services are unavailable")
        
        raise AIServiceError("No AI services configured")
    
    async def _get_claude_response(
        self,
        system_prompt: str,
        user_prompt: str,
        max_tokens: int
    ) -> str:
        """Get response from Claude"""
        
        for attempt in range(self.max_retries):
            try:
                async with httpx.AsyncClient(timeout=self.timeout) as client:
                    response = await self.claude_client.messages.create(
                        model=settings.CLAUDE_MODEL,
                        max_tokens=max_tokens,
                        system=system_prompt,
                        messages=[
                            {"role": "user", "content": user_prompt}
                        ]
                    )
                
                return response.content[0].text
                
            except Exception as e:
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay * (attempt + 1))
                    continue
                raise e
    
    async def _get_openai_response(
        self,
        system_prompt: str,
        user_prompt: str,
        response_format: str,
        max_tokens: int
    ) -> str:
        """Get response from OpenAI"""
        
        # Prepare messages
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        # Add JSON format instruction if needed
        if response_format == "json":
            messages.append({
                "role": "system", 
                "content": "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ –ø—Ä–æ–º–ø—Ç–µ."
            })
        
        for attempt in range(self.max_retries):
            try:
                response = await self.openai_client.chat.completions.create(
                    model=settings.OPENAI_MODEL,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=0.7,
                    response_format={"type": "json_object"} if response_format == "json" else None
                )
                
                return response.choices[0].message.content
                
            except Exception as e:
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay * (attempt + 1))
                    continue
                raise e
    
    def _parse_analysis_response(self, response: str) -> Dict[str, Any]:
        """Parse text analysis response"""
        try:
            data = safe_json_loads(response, {})
            toxicity_score = float(data.get("toxicity_score", 0))
            if not (0 <= toxicity_score <= 10):
                raise AIServiceError("toxicity_score –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-10")
            sentiment_score = data.get("sentiment_score")
            if sentiment_score is not None:
                sentiment_score = float(sentiment_score)
                if not (-1 <= sentiment_score <= 1):
                    raise AIServiceError("sentiment_score –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ -1..1")
            return {
                "toxicity_score": toxicity_score,
                "urgency_level": data.get("urgency_level", "low"),
                "red_flags": data.get("red_flags", []),
                "patterns_detected": data.get("patterns_detected", []),
                "analysis": data.get("analysis", ""),
                "recommendation": data.get("recommendation", ""),
                "keywords": data.get("keywords", []),
                "confidence_score": float(data.get("confidence_score", 0.5)),
                "sentiment_score": sentiment_score,
            }
        except Exception as e:
            logger.error(f"Failed to parse analysis response: {e}")
            raise AIServiceError("Invalid response format from AI")
    
    def _parse_profile_response(self, response: str) -> Dict[str, Any]:
        """Parse partner profile response from AI"""
        try:
            data = safe_json_loads(response, {})
            
            # Extract main fields with fallbacks
            psychological_profile = data.get("psychological_profile", "")
            if not psychological_profile:
                # Try alternative keys
                psychological_profile = data.get("analysis", data.get("detailed_analysis", ""))
            
            red_flags = data.get("red_flags", [])
            if not red_flags:
                red_flags = data.get("warning_signs", [])
            
            survival_guide = data.get("survival_guide", [])
            if not survival_guide:
                survival_guide = data.get("recommendations", [])
            
            # Extract risk assessment
            risk_score = float(data.get("manipulation_risk", data.get("overall_risk_score", 5.0)))
            if risk_score > 10:
                risk_score = risk_score / 10  # Normalize if needed
            risk_score = min(10, max(0, risk_score)) * 10  # Scale to 0-100
            
            urgency = data.get("urgency_level", "medium").upper()
            
            # Extract Dark Triad scores
            dark_triad = data.get("dark_triad", {})
            if not dark_triad:
                # Calculate based on risk score
                dark_triad = {
                    "narcissism": min(10, risk_score / 10),
                    "machiavellianism": min(10, (risk_score - 5) / 10),
                    "psychopathy": min(10, (risk_score - 10) / 10)
                }
            
            # Extract block scores
            block_scores = data.get("block_scores", {})
            if not block_scores:
                # Generate based on risk score
                block_scores = {
                    "narcissism": min(10, risk_score / 12),
                    "control": min(10, risk_score / 10),
                    "gaslighting": min(10, (risk_score - 5) / 12),
                    "emotion": min(10, risk_score / 15),
                    "intimacy": min(10, (risk_score - 10) / 12),
                    "social": min(10, risk_score / 11)
                }
            
            return {
                "psychological_profile": psychological_profile,
                "red_flags": red_flags if isinstance(red_flags, list) else [red_flags],
                "survival_guide": survival_guide if isinstance(survival_guide, list) else [survival_guide],
                "dark_triad": dark_triad,
                "block_scores": block_scores,
                "overall_risk_score": risk_score,
                "urgency_level": urgency,
                "safety_alerts": data.get("safety_alerts", ["–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º"]),
                "personality_type": data.get("personality_type", ""),
                "emotional_portrait": data.get("emotional_portrait", ""),
                "relationship_dynamics": data.get("relationship_dynamics", ""),
                "danger_assessment": data.get("danger_assessment", ""),
                "motivations": data.get("motivations", ""),
                "relationship_forecast": data.get("relationship_forecast", ""),
                "exit_strategy": data.get("exit_strategy", ""),
                "trust_indicators": data.get("trust_indicators", []),
                "ai_available": True,
                "fallback_used": False
            }
            
        except Exception as e:
            logger.error(f"Failed to parse profile response: {e}")
            logger.error(f"Response was: {response[:500]}...")
            raise AIServiceError(f"Failed to parse AI response: {str(e)}")
    
    def _parse_compatibility_response(self, response: str) -> Dict[str, Any]:
        """Parse compatibility analysis response"""
        try:
            data = safe_json_loads(response, {})
            overall_compatibility = float(data.get("overall_compatibility", 5.0))
            if not (0 <= overall_compatibility <= 1):
                raise AIServiceError("overall_compatibility –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0-1")
            return {
                "overall_compatibility": overall_compatibility,
                "communication_compatibility": float(data.get("communication_compatibility", 5.0)),
                "values_compatibility": float(data.get("values_compatibility", 5.0)),
                "lifestyle_compatibility": float(data.get("lifestyle_compatibility", 5.0)),
                "emotional_compatibility": float(data.get("emotional_compatibility", 5.0)),
                "similarity_score": float(data.get("similarity_score", 5.0)),
                "complement_score": float(data.get("complement_score", 5.0)),
                "conflict_potential": float(data.get("conflict_potential", 5.0)),
                "strengths": data.get("strengths", []),
                "challenges": data.get("challenges", []),
                "recommendations": data.get("recommendations", []),
                "compatibility_analysis": data.get("compatibility_analysis", ""),
                "relationship_advice": data.get("relationship_advice", ""),
                "growth_areas": data.get("growth_areas", "")
            }
        except Exception as e:
            logger.error(f"Failed to parse compatibility response: {e}")
            raise AIServiceError("Invalid response format from AI")
    
    async def _check_rate_limit(self, user_id: int) -> None:
        """Check rate limiting for user"""
        now = time.time()
        rate_limit = getattr(settings, 'AI_RATE_LIMIT_SECONDS', 3.0)
        # Simple rate limiting - max 1 request per N seconds per user
        if user_id in self._last_requests:
            time_since_last = now - self._last_requests[user_id]
            if time_since_last < rate_limit:
                wait_time = rate_limit - time_since_last
                await asyncio.sleep(wait_time)
        self._last_requests[user_id] = now
    
    def _get_last_model_used(self) -> str:
        """Get the last AI model used"""
        return getattr(self, '_last_model_used', 'unknown')
    
    def _create_fallback_analysis(self, answers: Dict[str, int]) -> Dict[str, Any]:
        """Create fallback analysis if AI fails"""
        from app.prompts.profiler_full_questions import calculate_weighted_scores, get_safety_alerts
        
        # Calculate weighted risk scores
        scores = calculate_weighted_scores(answers)
        safety_alerts = get_safety_alerts(answers)
        overall_risk = scores.get("overall_risk_score", 50.0)
        block_scores = scores.get("block_scores", {})
        
        # Determine urgency level
        if overall_risk >= 75.0:
            urgency = "CRITICAL"
            recommendations = [
                "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –£–†–û–í–ï–ù–¨ –†–ò–°–ö–ê - –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø–æ–º–æ—â—å—é –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ",
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–ª–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
                "–°–≤—è–∂–∏—Ç–µ—Å—å —Å–æ —Å–ª—É–∂–±–∞–º–∏ –ø–æ–º–æ—â–∏ –∂–µ—Ä—Ç–≤–∞–º –¥–æ–º–∞—à–Ω–µ–≥–æ –Ω–∞—Å–∏–ª–∏—è"
            ]
        elif overall_risk >= 50.0:
            urgency = "HIGH"
            recommendations = [
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —á–µ—Ç–∫–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö",
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –ø—Å–∏—Ö–æ–ª–æ–≥–∞",
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫ –±–ª–∏–∑–∫–∏–º"
            ]
        elif overall_risk >= 25.0:
            urgency = "MEDIUM" 
            recommendations = [
                "–†–∞–±–æ—Ç–∞–π—Ç–µ –Ω–∞–¥ —É–ª—É—á—à–µ–Ω–∏–µ–º –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏",
                "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã",
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–∞—Ä–Ω—É—é —Ç–µ—Ä–∞–ø–∏—é"
            ]
        else:
            urgency = "LOW"
            recommendations = [
                "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ä–∞–∑–≤–∏–≤–∞—Ç—å –∑–¥–æ—Ä–æ–≤—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è",
                "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç–æ–µ –æ–±—â–µ–Ω–∏–µ",
                "–ò–∑—É—á–∞–π—Ç–µ –Ω–∞–≤—ã–∫–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏"
            ]
        
        return {
            "overall_risk_score": overall_risk,
            "urgency_level": urgency,
            "block_scores": block_scores,
            "block_analysis": {
                "narcissism": {
                    "score": block_scores.get("narcissism", 0),
                    "level": self._risk_to_level(block_scores.get("narcissism", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "control": {
                    "score": block_scores.get("control", 0),
                    "level": self._risk_to_level(block_scores.get("control", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "gaslighting": {
                    "score": block_scores.get("gaslighting", 0),
                    "level": self._risk_to_level(block_scores.get("gaslighting", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "emotion": {
                    "score": block_scores.get("emotion", 0),
                    "level": self._risk_to_level(block_scores.get("emotion", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "intimacy": {
                    "score": block_scores.get("intimacy", 0),
                    "level": self._risk_to_level(block_scores.get("intimacy", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                },
                "social": {
                    "score": block_scores.get("social", 0),
                    "level": self._risk_to_level(block_scores.get("social", 0)),
                    "key_patterns": ["–ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö"],
                    "evidence": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–æ–≤"
                }
            },
            "psychological_profile": "–ü—Ä–æ—Ñ–∏–ª—å —Å–æ–∑–¥–∞–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∞—É—á–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤. –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞.",
            "risk_factors": ["–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ - —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–º"],
            "protective_factors": ["–û–±—Ä–∞—â–µ–Ω–∏–µ –∑–∞ –ø–æ–º–æ—â—å—é –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞"],
            "red_flags": safety_alerts if safety_alerts else [],
            "safety_alerts": safety_alerts,
            "immediate_recommendations": recommendations,
            "long_term_recommendations": [
                "–†–∞–∑–≤–∏–≤–∞–π—Ç–µ –Ω–∞–≤—ã–∫–∏ –∑–¥–æ—Ä–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è",
                "–ò–∑—É—á–∞–π—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∑–¥–æ—Ä–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π",
                "–†–∞–±–æ—Ç–∞–π—Ç–µ –Ω–∞–¥ –ø–æ–≤—ã—à–µ–Ω–∏–µ–º —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏"
            ],
            "communication_advice": [
                "–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç–æ–µ –∏ —á–µ—Å—Ç–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ",
                "–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ —á–µ—Ç–∫–∏–µ –ª–∏—á–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã",
                "–ò–∑—É—á–∞–π—Ç–µ —Ç–µ—Ö–Ω–∏–∫–∏ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤"
            ],
            "support_resources": [
                "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø–æ–º–æ—â—å: 8-800-2000-122",
                "–ö—Ä–∏–∑–∏—Å–Ω–∞—è –ª–∏–Ω–∏—è –¥–æ–≤–µ—Ä–∏—è: 8-800-7000-600",
                "–°–ª—É–∂–±–∞ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è: 112"
            ],
            "relationship_prognosis": "–ü—Ä–æ–≥–Ω–æ–∑ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–¥ –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏",
            "confidence_score": 0.7,
            "immediate_recommendations": recommendations,
            "analysis": f"–ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó\n\n–û–±—â–∏–π –±–∞–ª–ª —Ä–∏—Å–∫–∞: {overall_risk}% ({urgency})\n\n–≠—Ç–æ—Ç –∞–Ω–∞–ª–∏–∑ —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞."
        }
    
    def _risk_to_level(self, risk_score: float) -> str:
        """Convert risk score to text level"""
        if risk_score >= 8.0:
            return "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
        elif risk_score >= 6.0:
            return "–≤—ã—Å–æ–∫–∏–π"
        elif risk_score >= 3.0:
            return "—É–º–µ—Ä–µ–Ω–Ω—ã–π"
        else:
            return "–Ω–∏–∑–∫–∏–π"
    
    def _validate_profiler_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """Validate and clean profiler response"""
        
        # Required fields with defaults
        required_fields = {
            "psychological_profile": "–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
            "red_flags": [],
            "survival_guide": [],
            "overall_risk_score": 50.0,
            "urgency_level": "MEDIUM",
            "block_scores": {},
            "dark_triad": {},
            "safety_alerts": ["–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º"]
        }
        
        # Ensure all required fields exist
        for field, default_value in required_fields.items():
            if field not in response:
                response[field] = default_value
                logger.warning(f"Missing field '{field}' in AI response, using default")
        
        # Validate and normalize risk score
        try:
            risk_score = float(response.get("overall_risk_score", 50.0))
            response["overall_risk_score"] = max(0, min(100, risk_score))
        except (ValueError, TypeError):
            response["overall_risk_score"] = 50.0
        
        # Validate urgency level
        valid_urgency = ["LOW", "MEDIUM", "HIGH", "CRITICAL"]
        if response.get("urgency_level", "").upper() not in valid_urgency:
            response["urgency_level"] = "MEDIUM"
        
        # Ensure lists are actually lists
        list_fields = ["red_flags", "survival_guide", "safety_alerts", "trust_indicators"]
        for field in list_fields:
            if field in response and not isinstance(response[field], list):
                response[field] = [response[field]] if response[field] else []
        
        # Validate block scores
        if not isinstance(response.get("block_scores"), dict):
            response["block_scores"] = {}
        
        # Validate dark triad
        if not isinstance(response.get("dark_triad"), dict):
            response["dark_triad"] = {}
        
        return response
    
    async def health_check(self) -> Dict[str, Any]:
        """Check AI service health"""
        status = {
            "claude_available": bool(self.claude_client),
            "openai_available": bool(self.openai_client),
            "services_configured": 0
        }
        
        if self.claude_client:
            status["services_configured"] += 1
            
        if self.openai_client:
            status["services_configured"] += 1
        
        status["status"] = "healthy" if status["services_configured"] > 0 else "unhealthy"
        
        return status

    def _create_full_fallback_analysis(self, answers: Dict[str, int], scores: Dict[str, Any], partner_name: str) -> Dict[str, Any]:
        """Create fallback analysis for full profiler when AI fails"""
        try:
            from app.prompts.profiler_full_questions import get_safety_alerts
            
            # Get safety alerts
            alerts = get_safety_alerts(answers)
            
            # Generate basic analysis based on scores
            block_scores = scores["block_scores"]
            overall_risk = scores["overall_risk_score"]
            urgency_level = scores["urgency_level"].value
            
            # Generate immediate recommendations
            immediate_recommendations = []
            if overall_risk >= 75:
                immediate_recommendations = [
                    "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –£–†–û–í–ï–ù–¨ –†–ò–°–ö–ê - –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø–æ–º–æ—â—å—é –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ",
                    "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–ª–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑—ä–µ–∑–¥–∞",
                    "–°–≤—è–∂–∏—Ç–µ—Å—å —Å —Å–ª—É–∂–±–∞–º–∏ –ø–æ–º–æ—â–∏ –∂–µ—Ä—Ç–≤–∞–º –¥–æ–º–∞—à–Ω–µ–≥–æ –Ω–∞—Å–∏–ª–∏—è"
                ]
            elif overall_risk >= 50:
                immediate_recommendations = [
                    "‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞",
                    "–û–±—Å—É–¥–∏—Ç–µ —Å–∏—Ç—É–∞—Ü–∏—é —Å –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –ª—é–¥—å–º–∏",
                    "–ò–∑—É—á–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–¥–æ—Ä–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö"
                ]
            else:
                immediate_recommendations = [
                    "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫",
                    "–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–¥ —É–ª—É—á—à–µ–Ω–∏–µ–º –æ—Ç–Ω–æ—à–µ–Ω–∏–π",
                    "–ü—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É"
                ]
            
            # Create basic analysis text
            analysis_parts = [
                f"**–ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –ü–†–û–§–ò–õ–Ø: {partner_name}**\n",
                f"–û–±—â–∏–π –±–∞–ª–ª —Ä–∏—Å–∫–∞: {overall_risk}% ({urgency_level})\n",
                "**–ê–ù–ê–õ–ò–ó –ü–û –ë–õ–û–ö–ê–ú:**"
            ]
            
            block_names = {
                "narcissism": "üß† –ù–∞—Ä—Ü–∏—Å—Å–∏–∑–º –∏ –≥—Ä–∞–Ω–¥–∏–æ–∑–Ω–æ—Å—Ç—å",
                "control": "üéØ –ö–æ–Ω—Ç—Ä–æ–ª—å –∏ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏",
                "gaslighting": "üîÑ –ì–∞–∑–ª–∞–π—Ç–∏–Ω–≥ –∏ –∏—Å–∫–∞–∂–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏",
                "emotion": "üí≠ –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ü–∏—è",
                "intimacy": "üíï –ò–Ω—Ç–∏–º–Ω–æ—Å—Ç—å –∏ –ø—Ä–∏–Ω—É–∂–¥–µ–Ω–∏–µ",
                "social": "üë• –°–æ—Ü–∏–∞–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ"
            }
            
            for block, score in block_scores.items():
                block_name = block_names.get(block, block)
                risk_level = "–í–´–°–û–ö–ò–ô" if score >= 7 else "–°–†–ï–î–ù–ò–ô" if score >= 4 else "–ù–ò–ó–ö–ò–ô"
                analysis_parts.append(f"- {block_name}: {score}/10 ({risk_level})")
            
            if alerts:
                analysis_parts.append("\n**–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:**")
                analysis_parts.extend([f"- {alert}" for alert in alerts])
            
            analysis_parts.append("\n**–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**")
            analysis_parts.extend([f"- {rec}" for rec in immediate_recommendations])
            
            return {
                "analysis": "\n".join(analysis_parts),
                "block_scores": block_scores,
                "overall_risk_score": overall_risk,
                "urgency_level": urgency_level,
                "safety_alerts": alerts,
                "immediate_recommendations": immediate_recommendations,
                "partner_name": partner_name,
                "total_questions": 28,
                "questionnaire_version": "full_v1.0",
                "ai_available": False,
                "fallback_reason": "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑",
                "created_at": time.time()
            }
            
        except Exception as e:
            logger.error(f"Full fallback analysis failed: {e}")
            return self._create_basic_fallback_analysis(answers, partner_name)

    def _create_basic_fallback_analysis(self, answers: List[Dict[str, Any]], partner_name: str) -> Dict[str, Any]:
        """Create basic fallback analysis when AI fails"""
        
        # Analyze answers for content
        answer_texts = []
        for answer in answers:
            answer_text = answer.get('answer', '').lower()
            answer_texts.append(answer_text)
        
        combined_text = ' '.join(answer_texts)
        
        # Determine risk level based on keywords
        high_risk_keywords = ['–≤—Å–µ–≥–¥–∞', '–ø–æ—Å—Ç–æ—è–Ω–Ω–æ', '–Ω–∏–∫–æ–≥–¥–∞', '–∑–∞–ø—Ä–µ—â–∞–µ—Ç', '–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç', '–∫—Ä–∏—á–∏—Ç', '–∑–ª–∏—Ç—Å—è', '–±—å–µ—Ç', '—É–≥—Ä–æ–∂–∞–µ—Ç', '–∏–∑–æ–ª–∏—Ä—É–µ—Ç']
        medium_risk_keywords = ['—á–∞—Å—Ç–æ', '–∏–Ω–æ–≥–¥–∞', '–º–æ–∂–µ—Ç', '–±—ã–≤–∞–µ—Ç', '–Ω–µ —Ä–∞–∑—Ä–µ—à–∞–µ—Ç', '—Ä–µ–≤–Ω—É–µ—Ç', '–ø—Ä–æ–≤–µ—Ä—è–µ—Ç']
        
        high_risk_count = sum(1 for keyword in high_risk_keywords if keyword in combined_text)
        medium_risk_count = sum(1 for keyword in medium_risk_keywords if keyword in combined_text)
        
        if high_risk_count >= 3:
            risk_score = 85.0
            urgency = "CRITICAL"
        elif high_risk_count >= 1 or medium_risk_count >= 3:
            risk_score = 70.0
            urgency = "HIGH"
        elif medium_risk_count >= 1:
            risk_score = 55.0
            urgency = "MEDIUM"
        else:
            risk_score = 30.0
            urgency = "LOW"
        
        # Generate personalized psychological profile
        profile_parts = []
        
        if '–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç' in combined_text or '–ø—Ä–æ–≤–µ—Ä—è–µ—Ç' in combined_text:
            profile_parts.append(f"{partner_name} –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—â–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏. –û–Ω —Å—Ç—Ä–µ–º–∏—Ç—Å—è —É–ø—Ä–∞–≤–ª—è—Ç—å –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º –ø–∞—Ä—Ç–Ω–µ—Ä–∞, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—è –µ–≥–æ –∞–≤—Ç–æ–Ω–æ–º–∏—é –∏ —Å–≤–æ–±–æ–¥—É –≤—ã–±–æ—Ä–∞.")
        
        if '–∫—Ä–∏—á–∏—Ç' in combined_text or '–∑–ª–∏—Ç—Å—è' in combined_text:
            profile_parts.append("–ù–∞–±–ª—é–¥–∞–µ—Ç—Å—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å –≤—Å–ø—ã—à–∫–∞–º–∏ –≥–Ω–µ–≤–∞. –≠—Ç–æ –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–µ–≥—É–ª—è—Ü–∏–µ–π —ç–º–æ—Ü–∏–π –∏ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–º—É –ø–æ–≤–µ–¥–µ–Ω–∏—é.")
        
        if '–∑–∞–ø—Ä–µ—â–∞–µ—Ç' in combined_text or '–Ω–µ —Ä–∞–∑—Ä–µ—à–∞–µ—Ç' in combined_text:
            profile_parts.append("–ü–∞—Ä—Ç–Ω–µ—Ä –ø—ã—Ç–∞–µ—Ç—Å—è –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã –∏ –ª–∏—á–Ω—É—é —Å–≤–æ–±–æ–¥—É. –≠—Ç–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–∑–Ω–∞–∫ –∏–∑–æ–ª–∏—Ä—É—é—â–µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ–≥–æ –¥–ª—è –∞–±—å—é–∑–∏–≤–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π.")
        
        if '–Ω–∏–∫–æ–≥–¥–∞' in combined_text and ('–∏–∑–≤–∏–Ω—è–µ—Ç—Å—è' in combined_text or '–ø—Ä–∏–∑–Ω–∞–µ—Ç' in combined_text):
            profile_parts.append("–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∫ –ø—Ä–∏–∑–Ω–∞–Ω–∏—é –æ—à–∏–±–æ–∫ –∏ –∏–∑–≤–∏–Ω–µ–Ω–∏—è–º —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–∞—Ä—Ü–∏—Å—Å–∏—á–µ—Å–∫–∏–µ —á–µ—Ä—Ç—ã –ª–∏—á–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–æ–±–ª–µ–º—ã —Å —ç–º–ø–∞—Ç–∏–µ–π.")
        
        if not profile_parts:
            profile_parts.append(f"–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, {partner_name} –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è –∏ –≤–æ–∑–º–æ–∂–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.")
        
        psychological_profile = " ".join(profile_parts)
        
        # Generate red flags based on answers
        red_flags = []
        if '–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç' in combined_text:
            red_flags.append("–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å –ø–æ–≤–µ–¥–µ–Ω–∏—è –∏ –¥–µ–π—Å—Ç–≤–∏–π –ø–∞—Ä—Ç–Ω–µ—Ä–∞")
        if '–ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–ª–µ—Ñ–æ–Ω' in combined_text or '–ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è' in combined_text:
            red_flags.append("–ù–∞—Ä—É—à–µ–Ω–∏–µ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏ –∏ –ª–∏—á–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü")
        if '–Ω–µ —Ä–∞–∑—Ä–µ—à–∞–µ—Ç' in combined_text or '–∑–∞–ø—Ä–µ—â–∞–µ—Ç' in combined_text:
            red_flags.append("–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –∏ –∏–∑–æ–ª—è—Ü–∏—è –æ—Ç –±–ª–∏–∑–∫–∏—Ö")
        if '–∫—Ä–∏—á–∏—Ç' in combined_text or '–∑–ª–∏—Ç—Å—è' in combined_text:
            red_flags.append("–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∞–≥—Ä–µ—Å—Å–∏—è –∏ –≤—Å–ø—ã—à–∫–∏ –≥–Ω–µ–≤–∞")
        if '—É–Ω–∏–∂–∞–µ—Ç' in combined_text or '–æ—Å–∫–æ—Ä–±–ª—è–µ—Ç' in combined_text:
            red_flags.append("–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –Ω–∞—Å–∏–ª–∏–µ –∏ —É–Ω–∏–∂–µ–Ω–∏–µ –¥–æ—Å—Ç–æ–∏–Ω—Å—Ç–≤–∞")
        
        if not red_flags:
            red_flags = ["–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è, —Ç—Ä–µ–±—É—é—â–∏–µ –≤–Ω–∏–º–∞–Ω–∏—è"]
        
        # Generate survival guide
        survival_guide = []
        if risk_score >= 70:
            survival_guide.extend([
                "–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –ø—Å–∏—Ö–æ–ª–æ–≥—É –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –ø–æ —Å–µ–º–µ–π–Ω—ã–º –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º",
                "–°–æ–∑–¥–∞–π—Ç–µ –ø–ª–∞–Ω –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –ª—é–¥–µ–π, –∫ –∫–æ—Ç–æ—Ä—ã–º –º–æ–∂–Ω–æ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∑–∞ –ø–æ–º–æ—â—å—é",
                "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å–≤—è–∑–∏ —Å —Å–µ–º—å–µ–π –∏ –¥—Ä—É–∑—å—è–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ–∫–∞–∑–∞—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É",
                "–ò–∑—É—á–∏—Ç–µ —Ç–µ—Ö–Ω–∏–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –≥—Ä–∞–Ω–∏—Ü –∏ –∑–∞—â–∏—Ç—ã –æ—Ç –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π"
            ])
        else:
            survival_guide.extend([
                "–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Å–µ–º–µ–π–Ω–æ–º—É –ø—Å–∏—Ö–æ–ª–æ–≥—É –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–∞—Ä–æ–π",
                "–ò–∑—É—á–∏—Ç–µ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—É –æ –∑–¥–æ—Ä–æ–≤—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏",
                "–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç–æ–µ –∏ —á–µ—Å—Ç–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ —Å –ø–∞—Ä—Ç–Ω–µ—Ä–æ–º",
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —á–µ—Ç–∫–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö"
            ])
        
        return {
            "psychological_profile": psychological_profile,
            "red_flags": red_flags,
            "survival_guide": survival_guide,
            "dark_triad": {
                "narcissism": min(10, risk_score / 10),
                "machiavellianism": min(10, (risk_score - 10) / 10),
                "psychopathy": min(10, (risk_score - 20) / 10)
            },
            "block_scores": {
                "narcissism": min(10, risk_score / 12),
                "control": min(10, risk_score / 10),
                "gaslighting": min(10, (risk_score - 5) / 12),
                "emotion": min(10, risk_score / 15),
                "intimacy": min(10, (risk_score - 10) / 12),
                "social": min(10, risk_score / 11)
            },
            "overall_risk_score": risk_score,
            "urgency_level": urgency,
            "safety_alerts": ["–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º"],
            "partner_name": partner_name,
            "ai_available": False,
            "fallback_used": True
        }


# Global AI service instance
ai_service = AIService() 